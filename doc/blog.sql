/*
 Navicat Premium Data Transfer

 Source Server         : 博客系统数据库
 Source Server Type    : MySQL
 Source Server Version : 50735
 Source Host           : 129.28.156.166:3306
 Source Schema         : blog

 Target Server Type    : MySQL
 Target Server Version : 50735
 File Encoding         : 65001

 Date: 08/02/2022 15:27:11
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for blog_article
-- ----------------------------
DROP TABLE IF EXISTS `blog_article`;
CREATE TABLE `blog_article`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NULL DEFAULT NULL COMMENT '发表用户',
  `article_content` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL COMMENT '文章内容html格式',
  `article_content_md` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL COMMENT '文章内容Markdown格式',
  `article_newstime` datetime(0) NULL DEFAULT NULL COMMENT '发布时间',
  `article_status` int(11) NULL DEFAULT NULL COMMENT '文章状态 0已发布1草稿2回收站',
  `article_summary` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '文章摘要',
  `article_thumbnail` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '略缩图',
  `article_title` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '文章标题',
  `article_type` int(255) NULL DEFAULT NULL COMMENT '文章类型0原创1转载',
  `article_post` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT 'post文章 page页面',
  `article_comment` int(11) NULL DEFAULT NULL COMMENT '是否开启评论 0开启1不开启',
  `article_updatetime` datetime(0) NULL DEFAULT NULL COMMENT '文章最后修改时间',
  `article_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '文章路径',
  `article_views` bigint(20) NULL DEFAULT 0 COMMENT '访问量统计',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `blog_ARTICLE_URL`(`article_url`) USING BTREE,
  INDEX `blog_ARTICLE_USERID`(`user_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 168 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_article
-- ----------------------------
INSERT INTO `blog_article` VALUES (147, 9, '<h1 id=\"-\">概述</h1>\r\n<p>Apache JMeter 是 Apache 组织开发的基于java的压力测试工具。Apache jmeter 可以用于对静态的和动态的资源（文件，Servlet，Perl脚本，java 对象，数据库和查询，FTP服务器等等）的性能进行测试。它可以用于对服务器、网络或对象模拟繁重的负载来测试它们的强度或分析不同压力类型下的整体性能。你可以使用它做性能的图形分析或在大并发负载测试你的服务器/脚本/对象。</p>\r\n<p>官网：<a href=\"https://jmeter.apache.org/\">https://jmeter.apache.org/</a></p>\r\n<p>下载地址：<a href=\"https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.4.1.zip\">https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.4.1.zip</a></p>\r\n<h1 id=\"-\">使用前的一些配置</h1>\r\n<h2 id=\"-java-\">配置java环境</h2>\r\n<p>因为 JMeter 是使用 java 开发的，所以在使用 JMeter 的之前需要安装 java 环境，配置环境变量。具体不在本文讲述了。</p>\r\n<h2 id=\"-\">修改默认语言为中文</h2>\r\n<ol>\r\n<li><p>解压 刚刚下载的压缩包，进入 <code>bat</code> 目录，双击 <code>jmeter.bat</code> 启动程序。启动之后会有两个窗口，一个cmd窗口，一个JMeter的 GUI。</p>\r\n</li>\r\n<li><p>通过 options → Choose Language 变更为简体中文</p>\r\n</li>\r\n</ol>\r\n<h1 id=\"-\">具体使用</h1>\r\n<h2 id=\"-\">创建线程组</h2>\r\n<p>在“测试计划”上右键 【添加】--&gt;【Threads(Users)】--&gt;【线程组】。</p>\r\n<p><img src=\"https://www.ylcoder.top/upload/2021/12/27GinHHsJkpXpj8o1FJi262021121503494347.png\" alt=\"\"></p>\r\n<p>设置线程数和循环次数。我这里设置线程数为500，循环一次。</p>\r\n<p><img src=\"https://secure1.wostatic.cn/static/kN5f56SMTPx4rrWPLLC7p6/image.png\" alt=\"\"></p>\r\n<h2 id=\"-\">配置元件</h2>\r\n<p>在我们刚刚创建的线程组上右键 【添加】--&gt;【配置元件】--&gt;【HTTP请求默认值】。</p>\r\n<p><img src=\"https://secure1.wostatic.cn/static/3hZGDP2VcQXj77pGXJjidr/image.png\" alt=\"\"></p>\r\n<p>配置我们需要进行测试的程序协议、地址和端口</p>\r\n<p><img src=\"https://secure1.wostatic.cn/static/wJVokBzzMCWwHxEPLvVQvy/image.png\" alt=\"\"></p>\r\n<blockquote>\r\n<p>当所有的接口测试的访问域名和端口都一样时，可以使用该元件，一旦服务器地址变更，只需要修改请求默认值即可。</p>\r\n</blockquote>\r\n<h2 id=\"-http-\">构造 HTTP 请求</h2>\r\n<p>在“线程组”右键 【添加-】-&gt;【samlper】--&gt;【HTTP 请求】设置我们需要测试的API的请求路径和数据。我这里是用的json</p>\r\n<p><img src=\"https://secure1.wostatic.cn/static/ph4FmQaLqwAUCWCZrLttZ6/image.png\" alt=\"\"></p>\r\n<h2 id=\"-\">添加请求头</h2>\r\n<p>在我们刚刚创建的线程组上右键 【添加】--&gt;【配置元件】--&gt;【HTTP信息头管理器】。</p>\r\n<p>因为我要传输的数据为json，所以设置一个 <code>Content-Type:application/json</code></p>\r\n<p><img src=\"https://secure1.wostatic.cn/static/nJPbiQFUFH8NXPQ6DxZbXT/image.png\" alt=\"\"></p>\r\n<h2 id=\"-\">添加断言</h2>\r\n<p>在我们刚刚创建的线程组上右键 【添加】--&gt;【断言】--&gt;【响应断言】。</p>\r\n<p>根据响应的数据来判断请求是否正常。我在这里只判断的响应代码是否为200。还可以配置错误信息</p>\r\n<p><img src=\"https://secure1.wostatic.cn/static/mqU4JgCTVvrWYDmPuTJh2m/image.png\" alt=\"\"></p>\r\n<h2 id=\"-\">添加察看结果树</h2>\r\n<p>在我们刚刚创建的线程组上右键 【添加】--&gt;【监听器】--&gt;【察看结果树】。</p>\r\n<p>直接添加，然后点击<code>运行</code>按钮就可以看到结果了。</p>\r\n<p><img src=\"https://secure1.wostatic.cn/static/5Dxn7dZPUL6jnw4JzKPv7o/image.png\" alt=\"\"></p>\r\n<h2 id=\"-summary-report\">添加Summary Report</h2>\r\n<p>在我们刚刚创建的线程组上右键 【添加】--&gt;【监听器】--&gt;【Summary Report】。</p>\r\n<p>直接添加，然后点击<code>运行</code>按钮就可以看到结果了。<strong>记得保存测试计划</strong></p>\r\n<p><img src=\"https://secure1.wostatic.cn/static/mnuLNZYdZdR11NjshZTadU/image.png\" alt=\"\"></p>\r\n<h1 id=\"-\">执行测试计划</h1>\r\n<p>前面我们说过，执行测试计划不能用GUI，需要用命令行来执行。</p>\r\n<p><code>jmeter -n -t testplan/RedisLock.jmx -l testplan/result/result.txt -e -o testplan/webreport</code></p>\r\n<ul>\r\n<li><p><code>testplan/RedisLock.jmx</code> 为测试计划文件路径</p>\r\n</li>\r\n<li><p><code>testplan/result/result.txt</code> 为测试结果文件路径</p>\r\n</li>\r\n<li><p><code>testplan/webreport</code> 为web报告保存路径。</p>\r\n</li>\r\n</ul>\r\n<p>Web报告如下：</p>\r\n<p><img src=\"https://secure1.wostatic.cn/static/wAbt4AAaPAVdT1wDBYzsRd/image.png\" alt=\"\"></p>\r\n<p>线程数量和循环次数将会影响最终的测试报告。</p>', '# 概述\r\n\r\nApache JMeter 是 Apache 组织开发的基于java的压力测试工具。Apache jmeter 可以用于对静态的和动态的资源（文件，Servlet，Perl脚本，java 对象，数据库和查询，FTP服务器等等）的性能进行测试。它可以用于对服务器、网络或对象模拟繁重的负载来测试它们的强度或分析不同压力类型下的整体性能。你可以使用它做性能的图形分析或在大并发负载测试你的服务器/脚本/对象。\r\n\r\n官网：[https://jmeter.apache.org/](https://jmeter.apache.org/)\r\n\r\n下载地址：[https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.4.1.zip](https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.4.1.zip)\r\n\r\n\r\n\r\n\r\n\r\n# 使用前的一些配置\r\n\r\n## 配置java环境\r\n\r\n因为 JMeter 是使用 java 开发的，所以在使用 JMeter 的之前需要安装 java 环境，配置环境变量。具体不在本文讲述了。\r\n\r\n## 修改默认语言为中文\r\n\r\n1. 解压 刚刚下载的压缩包，进入 `bat` 目录，双击 `jmeter.bat` 启动程序。启动之后会有两个窗口，一个cmd窗口，一个JMeter的 GUI。\r\n\r\n2. 通过 options → Choose Language 变更为简体中文\r\n\r\n# 具体使用\r\n\r\n## 创建线程组\r\n\r\n在“测试计划”上右键 【添加】-->【Threads(Users)】-->【线程组】。\r\n\r\n![](https://www.ylcoder.top/upload/2021/12/27GinHHsJkpXpj8o1FJi262021121503494347.png)\r\n\r\n\r\n\r\n设置线程数和循环次数。我这里设置线程数为500，循环一次。\r\n\r\n![](https://secure1.wostatic.cn/static/kN5f56SMTPx4rrWPLLC7p6/image.png)\r\n\r\n## 配置元件\r\n\r\n在我们刚刚创建的线程组上右键 【添加】-->【配置元件】-->【HTTP请求默认值】。\r\n\r\n![](https://secure1.wostatic.cn/static/3hZGDP2VcQXj77pGXJjidr/image.png)\r\n\r\n配置我们需要进行测试的程序协议、地址和端口\r\n\r\n![](https://secure1.wostatic.cn/static/wJVokBzzMCWwHxEPLvVQvy/image.png)\r\n\r\n> 当所有的接口测试的访问域名和端口都一样时，可以使用该元件，一旦服务器地址变更，只需要修改请求默认值即可。\r\n\r\n## 构造 HTTP 请求\r\n\r\n在“线程组”右键 【添加-】->【samlper】-->【HTTP 请求】设置我们需要测试的API的请求路径和数据。我这里是用的json\r\n\r\n![](https://secure1.wostatic.cn/static/ph4FmQaLqwAUCWCZrLttZ6/image.png)\r\n\r\n## 添加请求头\r\n\r\n在我们刚刚创建的线程组上右键 【添加】-->【配置元件】-->【HTTP信息头管理器】。\r\n\r\n因为我要传输的数据为json，所以设置一个 `Content-Type:application/json`\r\n\r\n![](https://secure1.wostatic.cn/static/nJPbiQFUFH8NXPQ6DxZbXT/image.png)\r\n\r\n## 添加断言\r\n\r\n在我们刚刚创建的线程组上右键 【添加】-->【断言】-->【响应断言】。\r\n\r\n根据响应的数据来判断请求是否正常。我在这里只判断的响应代码是否为200。还可以配置错误信息\r\n\r\n![](https://secure1.wostatic.cn/static/mqU4JgCTVvrWYDmPuTJh2m/image.png)\r\n\r\n## 添加察看结果树\r\n\r\n在我们刚刚创建的线程组上右键 【添加】-->【监听器】-->【察看结果树】。\r\n\r\n直接添加，然后点击`运行`按钮就可以看到结果了。\r\n\r\n![](https://secure1.wostatic.cn/static/5Dxn7dZPUL6jnw4JzKPv7o/image.png)\r\n\r\n## 添加Summary Report\r\n\r\n在我们刚刚创建的线程组上右键 【添加】-->【监听器】-->【Summary Report】。\r\n\r\n直接添加，然后点击`运行`按钮就可以看到结果了。**记得保存测试计划**\r\n\r\n![](https://secure1.wostatic.cn/static/mnuLNZYdZdR11NjshZTadU/image.png)\r\n\r\n# 执行测试计划\r\n\r\n前面我们说过，执行测试计划不能用GUI，需要用命令行来执行。\r\n\r\n`jmeter -n -t testplan/RedisLock.jmx -l testplan/result/result.txt -e -o testplan/webreport`\r\n\r\n- `testplan/RedisLock.jmx` 为测试计划文件路径\r\n\r\n- `testplan/result/result.txt` 为测试结果文件路径\r\n\r\n- `testplan/webreport` 为web报告保存路径。\r\n\r\nWeb报告如下：\r\n\r\n![](https://secure1.wostatic.cn/static/wAbt4AAaPAVdT1wDBYzsRd/image.png)\r\n\r\n线程数量和循环次数将会影响最终的测试报告。', '2021-12-14 15:22:07', 0, '概述ApacheJMeter是Apache组织开发的基于java的压力测试工具。Apachejmet', '/static/img/rand/13.jpg', 'JMeter 入门', 0, 'post', 0, '2021-12-16 07:38:52', 'introduction to JMeter', 30);
INSERT INTO `blog_article` VALUES (148, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>Be good. Be bad. Just be yourself.<br>是好还是坏，只要做你自己就好。</p>\r\n<h1 id=\"-\">概念</h1>\r\n<p>数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。</p>\r\n<p>在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，叫做索引</p>\r\n<p>为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间（因为索引也要随之变动）</p>\r\n<h1 id=\"-\">创建索引的优缺点</h1>\r\n<p><strong>优点</strong>：</p>\r\n<ul>\r\n<li>通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性</li>\r\n<li>可以大大加快数据的检索速度，这也是创建索引的最主要的原因</li>\r\n<li>可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义</li>\r\n<li>在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间</li>\r\n<li>通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能</li>\r\n</ul>\r\n<p><strong>缺点：</strong></p>\r\n<ul>\r\n<li>创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加</li>\r\n<li>索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。</li>\r\n<li>当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护程度</li>\r\n</ul>\r\n<h1 id=\"-\">关于是否应该创建索引的列的探讨</h1>\r\n<ul>\r\n<li>对于那些在查询中很少使用或者参考的列不应该创建索引</li>\r\n<li>对于那些只有很少数据值的列也不应该增加索引</li>\r\n<li>对于那些定义为 text、image、bit 数据类型的列不应该增加索引</li>\r\n<li>当修改性能远远大于检索性能时，不应该创建索引。修改性能和检索性能时相互矛盾的。</li>\r\n</ul>\r\n<h1 id=\"-\">索引类型</h1>\r\n<h3 id=\"-\">唯一索引</h3>\r\n<p>唯一索引是不允许其中任何两行具有相同索引值的索引<br>当现有数据中存在重复的键值时，大多数数据库不允许将新创建的唯一索引与表一起保存。<br>数据库还可能防止添加将在表中创建重复键值的新数据。例如，如果在 employee 表中职员的姓名（name）上创建了唯一索引，则任何两个员工都不能同性</p>\r\n<h3 id=\"-\">主键索引</h3>\r\n<p>数据库表经常有一列或列组合，其值唯一标识表中的每一行，该列称为表的主键<br>在数据库关系图中为表定义主键将自动创建索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问</p>\r\n<h3 id=\"-\">聚集索引</h3>\r\n<p>在聚集索引中，表中行的物理顺序与键值的逻辑（索引）顺序相同。一个表只能包含一个聚集索引<br>如果某索引不是聚集索引，则表中行的物理顺序与键值的逻辑顺序不匹配。与非聚集索引相比，聚集索引通常提供更快的数据访问速度</p>\r\n<h1 id=\"-\">局部性原理与磁盘预读</h1>\r\n<p>由于存储介质特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的 存取速度往往是主存的几百分之一，因此<strong>为了提高效率，要尽量减少磁盘IO。</strong></p>\r\n<p>为了达到目的，磁盘往往不是严格按需读取，而是每次都会预读，即便只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。</p>\r\n<p>这样做的理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。</p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>总有一个人，一直住在心里，却告别在生活里。忘不掉的是回忆，继续的是生活，来来往往身边出现了很多人，总有一个位置，一直没有变。看看温暖的阳光，偶尔还是会想一想。怀旧，不是因为那个时代多么好，而是那个时候，你年轻。</p>', '# 每日一句\r\nBe good. Be bad. Just be yourself. \r\n是好还是坏，只要做你自己就好。\r\n\r\n# 概念\r\n\r\n数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。\r\n\r\n在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，叫做索引\r\n\r\n为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间（因为索引也要随之变动）\r\n\r\n# 创建索引的优缺点\r\n\r\n**优点**：\r\n\r\n* 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性\r\n* 可以大大加快数据的检索速度，这也是创建索引的最主要的原因\r\n* 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义\r\n* 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间\r\n* 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能\r\n\r\n**缺点：**\r\n\r\n* 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加\r\n* 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。\r\n* 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护程度\r\n\r\n# 关于是否应该创建索引的列的探讨\r\n\r\n* 对于那些在查询中很少使用或者参考的列不应该创建索引\r\n* 对于那些只有很少数据值的列也不应该增加索引\r\n* 对于那些定义为 text、image、bit 数据类型的列不应该增加索引\r\n* 当修改性能远远大于检索性能时，不应该创建索引。修改性能和检索性能时相互矛盾的。\r\n\r\n# 索引类型\r\n\r\n### 唯一索引\r\n\r\n唯一索引是不允许其中任何两行具有相同索引值的索引\r\n当现有数据中存在重复的键值时，大多数数据库不允许将新创建的唯一索引与表一起保存。\r\n数据库还可能防止添加将在表中创建重复键值的新数据。例如，如果在 employee 表中职员的姓名（name）上创建了唯一索引，则任何两个员工都不能同性\r\n\r\n### 主键索引\r\n\r\n数据库表经常有一列或列组合，其值唯一标识表中的每一行，该列称为表的主键\r\n在数据库关系图中为表定义主键将自动创建索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问\r\n\r\n### 聚集索引\r\n\r\n在聚集索引中，表中行的物理顺序与键值的逻辑（索引）顺序相同。一个表只能包含一个聚集索引\r\n如果某索引不是聚集索引，则表中行的物理顺序与键值的逻辑顺序不匹配。与非聚集索引相比，聚集索引通常提供更快的数据访问速度\r\n\r\n# 局部性原理与磁盘预读\r\n\r\n由于存储介质特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的 存取速度往往是主存的几百分之一，因此**为了提高效率，要尽量减少磁盘IO。**\r\n\r\n为了达到目的，磁盘往往不是严格按需读取，而是每次都会预读，即便只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。\r\n\r\n这样做的理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。\r\n\r\n\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n总有一个人，一直住在心里，却告别在生活里。忘不掉的是回忆，继续的是生活，来来往往身边出现了很多人，总有一个位置，一直没有变。看看温暖的阳光，偶尔还是会想一想。怀旧，不是因为那个时代多么好，而是那个时候，你年轻。', '2021-12-16 07:03:44', 0, '每日一句Begood.Bebad.Justbeyourself.是好还是坏，只要做你自己就好。概念数', '/static/img/rand/13.jpg', 'MYSQL 数据库索引及其数据结构', 0, 'post', 0, '2021-12-16 07:12:03', '1639659824', 30);
INSERT INTO `blog_article` VALUES (149, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>No victory comes without a price.<br>凡是成功就要付出代价。</p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>这个快速开始手册是帮忙您快速在您的电脑上，下载、安装并使用 nacos。</p>\r\n<h1 id=\"-\">版本选择</h1>\r\n<p>您可以在Nacos的<a href=\"https://github.com/alibaba/nacos/releases\">release notes</a>及<a href=\"https://nacos.io/zh-cn/blog/index.html\">博客</a>中找到每个版本支持的功能的介绍，当前推荐的稳定版本为1.4.1。</p>\r\n<h1 id=\"-\">预备环境准备</h1>\r\n<p>Nacos 依赖 Java 环境来运行。如果您是从代码开始构建并运行Nacos，还需要为此配置 Maven环境，请确保是在以下版本环境中安装使用:</p>\r\n<ol>\r\n<li>64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。</li>\r\n<li>64 bit JDK 1.8+；<a href=\"http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\">下载</a> &amp; <a href=\"https://docs.oracle.com/cd/E19182-01/820-7851/inst_cli_jdk_javahome_t/\">配置</a>。</li>\r\n<li>Maven 3.2.x+；<a href=\"https://maven.apache.org/download.cgi\">下载</a> &amp; <a href=\"https://maven.apache.org/settings.html\">配置</a>。</li>\r\n</ol>\r\n<h1 id=\"-\">下载源码或者安装包</h1>\r\n<p>你可以通过源码和发行包两种方式来获取 Nacos。</p>\r\n<p><strong>从 Github 上下载源码方式</strong></p>\r\n<pre><code class=\"lang-Bash\">git clone https://github.com/alibaba/nacos.git \r\ncd nacos/ \r\nmvn -Prelease-nacos -Dmaven.test.skip=true clean <span class=\"hljs-keyword\">install</span> -U ls -al distribution/target/ \r\n\r\n// <span class=\"hljs-keyword\">change</span> the $<span class=\"hljs-keyword\">version</span> <span class=\"hljs-keyword\">to</span> your actual <span class=\"hljs-keyword\">path</span> \r\ncd distribution/target/nacos-<span class=\"hljs-keyword\">server</span>-$<span class=\"hljs-keyword\">version</span>/nacos/<span class=\"hljs-keyword\">bin</span>\r\n</code></pre>\r\n<p><strong>下载编译后压缩包方式</strong></p>\r\n<p>您可以从 <a href=\"https://github.com/alibaba/nacos/releases\">最新稳定版本</a> 下载 nacos-server-$version.zip 包。</p>\r\n<p><code>unzip nacos-server-$version.zip 或者 tar -xvf nacos-server-$version.tar.gz cd nacos/bin</code></p>\r\n<h1 id=\"-\">启动服务器</h1>\r\n<p><strong>Linux/Unix/Mac</strong></p>\r\n<pre><code class=\"lang-Bash\"><span class=\"hljs-section\">启动命令(standalone代表着单机模式运行，非集群模式):</span>\r\nsh startup.sh -m standalone\r\n如果您使用的是ubuntu系统，或者运行脚本报错提示[[符号找不到，可尝试如下运行：\r\nbash startup.sh -m standalone\r\n</code></pre>\r\n<p><strong>Windows</strong></p>\r\n<pre><code class=\"lang-Bash\">启动命令(<span class=\"hljs-selector-tag\">standalone</span>代表着单机模式运行，非集群模式):\r\n<span class=\"hljs-selector-tag\">cmd</span> <span class=\"hljs-selector-tag\">startup</span><span class=\"hljs-selector-class\">.cmd</span> <span class=\"hljs-selector-tag\">-m</span> <span class=\"hljs-selector-tag\">standalone</span>\r\n</code></pre>\r\n<h1 id=\"-\">服务注册&amp;发现和配置管理</h1>\r\n<p><strong>服务注册</strong><br><code>curl -X POST &#39;http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080</code><br><strong>服务发现</strong><br><code>curl -X GET &#39;http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName</code><br><strong>发布配置</strong><br><code>curl -X POST &quot;http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=HelloWorld</code><br><strong>获取配置</strong><br><code>curl -X GET &quot;http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test</code></p>\r\n<h1 id=\"-\">关闭服务器</h1>\r\n<p><strong>Linux/Unix/Mac</strong></p>\r\n<p><code>sh shutdown.sh</code></p>\r\n<p><strong>Windows</strong></p>\r\n<p><code>cmd shutdown.cmd</code><br>或者双击shutdown.cmd运行文件。</p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>一生匆匆来去，没有什么是看不开，过不去的。</p>\r\n<p>没有人规定人人都必须长成玫瑰才算成功，只要你喜欢，你可以长成郁金香、雏菊、茉莉，甚至是路边迎风绽放的小花朵。</p>\r\n<p>想挣钱，就努力工作；累了倦了，就停下来休息；想追逐远方，就去旅行；想充实自己，就看书学习技能。</p>\r\n<p>孤独，会让人在无人打扰的时分，给自己的精神世界创造完美的留白；孤独，也可酿成岁月的香醇。</p>\r\n<p>虽然生活有时会有危机，但有时也可以变得温存和美好。只要一路向前，总会赶得上日出和日落。</p>\r\n<p>这世界盛大灿烂，只要自己开心快乐，我们可以尝试不同的生活方式。</p>', '# 每日一句\r\nNo victory comes without a price.\r\n凡是成功就要付出代价。\r\n\r\n# 概述\r\n\r\n这个快速开始手册是帮忙您快速在您的电脑上，下载、安装并使用 nacos。\r\n\r\n# 版本选择\r\n\r\n您可以在Nacos的[release notes](https://github.com/alibaba/nacos/releases)及[博客](https://nacos.io/zh-cn/blog/index.html)中找到每个版本支持的功能的介绍，当前推荐的稳定版本为1.4.1。\r\n\r\n# 预备环境准备\r\n\r\nNacos 依赖 Java 环境来运行。如果您是从代码开始构建并运行Nacos，还需要为此配置 Maven环境，请确保是在以下版本环境中安装使用:\r\n1. 64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。\r\n2. 64 bit JDK 1.8+；[下载](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) & [配置](https://docs.oracle.com/cd/E19182-01/820-7851/inst_cli_jdk_javahome_t/)。\r\n3. Maven 3.2.x+；[下载](https://maven.apache.org/download.cgi) & [配置](https://maven.apache.org/settings.html)。\r\n\r\n# 下载源码或者安装包\r\n\r\n你可以通过源码和发行包两种方式来获取 Nacos。\r\n\r\n**从 Github 上下载源码方式**\r\n\r\n```Bash\r\ngit clone https://github.com/alibaba/nacos.git \r\ncd nacos/ \r\nmvn -Prelease-nacos -Dmaven.test.skip=true clean install -U ls -al distribution/target/ \r\n\r\n// change the $version to your actual path \r\ncd distribution/target/nacos-server-$version/nacos/bin\r\n```\r\n\r\n\r\n**下载编译后压缩包方式**\r\n\r\n您可以从 [最新稳定版本](https://github.com/alibaba/nacos/releases) 下载 nacos-server-$version.zip 包。\r\n\r\n`unzip nacos-server-$version.zip 或者 tar -xvf nacos-server-$version.tar.gz cd nacos/bin`\r\n\r\n# 启动服务器\r\n\r\n**Linux/Unix/Mac**\r\n\r\n```Bash\r\n启动命令(standalone代表着单机模式运行，非集群模式):\r\nsh startup.sh -m standalone\r\n如果您使用的是ubuntu系统，或者运行脚本报错提示[[符号找不到，可尝试如下运行：\r\nbash startup.sh -m standalone\r\n```\r\n\r\n\r\n**Windows**\r\n\r\n```Bash\r\n启动命令(standalone代表着单机模式运行，非集群模式):\r\ncmd startup.cmd -m standalone\r\n```\r\n\r\n# 服务注册&发现和配置管理\r\n\r\n**服务注册**\r\n`curl -X POST \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&ip=20.18.7.10&port=8080`\r\n**服务发现**\r\n`curl -X GET \'http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName`\r\n**发布配置**\r\n`curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&group=test&content=HelloWorld`\r\n**获取配置**\r\n`curl -X GET \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&group=test`\r\n\r\n# 关闭服务器\r\n\r\n**Linux/Unix/Mac**\r\n\r\n`sh shutdown.sh`\r\n\r\n**Windows**\r\n\r\n`cmd shutdown.cmd`\r\n或者双击shutdown.cmd运行文件。\r\n\r\n\r\n# 美文佳句\r\n\r\n一生匆匆来去，没有什么是看不开，过不去的。\r\n\r\n没有人规定人人都必须长成玫瑰才算成功，只要你喜欢，你可以长成郁金香、雏菊、茉莉，甚至是路边迎风绽放的小花朵。\r\n\r\n想挣钱，就努力工作；累了倦了，就停下来休息；想追逐远方，就去旅行；想充实自己，就看书学习技能。\r\n\r\n孤独，会让人在无人打扰的时分，给自己的精神世界创造完美的留白；孤独，也可酿成岁月的香醇。\r\n\r\n虽然生活有时会有危机，但有时也可以变得温存和美好。只要一路向前，总会赶得上日出和日落。\r\n\r\n这世界盛大灿烂，只要自己开心快乐，我们可以尝试不同的生活方式。', '2021-12-16 07:36:41', 0, '每日一句Novictorycomeswithoutaprice.凡是成功就要付出代价。概述这个快速开', '/static/img/rand/2.jpg', 'nacos 快速入门', 0, 'post', 0, '2021-12-16 07:36:41', '1639661800', 40);
INSERT INTO `blog_article` VALUES (150, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>Never give up until the fight is over.<br>永远不要放弃，要一直战斗到最后一秒。</p>\r\n<h1 id=\"-\">概念</h1>\r\n<p>长连接<br>指在一个TCP连接上可以连续发送多个数据包。<br>在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维持。</p>\r\n<p>短连接<br>指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接。</p>\r\n<p>HTTP的长连接和短连接本质上是TCP长连接和短连接。<br>HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。<br>IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠的传递数据包。</p>\r\n<p>从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：<code>Connection:keep-alive</code></p>\r\n<h1 id=\"-\"><strong>连接过程</strong></h1>\r\n<p>短连接操作步骤是：<br>连接→数据传输→关闭连接；</p>\r\n<p>长连接通常就是：<br>连接→数据传输→保持连接(心跳)→数据传输→保持连接(心跳)→……→关闭连接</p>\r\n<h1 id=\"-\">使用场景</h1>\r\n<p>长连接:<br>多用于操作频繁，点对点的通讯，而且连接数不能太多情况.<br>如数据库连接</p>\r\n<p>短连接<br>web网站的http服务。长连接更加耗费服务器资源。bulabula..</p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>把握分寸，是一种难得的智慧。那些能看到别人优点的人，往往懂得把别人放在心上，时刻照顾别人的感受。他们会在一言一语中放低自己的姿态，让别人感受到关心和尊重。</p>\r\n<p>人与人之间，不过一场以心换心。学会欣赏别人，别人才会欣赏你。对他人适时地赞美，不需要多么高超的说话技巧，比技巧更重要的是真诚。真心实意、以诚相待，永远是人际交往中最基本的准则。</p>', '# 每日一句\r\nNever give up until the fight is over. \r\n永远不要放弃，要一直战斗到最后一秒。\r\n\r\n# 概念\r\n\r\n长连接\r\n指在一个TCP连接上可以连续发送多个数据包。\r\n在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维持。\r\n\r\n短连接\r\n指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接。\r\n\r\nHTTP的长连接和短连接本质上是TCP长连接和短连接。\r\nHTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。\r\nIP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠的传递数据包。\r\n\r\n从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：`Connection:keep-alive`\r\n\r\n# **连接过程**\r\n\r\n短连接操作步骤是：\r\n连接→数据传输→关闭连接；\r\n\r\n长连接通常就是：\r\n连接→数据传输→保持连接(心跳)→数据传输→保持连接(心跳)→……→关闭连接\r\n\r\n# 使用场景\r\n\r\n长连接:\r\n多用于操作频繁，点对点的通讯，而且连接数不能太多情况.\r\n如数据库连接\r\n\r\n短连接\r\nweb网站的http服务。长连接更加耗费服务器资源。bulabula..\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n把握分寸，是一种难得的智慧。那些能看到别人优点的人，往往懂得把别人放在心上，时刻照顾别人的感受。他们会在一言一语中放低自己的姿态，让别人感受到关心和尊重。\r\n\r\n人与人之间，不过一场以心换心。学会欣赏别人，别人才会欣赏你。对他人适时地赞美，不需要多么高超的说话技巧，比技巧更重要的是真诚。真心实意、以诚相待，永远是人际交往中最基本的准则。', '2021-12-16 07:41:46', 0, '每日一句Nevergiveupuntilthefightisover.永远不要放弃，要一直战斗到最后', '/static/img/rand/16.jpg', '20 HTTP 长连接与短连接', 0, 'post', 0, '2021-12-16 07:41:46', '1639662105', 10);
INSERT INTO `blog_article` VALUES (151, 9, '<p>每日一句<br>When I shiver with cold, not a snowflake is innocent. 当我冷得瑟瑟发抖时，没有一片雪花是无辜的。</p>\r\n<p>概述<br>CPU 利用时间片轮询来为每个任务都服务一定的时间，然后把当前任务的状态保存下来，继续服务下一个任务。 任务的状态保存及再加载就叫做线程的上下文切换。</p>\r\n<ol>\r\n<li><p>进程：指一个运行中的程序的实例。在一个进程内部可以有多个线程在同时运行，并与创建它的进程共享同一地址空间（一段内存区域）和其他资源</p>\r\n</li>\r\n<li><p>上下文：指线程切换时CPU寄存器和程序计数器所保存的当前线程的信息</p>\r\n</li>\r\n<li><p>寄存器：指CPU内部容量较小但速度很快的内存区域（与之对应的是CPU外部相对较慢的RAM主内存）。寄存器通过对常用值（通常是运算的中间值）的快速访问来加快计算机程序运行的速度</p>\r\n</li>\r\n<li><p>程序计数器：是一个专用的寄存器，用于表明指令序列中CPU正在执行的位置，存储的值为正在执行的指令的位置或者下一个将被执行的指令的位置，这依赖于特定的系统。</p>\r\n</li>\r\n</ol>\r\n<p>上下文切换<br>上下文切换指的是内核（操作系统的核心）在CPU上对进程或者线程进行切换。 上下文切换过程中的信息被保存在进程控制块（PCB-Process Control Block）中。PCB又被称作切换帧（SwitchFrame）。 上下文切换的信息会一直被保存在CPU的内存中，直到被再次使用。</p>\r\n<p>上下文切换流程如下：</p>\r\n<p>（1）挂起一个进程，将这个进程在CPU中的状态（上下文信息）存储于内存的PCB中。</p>\r\n<p>（2）在PCB中检索下一个进程的上下文并将其在CPU的寄存器中恢复。</p>\r\n<p>（3）跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行）并恢复该进程。</p>\r\n<p>时间片轮转方式使多个任务在同一CPU上的执行有了可能.</p>\r\n<p>引起线程上下文切换的原因<br>引起线程上下文切换的原因如下。</p>\r\n<p>◎ 当前正在执行的任务完成，系统的CPU正常调度下一个任务。</p>\r\n<p>◎ 当前正在执行的任务遇到I/O等阻塞操作，调度器挂起此任务，继续调度下一个任务。</p>\r\n<p>◎ 多个任务并发抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续调度下一个任务。</p>\r\n<p>◎ 用户的代码挂起当前任务，比如线程执行sleep方法，让出CPU。</p>\r\n<p>◎ 硬件中断。</p>\r\n<p>美文佳句<br>人这一生，其实面临着很多选择。大到人生规划，小到日常生活，常常都不会尽善尽美。</p>\r\n<p>我们的每一个选择，无论后来怎样，至少在我们选择的那一刻，一定是符合我们当时的需求的。</p>\r\n<p>若选择之后，这山望着那山高，始终不满意自己的选择，一直惦记着其他选择，那只会让自己迷失在选择之中，错过今后更多的选择。</p>\r\n<p>很多时候，选择无关对错，也无关优差。既然选择了一条路，试探再多的分岔路口，也不如走好脚下这条路。</p>\r\n<p>曾看过这样一段话：生命怎么活都会有遗憾，关键在于你怎么去领悟，给这个遗憾的部分更崇高的向往，然后尊重、包容它，反而会把这个遗憾的部分变成一种生命力的圆满。</p>\r\n<p>所以，有遗憾不可怕，可怕的是把遗憾一直当遗憾。其实，你不必羡慕任何人的选择，能把自己选择的路走好，也是一种了不起的能力。</p>', '每日一句\r\nWhen I shiver with cold, not a snowflake is innocent. 当我冷得瑟瑟发抖时，没有一片雪花是无辜的。\r\n\r\n概述\r\nCPU 利用时间片轮询来为每个任务都服务一定的时间，然后把当前任务的状态保存下来，继续服务下一个任务。 任务的状态保存及再加载就叫做线程的上下文切换。\r\n\r\n1. 进程：指一个运行中的程序的实例。在一个进程内部可以有多个线程在同时运行，并与创建它的进程共享同一地址空间（一段内存区域）和其他资源\r\n\r\n2. 上下文：指线程切换时CPU寄存器和程序计数器所保存的当前线程的信息\r\n\r\n3. 寄存器：指CPU内部容量较小但速度很快的内存区域（与之对应的是CPU外部相对较慢的RAM主内存）。寄存器通过对常用值（通常是运算的中间值）的快速访问来加快计算机程序运行的速度\r\n\r\n4. 程序计数器：是一个专用的寄存器，用于表明指令序列中CPU正在执行的位置，存储的值为正在执行的指令的位置或者下一个将被执行的指令的位置，这依赖于特定的系统。\r\n\r\n上下文切换\r\n上下文切换指的是内核（操作系统的核心）在CPU上对进程或者线程进行切换。 上下文切换过程中的信息被保存在进程控制块（PCB-Process Control Block）中。PCB又被称作切换帧（SwitchFrame）。 上下文切换的信息会一直被保存在CPU的内存中，直到被再次使用。\r\n\r\n上下文切换流程如下：\r\n\r\n（1）挂起一个进程，将这个进程在CPU中的状态（上下文信息）存储于内存的PCB中。\r\n\r\n（2）在PCB中检索下一个进程的上下文并将其在CPU的寄存器中恢复。\r\n\r\n（3）跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行）并恢复该进程。\r\n\r\n时间片轮转方式使多个任务在同一CPU上的执行有了可能.\r\n\r\n引起线程上下文切换的原因\r\n引起线程上下文切换的原因如下。\r\n\r\n◎ 当前正在执行的任务完成，系统的CPU正常调度下一个任务。\r\n\r\n◎ 当前正在执行的任务遇到I/O等阻塞操作，调度器挂起此任务，继续调度下一个任务。\r\n\r\n◎ 多个任务并发抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续调度下一个任务。\r\n\r\n◎ 用户的代码挂起当前任务，比如线程执行sleep方法，让出CPU。\r\n\r\n◎ 硬件中断。\r\n\r\n美文佳句\r\n人这一生，其实面临着很多选择。大到人生规划，小到日常生活，常常都不会尽善尽美。\r\n\r\n我们的每一个选择，无论后来怎样，至少在我们选择的那一刻，一定是符合我们当时的需求的。\r\n\r\n若选择之后，这山望着那山高，始终不满意自己的选择，一直惦记着其他选择，那只会让自己迷失在选择之中，错过今后更多的选择。\r\n\r\n很多时候，选择无关对错，也无关优差。既然选择了一条路，试探再多的分岔路口，也不如走好脚下这条路。\r\n\r\n曾看过这样一段话：生命怎么活都会有遗憾，关键在于你怎么去领悟，给这个遗憾的部分更崇高的向往，然后尊重、包容它，反而会把这个遗憾的部分变成一种生命力的圆满。\r\n\r\n所以，有遗憾不可怕，可怕的是把遗憾一直当遗憾。其实，你不必羡慕任何人的选择，能把自己选择的路走好，也是一种了不起的能力。', '2021-12-21 01:45:05', 0, 'When I shiver with cold, not a snowflake is innocent. 当我冷得瑟瑟发抖时，没有一片雪花是无辜的。', '/static/img/rand/8.jpg', 'java 线程上下文切换', 0, 'post', 0, '2021-12-21 01:45:05', '1640072704', 30);
INSERT INTO `blog_article` VALUES (152, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>You cannot swim for new horizons until you have courage to lose sight of the shore.<br>除非有勇气离开岸边，否则你永远游不到彼岸。</p>\r\n<h1 id=\"-\">概念</h1>\r\n<p>IO 是主存和外部设备（硬盘、终端和网络等）拷贝数据的过程。IO是操作系统的底层功能实现，底层通过I/O指令进行完成。</p>\r\n<p>以下是5种类Unix下可用的I/O模型</p>\r\n<ol>\r\n<li><p>阻塞式I/O：Blocking IO</p>\r\n</li>\r\n<li><p>非阻塞式I/O：nonblocking IO</p>\r\n</li>\r\n<li><p>I/O 复用（Select，poll epoll）：IO multiplexing</p>\r\n</li>\r\n<li><p>信号驱动式I/O（SIGIO）：signal driven IO</p>\r\n</li>\r\n<li><p>异步 I/O（posix 的 aio 系列函数）：asynchromous IO</p>\r\n</li>\r\n</ol>\r\n<h1 id=\"blocking-io\">Blocking IO</h1>\r\n<p>在 Linux 中，默认情况下所有的 socket 都是 Blocking，一个典型的读操作流程大概是这样：</p>\r\n<ol>\r\n<li><p>通常涉及等待数据从网络到达。当所有等待数据到达时，它被复制到内核中的某个缓冲区</p>\r\n</li>\r\n<li><p>把数据从内核缓冲区复制到应用程序缓冲区</p>\r\n</li>\r\n</ol>\r\n<p>当用户进程调用了 recvfrom 这个系统调用， kernel 就开始了 IO 的第一个阶段：准备数据。对于 network IO 来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的 UDP 包）。这个时候 kernel 就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当 kernel 一直等到数据准备好了，它就会将数据从kernel 中拷贝到用户内存，然后kernel返回结果，用户进程才解除 block 的状态，重新运行起来。<br>所以，Blocking IO 的特点就是在IO执行的两个阶段都被 block了</p>\r\n<h1 id=\"-i-o\">非阻塞式I/O</h1>\r\n<p>Linux 下，可以用过设置 socket 使其变为 non-blocking。当对一个 non-blocking socket 执行操作时，流程如下：<br>从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。 从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次 发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。</p>\r\n<p>所以，用户进程第一个阶段不是阻塞的,需要不断的主动询问kernel数据好了没有；第二个阶段依然总是阻塞的。</p>\r\n<h1 id=\"io-nio-\">IO 多路复用（NIO）</h1>\r\n<p>select、epoll 的好处就在于单个 process 就可以同时处理多个网络链接的 IO。</p>\r\n<p>IO 复用和同步阻塞本质一样，不过利用了新的 Select 系统调用，由内核来负责本来是请求进程该做的轮训操作，看似不非阻塞IO还多了哥系统调用开销，不过因为支持多路IO才算提高了效率<br>也就是一个可以监听多个。<br>它的基本原理就是 select、epoll 这个 function会不断的轮询所负责的所有 socket，当某个 socket 有数据到达了，就通知用户进程。它的流程如下图：</p>\r\n<p>当用户线程调用select，那么整个进程会被阻塞，而同时，kernel会监视所有select负责的 socket =，当任何一个 socket 中的数据准备好了，select 就会返回，这个时候用户进程会调用 read 操作，将数据 kernel 拷贝到用户进程。<br>首先开启套接字的信号驱动式IO功能，并且通过sigaction(信号处理程序) 系统调用安装一个信号处理函数 ，该函数调用将立即返回，当前进程没有被阻塞 ，继续工作；当数据报准备好的时候，内核为该进程产生SIGIO 的信号，随后既可以在信号处理函数中调用recvfrom 读取数据报，并且通知主循环数据已经准备好等待处理；也可以直接通知主循环让它读取数据报；(其实就是一个待读取的通知和待处理的通知)，基本不会用到。</p>\r\n<h1 id=\"-io-aio-\">异步IO（AIO）</h1>\r\n<p>多线程和多进程的模型虽然解决了并发的问题，但是系统不能无限的增加线程，由于系统的切换线程的开销恒大，所以，一旦线程数量过多，CPU的时间就花在线程的切换上，正真运行代码的时间就会减少，结果导致性能严重下降</p>\r\n<p>由于我们要解决的问题是CPU高速执行能力和IO设备的龟速严重不匹配，多线程和多进程只是解决这一个问题的一种方法。<br>另一种解决IO问题的方法是异步IO，当代码需要执行一个耗时的IO操作时，他只发出IO指令，并不等待IO结果然后就去执行其他代码，一段时间后，当IO返回结果是，在通知CPU进行处理我们调用aio_read函数，给内核传递描述符，缓冲区指针，缓冲区大小，和文件偏移量，并且告诉内核当整个操作完成时如何通知我们，该函数调用后，立即返回，不会被阻塞</p>\r\n<p>另一方面：从kernel的角度，当他收到一个aio_read之后，首先它立即返回，所以不会对用户进程产生block，然后kernel会等待数据准备完成，然后将数据拷贝到用户内存（copy由内核完成），当着一切完成后，kernel会给用户进程发送一个singal或者执行下一个基于线程回调函数来完成此次IO处理过程，告诉他read操作完成</p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>岁月应是静好。近来，心神总是不宁，想必是被尘世间的诱惑所困。</p>\r\n<p>我想，要是远方的祥夫先生来到我这“梅知堂”，两人清茶一杯，盘腿而坐，或看他画梅，纸上的梅花仿佛兀自开在飞雪里，如是，那该是一幅怎样的墨梅图？</p>\r\n<p>昨晚，梦里看到那个戴着小黑圆眼镜的祥夫背着黄色的大包正往江南赶路。是又到了梅花开的日子了吗？</p>', '# 每日一句\r\nYou cannot swim for new horizons until you have courage to lose sight of the shore. \r\n除非有勇气离开岸边，否则你永远游不到彼岸。\r\n\r\n# 概念\r\n\r\nIO 是主存和外部设备（硬盘、终端和网络等）拷贝数据的过程。IO是操作系统的底层功能实现，底层通过I/O指令进行完成。\r\n\r\n以下是5种类Unix下可用的I/O模型\r\n\r\n1. 阻塞式I/O：Blocking IO\r\n\r\n2. 非阻塞式I/O：nonblocking IO\r\n\r\n3. I/O 复用（Select，poll epoll）：IO multiplexing\r\n\r\n4. 信号驱动式I/O（SIGIO）：signal driven IO\r\n\r\n5. 异步 I/O（posix 的 aio 系列函数）：asynchromous IO\r\n\r\n# Blocking IO\r\n\r\n在 Linux 中，默认情况下所有的 socket 都是 Blocking，一个典型的读操作流程大概是这样：\r\n\r\n1. 通常涉及等待数据从网络到达。当所有等待数据到达时，它被复制到内核中的某个缓冲区\r\n\r\n2. 把数据从内核缓冲区复制到应用程序缓冲区\r\n\r\n当用户进程调用了 recvfrom 这个系统调用， kernel 就开始了 IO 的第一个阶段：准备数据。对于 network IO 来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的 UDP 包）。这个时候 kernel 就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当 kernel 一直等到数据准备好了，它就会将数据从kernel 中拷贝到用户内存，然后kernel返回结果，用户进程才解除 block 的状态，重新运行起来。\r\n所以，Blocking IO 的特点就是在IO执行的两个阶段都被 block了\r\n\r\n# 非阻塞式I/O\r\n\r\nLinux 下，可以用过设置 socket 使其变为 non-blocking。当对一个 non-blocking socket 执行操作时，流程如下：\r\n从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。 从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次 发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。\r\n\r\n所以，用户进程第一个阶段不是阻塞的,需要不断的主动询问kernel数据好了没有；第二个阶段依然总是阻塞的。\r\n\r\n# IO 多路复用（NIO）\r\n\r\nselect、epoll 的好处就在于单个 process 就可以同时处理多个网络链接的 IO。\r\n\r\nIO 复用和同步阻塞本质一样，不过利用了新的 Select 系统调用，由内核来负责本来是请求进程该做的轮训操作，看似不非阻塞IO还多了哥系统调用开销，不过因为支持多路IO才算提高了效率\r\n也就是一个可以监听多个。\r\n它的基本原理就是 select、epoll 这个 function会不断的轮询所负责的所有 socket，当某个 socket 有数据到达了，就通知用户进程。它的流程如下图：\r\n\r\n当用户线程调用select，那么整个进程会被阻塞，而同时，kernel会监视所有select负责的 socket =，当任何一个 socket 中的数据准备好了，select 就会返回，这个时候用户进程会调用 read 操作，将数据 kernel 拷贝到用户进程。\r\n首先开启套接字的信号驱动式IO功能，并且通过sigaction(信号处理程序) 系统调用安装一个信号处理函数 ，该函数调用将立即返回，当前进程没有被阻塞 ，继续工作；当数据报准备好的时候，内核为该进程产生SIGIO 的信号，随后既可以在信号处理函数中调用recvfrom 读取数据报，并且通知主循环数据已经准备好等待处理；也可以直接通知主循环让它读取数据报；(其实就是一个待读取的通知和待处理的通知)，基本不会用到。\r\n\r\n# 异步IO（AIO）\r\n\r\n多线程和多进程的模型虽然解决了并发的问题，但是系统不能无限的增加线程，由于系统的切换线程的开销恒大，所以，一旦线程数量过多，CPU的时间就花在线程的切换上，正真运行代码的时间就会减少，结果导致性能严重下降\r\n\r\n由于我们要解决的问题是CPU高速执行能力和IO设备的龟速严重不匹配，多线程和多进程只是解决这一个问题的一种方法。\r\n另一种解决IO问题的方法是异步IO，当代码需要执行一个耗时的IO操作时，他只发出IO指令，并不等待IO结果然后就去执行其他代码，一段时间后，当IO返回结果是，在通知CPU进行处理我们调用aio_read函数，给内核传递描述符，缓冲区指针，缓冲区大小，和文件偏移量，并且告诉内核当整个操作完成时如何通知我们，该函数调用后，立即返回，不会被阻塞\r\n\r\n另一方面：从kernel的角度，当他收到一个aio_read之后，首先它立即返回，所以不会对用户进程产生block，然后kernel会等待数据准备完成，然后将数据拷贝到用户内存（copy由内核完成），当着一切完成后，kernel会给用户进程发送一个singal或者执行下一个基于线程回调函数来完成此次IO处理过程，告诉他read操作完成\r\n\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n岁月应是静好。近来，心神总是不宁，想必是被尘世间的诱惑所困。\r\n\r\n我想，要是远方的祥夫先生来到我这“梅知堂”，两人清茶一杯，盘腿而坐，或看他画梅，纸上的梅花仿佛兀自开在飞雪里，如是，那该是一幅怎样的墨梅图？\r\n\r\n昨晚，梦里看到那个戴着小黑圆眼镜的祥夫背着黄色的大包正往江南赶路。是又到了梅花开的日子了吗？', '2021-12-21 01:53:53', 0, '每日一句Youcannotswimfornewhorizonsuntilyouhavecourage', '/static/img/rand/4.jpg', 'java 5种IO模型', 0, 'post', 0, '2021-12-21 01:53:53', '1640073233', 20);
INSERT INTO `blog_article` VALUES (153, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>The snow whispers around me.<br>雪花萦绕在我耳边，窃窃私语。</p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>static 关键字主要有两个作用：</p>\r\n<p>第一，为某特定数据类型或对象分配单一的存储空间，而与创建对象的个数无关。</p>\r\n<p>第二，实现某个方法或属性与类而不是对象关联在一起，也就是说，在不创建对象的情况下就可以通过类来直接使用类的方法或者属性。</p>\r\n<h1 id=\"-\">可修饰的元素</h1>\r\n<ol>\r\n<li><p>变量：静态变量，可以跨越代码块访问</p>\r\n</li>\r\n<li><p>方法：静态方法，可以跨越代码块访问</p>\r\n</li>\r\n<li><p>代码块：静态代码块，只能定义在类定义下，在类被加载时执行</p>\r\n</li>\r\n<li><p>内部类：静态内部类，该类定义可以由外部类名引用。</p>\r\n</li>\r\n<li><p>导入包：静态导入包，导入指定的 static 变量</p>\r\n</li>\r\n</ol>\r\n<h1 id=\"-\">详细说明</h1>\r\n<p>static，静态，表示随着类的加载而加载，不会重复加载，执行顺序在 main方法之前。<br>在 JVM 内存中，static 修饰的变量存在于方法区中。JVM 内存区域</p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>爱是清晨六点钟，餐桌上爱人准备的早餐。爱是出行途中，公车上陌生人让出的座位。爱是当东西掉落，你却双手无暇时，后面有人随手捡起的善意。</p>\r\n<p>世人赠予善意与爱，我们唯有还以微笑，报以感恩。</p>\r\n<p>心中有大爱，可以容山海。心中有小爱，亦有花香来。</p>\r\n<p>心中有爱的人，无畏前路，不怕失去。对生活感恩，对他人感激，对万物有情，活得温暖有力量。</p>\r\n<p>如果说，房子只是用来容纳居住的地方，那么真正的家，则应该是用来安顿灵魂的栖处。</p>\r\n<p>或是在书海中徜徉知识，或是在旅途中遍尝风情，抑或是在草木间感受生机。当一个人的灵魂饱满了，有处可栖，心境也会随之变得通透清明，不再患得患失，亦不再漂泊无依。</p>\r\n<p>真情，可令时光温柔。热爱，可抵岁月漫长。如此，四海皆是家，心安即归处。</p>\r\n<p>最好的余生，便是：眼底有光，心中有爱，灵魂有家。</p>', '# 每日一句\r\nThe snow whispers around me. \r\n雪花萦绕在我耳边，窃窃私语。\r\n\r\n# 概述\r\n\r\nstatic 关键字主要有两个作用：\r\n\r\n第一，为某特定数据类型或对象分配单一的存储空间，而与创建对象的个数无关。\r\n\r\n第二，实现某个方法或属性与类而不是对象关联在一起，也就是说，在不创建对象的情况下就可以通过类来直接使用类的方法或者属性。\r\n\r\n# 可修饰的元素\r\n\r\n1. 变量：静态变量，可以跨越代码块访问\r\n\r\n2. 方法：静态方法，可以跨越代码块访问\r\n\r\n3. 代码块：静态代码块，只能定义在类定义下，在类被加载时执行\r\n\r\n4. 内部类：静态内部类，该类定义可以由外部类名引用。\r\n\r\n5. 导入包：静态导入包，导入指定的 static 变量\r\n\r\n# 详细说明\r\n\r\nstatic，静态，表示随着类的加载而加载，不会重复加载，执行顺序在 main方法之前。\r\n在 JVM 内存中，static 修饰的变量存在于方法区中。JVM 内存区域\r\n\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n爱是清晨六点钟，餐桌上爱人准备的早餐。爱是出行途中，公车上陌生人让出的座位。爱是当东西掉落，你却双手无暇时，后面有人随手捡起的善意。\r\n\r\n世人赠予善意与爱，我们唯有还以微笑，报以感恩。\r\n\r\n心中有大爱，可以容山海。心中有小爱，亦有花香来。\r\n\r\n心中有爱的人，无畏前路，不怕失去。对生活感恩，对他人感激，对万物有情，活得温暖有力量。\r\n\r\n如果说，房子只是用来容纳居住的地方，那么真正的家，则应该是用来安顿灵魂的栖处。\r\n\r\n或是在书海中徜徉知识，或是在旅途中遍尝风情，抑或是在草木间感受生机。当一个人的灵魂饱满了，有处可栖，心境也会随之变得通透清明，不再患得患失，亦不再漂泊无依。\r\n\r\n真情，可令时光温柔。热爱，可抵岁月漫长。如此，四海皆是家，心安即归处。\r\n\r\n最好的余生，便是：眼底有光，心中有爱，灵魂有家。', '2021-12-21 02:02:42', 0, '每日一句Thesnowwhispersaroundme.雪花萦绕在我耳边，窃窃私语。概述static', '/static/img/rand/12.jpg', 'static 关键字', 0, 'post', 0, '2021-12-21 02:02:42', '1640073762', 30);
INSERT INTO `blog_article` VALUES (154, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>What we call &quot;failure&quot; is not falling down, but the staying down.<br>所谓“失败”不是跌倒，而是就此躺平。</p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>数据类型的转换，分为自动转换和强制转换。自动转换是程序在执行过程中“悄然”进行的转换，不需要用户提前声明，一般是从位数低的类型向位数高的类型转换；强制类型转换则必须在代码中声明，转换顺序不受限制。</p>\r\n<h1 id=\"-\">自动数据类型转换</h1>\r\n<p>自动转换按从低到高的顺序转换。不同类型数据间的优先关系如下：</p>\r\n<pre><code class=\"lang-text\">低---------------------------------------------&gt;高\r\n<span class=\"hljs-keyword\">byte</span>,<span class=\"hljs-keyword\">short</span>,<span class=\"hljs-keyword\">char</span>-&gt; <span class=\"hljs-keyword\">int</span> -&gt; <span class=\"hljs-keyword\">long</span> -&gt; <span class=\"hljs-keyword\">float</span> -&gt; <span class=\"hljs-keyword\">double</span>\r\n</code></pre>\r\n<p>运算中，不同类型的数据先转化为同一类型，然后进行运算，转换规则如下：</p>\r\n<table>\r\n<thead>\r\n<tr>\r\n<th></th>\r\n<th></th>\r\n<th></th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr>\r\n<td>操作数1类型</td>\r\n<td>操作数2类型</td>\r\n<td>转换后的类型<br></td>\r\n</tr>\r\n<tr>\r\n<td>byte、short、char</td>\r\n<td>int</td>\r\n<td>int</td>\r\n</tr>\r\n<tr>\r\n<td>byte、short、char、int</td>\r\n<td>long</td>\r\n<td>long</td>\r\n</tr>\r\n<tr>\r\n<td>byte、short、char、int、long</td>\r\n<td>float</td>\r\n<td>float</td>\r\n</tr>\r\n<tr>\r\n<td>byte、short、char、int、long、float</td>\r\n<td>double</td>\r\n<td>double</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h1 id=\"-\">强制数据类型转换</h1>\r\n<p>强制转换的格式是在需要转型的数据前加上“( )”，然后在括号内加入需要转化的数据类型。有的数据经过转型运算后，精度会丢失，而有的会更加精确，下面的例子可以说明这个问题。</p>\r\n<pre><code class=\"lang-text\">publicclassDemo{\r\n    publicstaticvoidmain(String[] args){\r\n        <span class=\"hljs-keyword\">int</span> x;\r\n        <span class=\"hljs-keyword\">double</span> y;\r\n        x = (<span class=\"hljs-keyword\">int</span>)<span class=\"hljs-number\">34.56</span> + (<span class=\"hljs-keyword\">int</span>)<span class=\"hljs-number\">11.2</span>;  *<span class=\"hljs-comment\">// 丢失精度*</span>\r\n        y = (<span class=\"hljs-keyword\">double</span>)x + (<span class=\"hljs-keyword\">double</span>)<span class=\"hljs-number\">10</span> + <span class=\"hljs-number\">1</span>;  *<span class=\"hljs-comment\">// 提高精度*</span>\r\n        System.<span class=\"hljs-keyword\">out</span>.println(<span class=\"hljs-string\">\"x=\"</span> + x);\r\n        System.<span class=\"hljs-keyword\">out</span>.println(<span class=\"hljs-string\">\"y=\"</span> + y);\r\n    }\r\n}\r\n运行结果：\r\nx=<span class=\"hljs-number\">45</span>\r\ny=<span class=\"hljs-number\">56.0</span>\r\n</code></pre>\r\n<p>仔细分析上面程序段：由于在 34.56 前有一个 int 的强制类型转化，所以 34.56 就变成了 34。同样 11.2 就变成了 11 了，所以 x 的结果就是 45。在 x 前有一个 double 类型的强制转换，所以 x 的值变为 45.0，而 10 的前面也被强制成 double 类型，所以也变成 10.0，所以最后 y 的值变为 56。</p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>很多时候，事情的困境，常常是因为我们自己钻了牛角尖，此时，你需要做的就是改变。</p>\r\n<p>完美主义者可以放下执念，允许自己有普通人都会犯的小迷糊；职场妈妈可以直面现实，一个人永远做不到家庭和事业的双百分；承担了过多工作任务的员工，可以尝试向上级反映，寻求资源或调整目标……这些，都是我们应当并可以作出的改变。</p>\r\n<p>正如这句话所说：世界上从来都没有所谓的奇迹，命运一直都掌握在我们自己手里。想要改变自己的命运，最重要的就是改变自己。当你开始改变自己的时候，很多东西就跟着改变了。</p>\r\n<p>下一次，当烦恼降临时，不妨试试从自身找找问题。调整努力的方向和节奏，学会给心灵松绑，你会发现：很多事，其实没什么大不了。</p>', '# 每日一句\r\nWhat we call \"failure\" is not falling down, but the staying down. \r\n所谓“失败”不是跌倒，而是就此躺平。\r\n\r\n# 概述\r\n\r\n数据类型的转换，分为自动转换和强制转换。自动转换是程序在执行过程中“悄然”进行的转换，不需要用户提前声明，一般是从位数低的类型向位数高的类型转换；强制类型转换则必须在代码中声明，转换顺序不受限制。\r\n\r\n# 自动数据类型转换\r\n\r\n自动转换按从低到高的顺序转换。不同类型数据间的优先关系如下：\r\n\r\n```text\r\n低--------------------------------------------->高\r\nbyte,short,char-> int -> long -> float -> double\r\n```\r\n\r\n运算中，不同类型的数据先转化为同一类型，然后进行运算，转换规则如下：\r\n\r\n||||\r\n|-|-|-|\r\n|操作数1类型|操作数2类型|转换后的类型<br>|\r\n|byte、short、char|int|int|\r\n|byte、short、char、int|long|long|\r\n|byte、short、char、int、long|float|float|\r\n|byte、short、char、int、long、float|double|double|\r\n\r\n\r\n# 强制数据类型转换\r\n\r\n强制转换的格式是在需要转型的数据前加上“( )”，然后在括号内加入需要转化的数据类型。有的数据经过转型运算后，精度会丢失，而有的会更加精确，下面的例子可以说明这个问题。\r\n\r\n```text\r\npublicclassDemo{\r\n    publicstaticvoidmain(String[] args){\r\n        int x;\r\n        double y;\r\n        x = (int)34.56 + (int)11.2;  *// 丢失精度*\r\n        y = (double)x + (double)10 + 1;  *// 提高精度*\r\n        System.out.println(\"x=\" + x);\r\n        System.out.println(\"y=\" + y);\r\n    }\r\n}\r\n运行结果：\r\nx=45\r\ny=56.0\r\n```\r\n\r\n仔细分析上面程序段：由于在 34.56 前有一个 int 的强制类型转化，所以 34.56 就变成了 34。同样 11.2 就变成了 11 了，所以 x 的结果就是 45。在 x 前有一个 double 类型的强制转换，所以 x 的值变为 45.0，而 10 的前面也被强制成 double 类型，所以也变成 10.0，所以最后 y 的值变为 56。\r\n\r\n\r\n# 美文佳句\r\n\r\n很多时候，事情的困境，常常是因为我们自己钻了牛角尖，此时，你需要做的就是改变。\r\n\r\n完美主义者可以放下执念，允许自己有普通人都会犯的小迷糊；职场妈妈可以直面现实，一个人永远做不到家庭和事业的双百分；承担了过多工作任务的员工，可以尝试向上级反映，寻求资源或调整目标……这些，都是我们应当并可以作出的改变。\r\n\r\n正如这句话所说：世界上从来都没有所谓的奇迹，命运一直都掌握在我们自己手里。想要改变自己的命运，最重要的就是改变自己。当你开始改变自己的时候，很多东西就跟着改变了。\r\n\r\n下一次，当烦恼降临时，不妨试试从自身找找问题。调整努力的方向和节奏，学会给心灵松绑，你会发现：很多事，其实没什么大不了。', '2021-12-21 02:23:10', 0, '每日一句Whatwecall&quot;failure&quot;isnotfallingdown,', '/static/img/rand/13.jpg', '第24章 Java 数据类型转换', 0, 'post', 0, '2021-12-21 02:35:34', '1640074990', 30);
INSERT INTO `blog_article` VALUES (155, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>The frog in the well knows nothing of the great ocean.<br>井底之蛙，不知大海。</p>\r\n<h1 id=\"jvm-\">JVM 的类加载阶段</h1>\r\n<p>JVM 的类加载分为五个阶段：</p>\r\n<ol>\r\n<li><p>加载：被虚拟机读入内存</p>\r\n</li>\r\n<li><p>验证：验证 Class 字节流的数据是否遵守JVM的规定</p>\r\n</li>\r\n<li><p>准备：正式为类变量（静态变量）分配内存并设置初始值，并非代码中设置的值</p>\r\n</li>\r\n<li><p>解析：将常量池中的符号引用解析为直接引用</p>\r\n</li>\r\n<li><p>初始化：真正执行类中定义的java代码</p>\r\n</li>\r\n</ol>\r\n<h1 id=\"-\">加载</h1>\r\n<p>指 JVM 读取 class 文件，并且根据 Class 文件描述创建 java.lang.Class 对象的过程。</p>\r\n<p>类加载过程主要包含将 Class 文件读取到运行时区域的方法区内，在堆中创建 java.lang.Class 对象，并封装类在方法区的数据结构的过程。</p>\r\n<p>在读取 Class 文件是既可以通过文件的形式读取，也可以通过 jar 包、war 包读取，还可以通过代理自动生成 Class或其他方式读取</p>\r\n<h1 id=\"-\">验证</h1>\r\n<p>主要用于确保 Class 文件符合当前虚拟机的要求，保障虚拟机自身的安全，只有通过验证的 CLass 文件才能被 JVM 加载</p>\r\n<h1 id=\"-\">准备</h1>\r\n<p>主要工作是在方法区中为类变量分配内存空间并设置类中变量的初始值。<br>初始值指不同数据类型的默认值，这里需要注意 final 类型的变量和非final类型的变量在准备阶段的数据初始化过程不同</p>\r\n<p>例如一个成员变量定义如下：<br>public static long value = 1000;<br>在以上代码中，静态变量 value 在准备阶段的初始值是0，将 value 设置为 1000 的动作是在对象初始化时完成的，因为 JVM 在编译阶段会将静态变量的初始化操作定义在构造器中。<br>public static final int value = 1000;</p>\r\n<p>则JVM在编译阶段后会为final类型的变量value生成其对应的ConstantValue属性，虚拟机在准备阶段会根据ConstantValue属性将value赋值为1000。</p>\r\n<p>总结：静态变量会赋两次初值，准备阶段赋零值，初始化时赋用户设定值，而final变量会在准备阶段一次性赋值完毕</p>\r\n<h1 id=\"-\">解析</h1>\r\n<p>JVM 会将常量池中的符号引用替换为直接引用。</p>\r\n<h1 id=\"-\">初始化</h1>\r\n<p>主要通过执行类构造器的 <client> 方法为类进行初始化。</p>\r\n<p><client> 方法是在编译阶段由编译器自动收集类中静态语句和变量的赋值操作组成的。JVM规定，只有在父类的 <client> 方法都执行成功后，子类中的 <client> 方法才可以被执行。<br>在一个类中既没有静态变量赋值操作也没有静态语句块时，编译器不会为该类生成 <client> 方法。</p>\r\n<p>在发生以下几种情况时，JVM不会执行类的初始化流程：</p>\r\n<ol>\r\n<li><p>常量在编译时会将其常量值存入使用该常量的类的常量池中，该过程不需要调用常量所在的类，因此，不会触发该常量类的初始化。</p>\r\n</li>\r\n<li><p>在子类引用父类的静态字段时，不会触发子类的初始化，只会触发父类的初始化。</p>\r\n</li>\r\n<li><p>定义对象数组，不会触发父类的初始化</p>\r\n</li>\r\n<li><p>在使用类名获取 Class 对象时不会触发类的初始化</p>\r\n</li>\r\n<li><p>在使用 Class.forName 加载指定的类时，可以通过 initialize 参数设置是否需要对类进行初始化</p>\r\n</li>\r\n<li><p>在使用ClassLoader默认的loadClass方法加载类时不会触发该类的初始化。</p>\r\n</li>\r\n</ol>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>很多时候，事情的困境，常常是因为我们自己钻了牛角尖，此时，你需要做的就是改变。</p>\r\n<p>完美主义者可以放下执念，允许自己有普通人都会犯的小迷糊；职场妈妈可以直面现实，一个人永远做不到家庭和事业的双百分；承担了过多工作任务的员工，可以尝试向上级反映，寻求资源或调整目标……这些，都是我们应当并可以作出的改变。</p>\r\n<p>正如这句话所说：世界上从来都没有所谓的奇迹，命运一直都掌握在我们自己手里。想要改变自己的命运，最重要的就是改变自己。当你开始改变自己的时候，很多东西就跟着改变了。</p>\r\n<p>下一次，当烦恼降临时，不妨试试从自身找找问题。调整努力的方向和节奏，学会给心灵松绑，你会发现：很多事，其实没什么大不了。</p>', '# 每日一句\r\nThe frog in the well knows nothing of the great ocean. \r\n井底之蛙，不知大海。\r\n\r\n# JVM 的类加载阶段\r\n\r\nJVM 的类加载分为五个阶段：\r\n\r\n1. 加载：被虚拟机读入内存\r\n\r\n2. 验证：验证 Class 字节流的数据是否遵守JVM的规定\r\n\r\n3. 准备：正式为类变量（静态变量）分配内存并设置初始值，并非代码中设置的值\r\n\r\n4. 解析：将常量池中的符号引用解析为直接引用\r\n\r\n5. 初始化：真正执行类中定义的java代码\r\n\r\n# 加载\r\n\r\n指 JVM 读取 class 文件，并且根据 Class 文件描述创建 java.lang.Class 对象的过程。\r\n\r\n类加载过程主要包含将 Class 文件读取到运行时区域的方法区内，在堆中创建 java.lang.Class 对象，并封装类在方法区的数据结构的过程。\r\n\r\n在读取 Class 文件是既可以通过文件的形式读取，也可以通过 jar 包、war 包读取，还可以通过代理自动生成 Class或其他方式读取\r\n\r\n# 验证\r\n\r\n主要用于确保 Class 文件符合当前虚拟机的要求，保障虚拟机自身的安全，只有通过验证的 CLass 文件才能被 JVM 加载\r\n\r\n# 准备\r\n\r\n主要工作是在方法区中为类变量分配内存空间并设置类中变量的初始值。\r\n初始值指不同数据类型的默认值，这里需要注意 final 类型的变量和非final类型的变量在准备阶段的数据初始化过程不同\r\n\r\n例如一个成员变量定义如下：\r\npublic static long value = 1000;\r\n在以上代码中，静态变量 value 在准备阶段的初始值是0，将 value 设置为 1000 的动作是在对象初始化时完成的，因为 JVM 在编译阶段会将静态变量的初始化操作定义在构造器中。\r\npublic static final int value = 1000;\r\n\r\n则JVM在编译阶段后会为final类型的变量value生成其对应的ConstantValue属性，虚拟机在准备阶段会根据ConstantValue属性将value赋值为1000。\r\n\r\n总结：静态变量会赋两次初值，准备阶段赋零值，初始化时赋用户设定值，而final变量会在准备阶段一次性赋值完毕\r\n\r\n# 解析\r\n\r\nJVM 会将常量池中的符号引用替换为直接引用。\r\n\r\n# 初始化\r\n\r\n主要通过执行类构造器的 <client> 方法为类进行初始化。\r\n<client> 方法是在编译阶段由编译器自动收集类中静态语句和变量的赋值操作组成的。JVM规定，只有在父类的 <client> 方法都执行成功后，子类中的 <client> 方法才可以被执行。\r\n在一个类中既没有静态变量赋值操作也没有静态语句块时，编译器不会为该类生成 <client> 方法。\r\n\r\n \r\n在发生以下几种情况时，JVM不会执行类的初始化流程：\r\n  \r\n1. 常量在编译时会将其常量值存入使用该常量的类的常量池中，该过程不需要调用常量所在的类，因此，不会触发该常量类的初始化。\r\n  \r\n2. 在子类引用父类的静态字段时，不会触发子类的初始化，只会触发父类的初始化。\r\n  \r\n3. 定义对象数组，不会触发父类的初始化\r\n  \r\n4. 在使用类名获取 Class 对象时不会触发类的初始化\r\n  \r\n5. 在使用 Class.forName 加载指定的类时，可以通过 initialize 参数设置是否需要对类进行初始化\r\n  \r\n6. 在使用ClassLoader默认的loadClass方法加载类时不会触发该类的初始化。\r\n\r\n# 美文佳句\r\n\r\n很多时候，事情的困境，常常是因为我们自己钻了牛角尖，此时，你需要做的就是改变。\r\n\r\n完美主义者可以放下执念，允许自己有普通人都会犯的小迷糊；职场妈妈可以直面现实，一个人永远做不到家庭和事业的双百分；承担了过多工作任务的员工，可以尝试向上级反映，寻求资源或调整目标……这些，都是我们应当并可以作出的改变。\r\n\r\n正如这句话所说：世界上从来都没有所谓的奇迹，命运一直都掌握在我们自己手里。想要改变自己的命运，最重要的就是改变自己。当你开始改变自己的时候，很多东西就跟着改变了。\r\n\r\n下一次，当烦恼降临时，不妨试试从自身找找问题。调整努力的方向和节奏，学会给心灵松绑，你会发现：很多事，其实没什么大不了。', '2021-12-21 02:41:14', 0, '每日一句Thefroginthewellknowsnothingofthegreatocean.井底', '/static/img/rand/18.jpg', '第25章 JVM的类加载过程', 0, 'post', 0, '2021-12-21 02:41:14', '1640076074', 40);
INSERT INTO `blog_article` VALUES (156, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>Hope is for some sort of looking forward to the future glory.<br>希望是对未来荣耀的某种期待。 </p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>光阴似箭催人老，光阴如骏赶少年，转眼间2021已成为过去式，2022年的大门已向我们敞开。在新年尹始，祝大家大吉大利。</p>\r\n<h1 id=\"-\">回顾</h1>\r\n<p>我们都是平凡人，却有着不甘平凡的心。回顾过去，有收获，有不足。</p>\r\n<h2 id=\"-\">博客</h2>\r\n<p>这一年来里，重新搭建了博客，买了一个新域名 ylcoder.top 。定位技术知识体系搭建。<br>下半年开始了新的博客计划，使用 openWrite 推送到各大博客平台，每天一篇，目前已有三十篇了。</p>\r\n<h2 id=\"-\">公众号</h2>\r\n<p>公众号其实2017年就申请了，在此期间一直断断续续的发文。今年重新拾起，开始建立自己的技术影响力。人总要有点自己的追求。<br>这一年里，关注人数终于突破500，开通了流量主，能在写文章的同时还有一点微薄收入，这样已经很好了。</p>\r\n<h2 id=\"-\">小程序</h2>\r\n<p>其实很久之前就关注小程序了，只不过一直没时间去研究，哈哈这是借口。<br>这一年里，我在哔哩哔哩-尚大学完了入门课程，自己搭建了一个小程序，目前已经发布上线，可喜可贺。</p>\r\n<h2 id=\"github\">github</h2>\r\n<p>已经连续三年有一定的提交记录了，希望继续保持。</p>\r\n<h2 id=\"-\">工作</h2>\r\n<p>离开了工作两年多的公司，感谢相遇，在这里学到了很多技术之外的东西，有关相处、职场、团队、运营，后会有期。</p>\r\n<h2 id=\"-\">生活</h2>\r\n<p>这一年里，买了房，订了车，就只剩下感情了。这也是自己一直处理不好的地方。人的情感是最复杂的，希望陪我走到最后的是你，就这样了。</p>\r\n<h2 id=\"-\">数据结构与算法</h2>\r\n<p>这部分是我重视的内容，但是一直完成的不好。在大学期间ACM接触算法后就一直断断续续的练习算法，一直无法达到我想要的效果。</p>\r\n<h2 id=\"-\">健身、练字、英语和早起</h2>\r\n<p>这部分做的也不是很好啊，老大难了。</p>\r\n<ol>\r\n<li>英语练习了那么久还是无法熟练的用英语表达出来。</li>\r\n<li>早起，这是我定的目标吗？诶，起不来啊 真难受。</li>\r\n</ol>\r\n<p>诶，来年继续加油吧。</p>\r\n<h2 id=\"-\">出书</h2>\r\n<p>哈哈，这是未来的计划之一，目前在github上是开放的很多都是我的读书笔记，以及半成品的电子书。</p>\r\n<p>我非常希望能够自己出版书籍，一本就好啊。</p>\r\n<h2 id=\"-\">总结</h2>\r\n<p>感谢这一年里的各位朋友，回首2021，学到很多。很喜欢这种学习的状态，2022希望继续保持下去。</p>\r\n<h1 id=\"-\">展望</h1>\r\n<p>我回忆过去，但更向往未来。让我的未来充满鸟语，布满新绿，注定收获，洋溢温馨。</p>\r\n<p>我希望来年能够做到：</p>\r\n<ol>\r\n<li>加强数据结构与算法的训练，尽快拿出一定的成果 </li>\r\n<li>加快读书笔记整理的进度，加快电子书的进度，争取整理至少一本电子书，不出书也没关系哦。</li>\r\n<li>希望工资double，快乐加倍，哈哈</li>\r\n<li>希望公众号关注数更上一层楼，5000还是一万。听过一万的关注是公众号的生命线，是真的吗？</li>\r\n<li>开源更多的项目，保持github的提交记录</li>\r\n<li>新技术的学习，人工智能、元宇宙。哈哈，太多了，走一步看三步吧。</li>\r\n</ol>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>似乎只是一夜风、一场雨，便暑去凉至，忽然秋天。沐浴在通透明丽的秋阳下，有几件渴望已久的事想要去做。</p>\r\n<p>秋来了，我并无什么惊天动地的大事可为，却有许多细碎平淡的小事想做。想做就去做，秋天短暂，不等人的。做到了，那便是人生乐事，幸福着呢！</p>', '# 每日一句\r\nHope is for some sort of looking forward to the future glory.\r\n希望是对未来荣耀的某种期待。 \r\n\r\n# 概述\r\n\r\n光阴似箭催人老，光阴如骏赶少年，转眼间2021已成为过去式，2022年的大门已向我们敞开。在新年尹始，祝大家大吉大利。\r\n\r\n\r\n# 回顾\r\n\r\n我们都是平凡人，却有着不甘平凡的心。回顾过去，有收获，有不足。\r\n\r\n## 博客\r\n\r\n这一年来里，重新搭建了博客，买了一个新域名 ylcoder.top 。定位技术知识体系搭建。\r\n下半年开始了新的博客计划，使用 openWrite 推送到各大博客平台，每天一篇，目前已有三十篇了。\r\n\r\n## 公众号\r\n\r\n公众号其实2017年就申请了，在此期间一直断断续续的发文。今年重新拾起，开始建立自己的技术影响力。人总要有点自己的追求。\r\n这一年里，关注人数终于突破500，开通了流量主，能在写文章的同时还有一点微薄收入，这样已经很好了。\r\n\r\n## 小程序\r\n\r\n其实很久之前就关注小程序了，只不过一直没时间去研究，哈哈这是借口。\r\n这一年里，我在哔哩哔哩-尚大学完了入门课程，自己搭建了一个小程序，目前已经发布上线，可喜可贺。\r\n\r\n## github\r\n\r\n已经连续三年有一定的提交记录了，希望继续保持。\r\n\r\n## 工作\r\n\r\n离开了工作两年多的公司，感谢相遇，在这里学到了很多技术之外的东西，有关相处、职场、团队、运营，后会有期。\r\n\r\n## 生活\r\n\r\n这一年里，买了房，订了车，就只剩下感情了。这也是自己一直处理不好的地方。人的情感是最复杂的，希望陪我走到最后的是你，就这样了。\r\n\r\n\r\n## 数据结构与算法\r\n\r\n这部分是我重视的内容，但是一直完成的不好。在大学期间ACM接触算法后就一直断断续续的练习算法，一直无法达到我想要的效果。\r\n\r\n## 健身、练字、英语和早起\r\n\r\n这部分做的也不是很好啊，老大难了。\r\n\r\n1. 英语练习了那么久还是无法熟练的用英语表达出来。\r\n2. 早起，这是我定的目标吗？诶，起不来啊 真难受。\r\n\r\n诶，来年继续加油吧。\r\n\r\n## 出书\r\n\r\n哈哈，这是未来的计划之一，目前在github上是开放的很多都是我的读书笔记，以及半成品的电子书。\r\n\r\n我非常希望能够自己出版书籍，一本就好啊。\r\n\r\n## 总结\r\n\r\n感谢这一年里的各位朋友，回首2021，学到很多。很喜欢这种学习的状态，2022希望继续保持下去。\r\n\r\n\r\n# 展望 \r\n\r\n我回忆过去，但更向往未来。让我的未来充满鸟语，布满新绿，注定收获，洋溢温馨。\r\n\r\n我希望来年能够做到：\r\n1. 加强数据结构与算法的训练，尽快拿出一定的成果 \r\n2. 加快读书笔记整理的进度，加快电子书的进度，争取整理至少一本电子书，不出书也没关系哦。\r\n3. 希望工资double，快乐加倍，哈哈\r\n4. 希望公众号关注数更上一层楼，5000还是一万。听过一万的关注是公众号的生命线，是真的吗？\r\n5. 开源更多的项目，保持github的提交记录\r\n6. 新技术的学习，人工智能、元宇宙。哈哈，太多了，走一步看三步吧。\r\n\r\n# 美文佳句\r\n\r\n似乎只是一夜风、一场雨，便暑去凉至，忽然秋天。沐浴在通透明丽的秋阳下，有几件渴望已久的事想要去做。\r\n\r\n秋来了，我并无什么惊天动地的大事可为，却有许多细碎平淡的小事想做。想做就去做，秋天短暂，不等人的。做到了，那便是人生乐事，幸福着呢！', '2021-12-31 04:48:49', 0, '每日一句Hopeisforsomesortoflookingforwardtothefuturegl', '/static/img/rand/12.jpg', '2021再见，2022你好', 0, 'post', 0, '2021-12-31 04:48:49', '1640947728', 40);
INSERT INTO `blog_article` VALUES (158, NULL, '<h1>Hello blog!</h1>\n<p>欢迎使用blog进行创作，删除这篇文章后赶紧开始吧。</p>', '# Hello blog!\n欢迎使用blog进行创作，删除这篇文章后赶紧开始吧。', '2022-01-02 08:19:51', 2, '欢迎使用blog进行创作，删除这篇文章后赶紧开始吧。', '/static/img/rand/16.jpg', 'Hello blog!', 0, 'post', 0, '2022-01-02 08:19:51', 'hello-blog', NULL);
INSERT INTO `blog_article` VALUES (160, 9, '<h1 id=\"-mk-\">随机获取指定数量的MK面试题</h1>\r\n<ul>\r\n<li>请求方式：GET</li>\r\n<li>URL：<a href=\"https://www.ylcoder.top/api/random/getmk?nums=3\">https://www.ylcoder.top/api/random/getmk?nums=3</a></li>\r\n</ul>\r\n<h1 id=\"-html-\">随机获取指定数量的HTML面试题</h1>\r\n<ul>\r\n<li>请求方式：GET</li>\r\n<li>URL：<a href=\"https://www.ylcoder.top/api/random/getpage?nums=3\">https://www.ylcoder.top/api/random/getpage?nums=3</a></li>\r\n</ul>', '# 随机获取指定数量的MK面试题\r\n* 请求方式：GET\r\n* URL：https://www.ylcoder.top/api/random/getmk?nums=3\r\n\r\n# 随机获取指定数量的HTML面试题\r\n* 请求方式：GET\r\n* URL：https://www.ylcoder.top/api/random/getpage?nums=3', '2022-01-17 03:59:37', 0, NULL, '/static/img/rand/6.jpg', '开放API接口', NULL, 'page', 0, '2022-01-17 04:01:03', 'api', NULL);
INSERT INTO `blog_article` VALUES (161, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>Sometimes your whole life boils down to one insane move.<br>人一生中出人头地的机会不多，一旦有了一定要抓住！</p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>默认情况下，MongoDB实例启动运行时是没有启用用户访问权限控制的，也就是说，在实例本机服务器上都可以随意连接到实例进行各种操作，MongoDB不会对连接客户端进行用户验证，这是非常危险的。</p>\r\n<p>可以通过以下的几种方式来保障 MongoDB的安全：</p>\r\n<ul>\r\n<li>使用新的端口，默认的 27017 端口如果一旦知道了IP就能连接上，不太安全</li>\r\n<li>设置MongoDB的网络环境。最好将MongoDB部署到公司服务器内网，这样外网是访问不到的。公司内部访问使用VPN等。</li>\r\n<li>开启安全认证。认证要同时设置服务器之间的内部认证方式，同时设置客户端连接到集群的账号密码认证方式。</li>\r\n</ul>\r\n<p>为了强制开启用户访问控制（用户验证），则需要在MongoDB实例启动时使用选项 <code>--auth</code> 或在指定启动配置文件中添加选项 <code>auth=true</code></p>\r\n<h1 id=\"-\">相关概念</h1>\r\n<h2 id=\"-\">启动访问控制</h2>\r\n<p>MongoDB使用的是基于角色的访问控制（Role-Based-Access-Control，RBAC）来管理用户对实例的访问。通过对用户授予一个或多个角色来控制用户访问数据库资源的权限和数据库操作的权限，在对用户分配角色之前，用户无法访问实例。</p>\r\n<h2 id=\"-\">角色</h2>\r\n<p>在MongoDB中通过角色对用户授予相应数据库资源的操作权限。每个角色当中的权限可以显式指定，也可以通过继承其他角色的权限，或者两者都存在的权限。</p>\r\n<h2 id=\"-\">权限</h2>\r\n<p>权限由指定的数据库资源（resource）以及允许在指定资源上进行的操作（action）组成。</p>\r\n<ul>\r\n<li>资源（resource）：数据库、集合、部分集合和集群</li>\r\n<li>操作（action）：对资源进行的增、删、改、查（CRUD）操作</li>\r\n</ul>\r\n<h1 id=\"-\">角色</h1>\r\n<p>在角色定义时可以包含一个或多个已存在的角色，新创建的角色会继承包含的角色所有的权限。在同一个数据库中，新创建角色可以继承其他角色的权限，在 admin 数据库中创建的角色可以继承在其它任意数据库中角色的权限。</p>\r\n<h2 id=\"-\">角色相关命令</h2>\r\n<pre><code class=\"lang-PowerShell\"># 查询所有角色权限(仅用户自定义角色)\r\n<span class=\"hljs-selector-tag\">db</span><span class=\"hljs-selector-class\">.runCommand</span>({ <span class=\"hljs-attribute\">rolesInfo</span>: <span class=\"hljs-number\">1</span> })\r\n\r\n# 查询所有角色权限（包含内置角色）\r\n<span class=\"hljs-selector-tag\">db</span><span class=\"hljs-selector-class\">.runCommand</span>({ <span class=\"hljs-attribute\">rolesInfo</span>: <span class=\"hljs-number\">1</span>, showBuiltinRoles: true })\r\n\r\n# 查询当前数据库中的某角色的权限\r\n<span class=\"hljs-selector-tag\">db</span><span class=\"hljs-selector-class\">.runCommand</span>({ <span class=\"hljs-attribute\">rolesInfo</span>: <span class=\"hljs-string\">\"&lt;rolename&gt;\"</span> })\r\n\r\n# 查询其它数据库中指定的角色权限\r\n<span class=\"hljs-selector-tag\">db</span><span class=\"hljs-selector-class\">.runCommand</span>({ <span class=\"hljs-attribute\">rolesInfo</span>: { role: <span class=\"hljs-string\">\"&lt;rolename&gt;\"</span>, db: <span class=\"hljs-string\">\"&lt;database&gt;\"</span> } }\r\n\r\n# 查询多个角色权限\r\n<span class=\"hljs-selector-tag\">db</span><span class=\"hljs-selector-class\">.runCommand</span>( { <span class=\"hljs-attribute\">rolesInfo</span>: [ <span class=\"hljs-string\">\"&lt;rolename&gt;\"</span>, { role: <span class=\"hljs-string\">\"&lt;rolename&gt;\"</span>, db: <span class=\"hljs-string\">\"&lt;database&gt;\"</span> }, ... ] } )\r\n</code></pre>\r\n<h2 id=\"-\">常用的内置角色：</h2>\r\n<ul>\r\n<li>数据库用户角色：<code>read</code> 、<code>readWrite</code></li>\r\n<li>所有数据库用户角色：<code>readAnyDatabase</code>、<code>readWriteAnyDatabase</code>、<code>userAdminAnyDatabase</code>、<code>dbAdminAnyDatabase</code></li>\r\n<li>数据库管理角色：<code>dbAdmin</code>、<code>dbOwner</code>、<code>userAdmin</code>；</li>\r\n<li>集群管理角色：<code>clusterAdmin</code>、<code>clusterManager</code>、<code>clusterMonitor</code>、<code>hostManager</code>；</li>\r\n<li>备份恢复角色：<code>backup</code>、<code>restore</code>；</li>\r\n<li>超级用户角色：<code>root</code></li>\r\n<li>内部角色：<code>system</code></li>\r\n</ul>\r\n<p><strong>角色说明</strong>：</p>\r\n<table>\r\n<thead>\r\n<tr>\r\n<th></th>\r\n<th></th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr>\r\n<td><strong>角色</strong></td>\r\n<td><strong>权限描述</strong></td>\r\n</tr>\r\n<tr>\r\n<td>read</td>\r\n<td>可以读取指定数据库中任何数据。</td>\r\n</tr>\r\n<tr>\r\n<td>readWrite</td>\r\n<td>可以读写指定数据库中任何数据，包括创建、重命名、删除集合。</td>\r\n</tr>\r\n<tr>\r\n<td>readAnyDatabase</td>\r\n<td>可以读取所有数据库中任何数据(除了数据库confifig和local之外)。</td>\r\n</tr>\r\n<tr>\r\n<td>readWriteAnyDatabase</td>\r\n<td>可以读写所有数据库中任何数据(除了数据库confifig和local之外)。</td>\r\n</tr>\r\n<tr>\r\n<td>userAdminAnyDatabase</td>\r\n<td>可以在指定数据库创建和修改用户(除了数据库confifig和local之外)。</td>\r\n</tr>\r\n<tr>\r\n<td>dbAdminAnyDatabase</td>\r\n<td>可以读取任何数据库以及对数据库进行清理、修改、压缩、获取统计信息、执行检查等操作(除了数据库confifig和local之外)。</td>\r\n</tr>\r\n<tr>\r\n<td>dbAdmin</td>\r\n<td>可以读取指定数据库以及对数据库进行清理、修改、压缩、获取统计信息、执行检查等操作。</td>\r\n</tr>\r\n<tr>\r\n<td>userAdmin</td>\r\n<td>可以在指定数据库创建和修改用户。</td>\r\n</tr>\r\n<tr>\r\n<td>clusterAdmin</td>\r\n<td>可以对整个集群或数据库系统进行管理操作。</td>\r\n</tr>\r\n<tr>\r\n<td>backup</td>\r\n<td>备份MongoDB数据最小的权限。</td>\r\n</tr>\r\n<tr>\r\n<td>restore</td>\r\n<td>从备份文件中还原恢复MongoDB数据(除了system.profifile集合)的权限。</td>\r\n</tr>\r\n<tr>\r\n<td>root</td>\r\n<td>超级账号，超级权限</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>人生其实就像一场旅行，不必在乎目的地，在乎的是沿途的风景以及看风景的心情。忙碌的生活中懂得适时停下脚步欣赏一路走来的风景，是一种享受，是一种需要，是一种智慧，更是一种对待人生的态度。</p>\r\n<p>花随风落，雨伴云晴，过客匆匆，相逢有期。路过的风景，经过的往事，放在心间就好。感恩生活的所有，珍惜所有的有缘人，努力让自己活得更幸福快乐一点。</p>', '# 每日一句\r\nSometimes your whole life boils down to one insane move. \r\n人一生中出人头地的机会不多，一旦有了一定要抓住！\r\n\r\n# 概述\r\n\r\n默认情况下，MongoDB实例启动运行时是没有启用用户访问权限控制的，也就是说，在实例本机服务器上都可以随意连接到实例进行各种操作，MongoDB不会对连接客户端进行用户验证，这是非常危险的。\r\n\r\n\r\n\r\n可以通过以下的几种方式来保障 MongoDB的安全：\r\n\r\n- 使用新的端口，默认的 27017 端口如果一旦知道了IP就能连接上，不太安全\r\n- 设置MongoDB的网络环境。最好将MongoDB部署到公司服务器内网，这样外网是访问不到的。公司内部访问使用VPN等。\r\n- 开启安全认证。认证要同时设置服务器之间的内部认证方式，同时设置客户端连接到集群的账号密码认证方式。\r\n\r\n\r\n\r\n为了强制开启用户访问控制（用户验证），则需要在MongoDB实例启动时使用选项 `--auth` 或在指定启动配置文件中添加选项 `auth=true`\r\n\r\n\r\n\r\n# 相关概念\r\n\r\n## 启动访问控制\r\n\r\nMongoDB使用的是基于角色的访问控制（Role-Based-Access-Control，RBAC）来管理用户对实例的访问。通过对用户授予一个或多个角色来控制用户访问数据库资源的权限和数据库操作的权限，在对用户分配角色之前，用户无法访问实例。\r\n\r\n## 角色\r\n\r\n在MongoDB中通过角色对用户授予相应数据库资源的操作权限。每个角色当中的权限可以显式指定，也可以通过继承其他角色的权限，或者两者都存在的权限。\r\n\r\n## 权限\r\n\r\n权限由指定的数据库资源（resource）以及允许在指定资源上进行的操作（action）组成。\r\n\r\n- 资源（resource）：数据库、集合、部分集合和集群\r\n- 操作（action）：对资源进行的增、删、改、查（CRUD）操作\r\n\r\n\r\n\r\n# 角色\r\n\r\n在角色定义时可以包含一个或多个已存在的角色，新创建的角色会继承包含的角色所有的权限。在同一个数据库中，新创建角色可以继承其他角色的权限，在 admin 数据库中创建的角色可以继承在其它任意数据库中角色的权限。\r\n\r\n\r\n\r\n## 角色相关命令\r\n\r\n```PowerShell\r\n# 查询所有角色权限(仅用户自定义角色)\r\ndb.runCommand({ rolesInfo: 1 })\r\n\r\n# 查询所有角色权限（包含内置角色）\r\ndb.runCommand({ rolesInfo: 1, showBuiltinRoles: true })\r\n\r\n# 查询当前数据库中的某角色的权限\r\ndb.runCommand({ rolesInfo: \"<rolename>\" })\r\n\r\n# 查询其它数据库中指定的角色权限\r\ndb.runCommand({ rolesInfo: { role: \"<rolename>\", db: \"<database>\" } }\r\n\r\n# 查询多个角色权限\r\ndb.runCommand( { rolesInfo: [ \"<rolename>\", { role: \"<rolename>\", db: \"<database>\" }, ... ] } )\r\n\r\n```\r\n\r\n\r\n\r\n## 常用的内置角色：\r\n\r\n- 数据库用户角色：`read` 、`readWrite`\r\n- 所有数据库用户角色：`readAnyDatabase`、`readWriteAnyDatabase`、`userAdminAnyDatabase`、`dbAdminAnyDatabase`\r\n- 数据库管理角色：`dbAdmin`、`dbOwner`、`userAdmin`；\r\n- 集群管理角色：`clusterAdmin`、`clusterManager`、`clusterMonitor`、`hostManager`；\r\n- 备份恢复角色：`backup`、`restore`；\r\n- 超级用户角色：`root`\r\n- 内部角色：`system`\r\n\r\n**角色说明**：\r\n\r\n|||\r\n|-|-|\r\n|**角色**|**权限描述**|\r\n|read|可以读取指定数据库中任何数据。|\r\n|readWrite|可以读写指定数据库中任何数据，包括创建、重命名、删除集合。|\r\n|readAnyDatabase|可以读取所有数据库中任何数据(除了数据库confifig和local之外)。|\r\n|readWriteAnyDatabase|可以读写所有数据库中任何数据(除了数据库confifig和local之外)。|\r\n|userAdminAnyDatabase|可以在指定数据库创建和修改用户(除了数据库confifig和local之外)。|\r\n|dbAdminAnyDatabase|可以读取任何数据库以及对数据库进行清理、修改、压缩、获取统计信息、执行检查等操作(除了数据库confifig和local之外)。|\r\n|dbAdmin|可以读取指定数据库以及对数据库进行清理、修改、压缩、获取统计信息、执行检查等操作。|\r\n|userAdmin|可以在指定数据库创建和修改用户。|\r\n|clusterAdmin|可以对整个集群或数据库系统进行管理操作。|\r\n|backup|备份MongoDB数据最小的权限。|\r\n|restore|从备份文件中还原恢复MongoDB数据(除了system.profifile集合)的权限。|\r\n|root|超级账号，超级权限|\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n人生其实就像一场旅行，不必在乎目的地，在乎的是沿途的风景以及看风景的心情。忙碌的生活中懂得适时停下脚步欣赏一路走来的风景，是一种享受，是一种需要，是一种智慧，更是一种对待人生的态度。\r\n\r\n花随风落，雨伴云晴，过客匆匆，相逢有期。路过的风景，经过的往事，放在心间就好。感恩生活的所有，珍惜所有的有缘人，努力让自己活得更幸福快乐一点。', '2022-01-18 21:40:06', 0, '每日一句Sometimesyourwholelifeboilsdowntooneinsanemove', '/static/img/rand/14.jpg', 'MongoDB 安全认证', 0, 'post', 0, '2022-01-18 21:40:06', '1642563605', NULL);
INSERT INTO `blog_article` VALUES (162, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>Medalist don&#39;t grow on trees， you have to nurture them with love, with hard work, with dedication.<br>金牌选手不会从天而降，你必须用热爱、刻苦和投入来浇灌他们。</p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>分片（sharding）是一种垮多台机器分布数据的方法，MongoDB使用分片来支持具有非常大的数据集和高吞吐量操作的部署。</p>\r\n<p>分片(sharding)是指将数据拆分，将其分散存在不同的机器上的过程。有时也用分区(partitioning)来表示这个概念。将数据分散到不同的机器上，不需要功能强大的大型计算机就可以储存更多的数据，处理更多的负载。</p>\r\n<p>具有大型数据集或高吞吐量应用程序的数据库系统可以会挑战单个服务器的容量。例如，高查询率会耗尽服务器的CPU容量。工作集大小大于系统的RAM会强调磁盘驱动器的I / O容量。</p>\r\n<p>有两种解决系统增长的方法：垂直扩展和水平扩展。</p>\r\n<ul>\r\n<li>垂直扩展意味着增加单个服务器的容量，例如使用更强大的CPU，添加更多RAM或增加存储空间量。可用技术的局限性可能会限制单个机器对于给定工作负载而言足够强大。此外，基于云的提供商基于可用的硬件配置具有硬性上限。结果，垂直缩放有实际的最大值。</li>\r\n<li>水平扩展意味着划分系统数据集并加载多个服务器，添加其他服务器以根据需要增加容量。虽然单个机器的总体速度或容量可能不高，但每台机器处理整个工作负载的子集，可能提供比单个高速大容量服务器更高的效率。扩展部署容量只需要根据需要添加额外的服务器，这可能比单个机器的高端硬件的总体成本更低。MongoDB支持通过分片进行水平扩展。</li>\r\n</ul>\r\n<h1 id=\"-\">组件</h1>\r\n<p>MongoDB分片群集包含以下组件：</p>\r\n<ul>\r\n<li>分片（存储）：每个分片包含分片数据的子集。每个分片都可以部署为副本集。</li>\r\n<li>Mongos（路由）：mongos充当查询路由器，在客户端应用程序和分片集群之间提供接口。</li>\r\n<li>config servers：配置服务器存储集群的元数据和配置设置。从MongoDB3.4开始，必须将配置服务器部署为副本集（CSRS）</li>\r\n</ul>\r\n<p>下图描述了分片集群中组件的交互：</p>\r\n<p>MongoDB在集合级别对数据进行分片，将集合数据分布在集群中的分片上。</p>\r\n<h1 id=\"-\">实例</h1>\r\n<p>两个分片节点副本集（3+3）+一个配置节点副本集（3）+两个路由节点（2），共11个服务节点。</p>\r\n<h2 id=\"-\">分片节点副本集的创建</h2>\r\n<p>所有的的配置文件都直接放到 sharded_cluster 的相应的子目录下面，默认配置文件名字：mongod.conf</p>\r\n<h3 id=\"-\">第一套副本集</h3>\r\n<p>1 准备存放数据和日志的目录</p>\r\n<pre><code><span class=\"hljs-comment\">#-----------myshardrs01 </span>\r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27018/<span class=\"hljs-keyword\">log</span> \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27018/data/db \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27118/<span class=\"hljs-keyword\">log</span> \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27118/data/db \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27218/<span class=\"hljs-keyword\">log</span> \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27218/data/db\r\n</code></pre><p>2 新建或修改配置文件：<code>vim /mongodb/sharded_cluster/myshardrs01_27018/mongod.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27018/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27018/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27018/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27018 \r\nreplication: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">副本集的名称 </span>\r\n  replSetName: myshardrs01 \r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">分片角色 </span>\r\n  clusterRole: shardsvr\r\n</code></pre><p>sharding.clusterRole：</p>\r\n<table>\r\n<thead>\r\n<tr>\r\n<th></th>\r\n<th></th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr>\r\n<td>Value</td>\r\n<td>Description</td>\r\n</tr>\r\n<tr>\r\n<td>configsvr</td>\r\n<td>Start this instance as a <a href=\"https://docs.mongodb.com/manual/reference/glossary/#term-config-server\">config server</a>. The instance starts on port 27019 by default.</td>\r\n</tr>\r\n<tr>\r\n<td>shardsvr</td>\r\n<td>Start this instance as a <a href=\"https://docs.mongodb.com/manual/reference/glossary/#term-shard\">shard</a>. The instance starts on port 27018 by default.</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<p>注意：</p>\r\n<p>设置sharding.clusterRole需要mongod实例运行复制。 要将实例部署为副本集成员，请使用</p>\r\n<p>replSetName设置并指定副本集的名称。</p>\r\n<p>3 新建或修改配置文件: <code>vim /mongodb/sharded_cluster/myshardrs01_27118/mongod.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27118/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27118/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27118/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27118 \r\nreplication: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">副本集的名称 </span>\r\n  replSetName: myshardrs01 \r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">分片角色 </span>\r\n  clusterRole: shardsvr\r\n</code></pre><p>4 新建或修改配置文件: <code>vim /mongodb/sharded_cluster/myshardrs01_27218/mongod.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27218/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27218/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27218/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27218 \r\nreplication: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">副本集的名称 </span>\r\n  replSetName: myshardrs01 \r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">分片角色 </span>\r\n  clusterRole: shardsvr\r\n</code></pre><p>5 启动第一套副本集：一主一副本一仲裁</p>\r\n<p>依次启动三个mongod服务:</p>\r\n<pre><code>/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/myshardrs01_27018/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/myshardrs01_27118/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/myshardrs01_27218/mongod.conf\r\n</code></pre><p>6 初始化副本集和创建主节点</p>\r\n<p>使用客户端命令连接任意一个节点，但这里尽量要连接主节点: <code>/usr/yltrcc/mongodb/bin/mongo --host 180.76.159.126 --port 27018</code></p>\r\n<p>执行命令：</p>\r\n<pre><code><span class=\"hljs-meta\">#</span><span class=\"bash\"> 初始化副本集</span>\r\n<span class=\"hljs-meta\">&gt;</span><span class=\"bash\"> rs.initiate()</span>\r\n<span class=\"hljs-meta\">\r\n#</span><span class=\"bash\"> 查看副本集情况</span>\r\nmyshardrs01:SECONDARY&gt; rs.status()\r\n<span class=\"hljs-meta\">\r\n#</span><span class=\"bash\"> 主节点配置查看</span>\r\nmyshardrs01:PRIMARY&gt; rs.conf()\r\n</code></pre><p>7 添加副本节点和仲裁节点</p>\r\n<pre><code># 添加从节点\r\n<span class=\"hljs-selector-tag\">myshardrs01</span><span class=\"hljs-selector-pseudo\">:PRIMARY</span>&gt; <span class=\"hljs-selector-tag\">rs</span><span class=\"hljs-selector-class\">.add</span>(\"180<span class=\"hljs-selector-class\">.76</span><span class=\"hljs-selector-class\">.159</span><span class=\"hljs-selector-class\">.126</span><span class=\"hljs-selector-pseudo\">:27118\")</span>\r\n\r\n# 添加仲裁节点\r\n<span class=\"hljs-selector-tag\">myshardrs01</span><span class=\"hljs-selector-pseudo\">:PRIMARY</span>&gt; <span class=\"hljs-selector-tag\">rs</span><span class=\"hljs-selector-class\">.addArb</span>(\"180<span class=\"hljs-selector-class\">.76</span><span class=\"hljs-selector-class\">.159</span><span class=\"hljs-selector-class\">.126</span><span class=\"hljs-selector-pseudo\">:27218\")</span>\r\n\r\n# 查看配置情况\r\n<span class=\"hljs-selector-tag\">myshardrs01</span><span class=\"hljs-selector-pseudo\">:PRIMARY</span>&gt; <span class=\"hljs-selector-tag\">rs</span><span class=\"hljs-selector-class\">.conf</span>()\r\n</code></pre><h3 id=\"-\">第二套副本集</h3>\r\n<p>1 准备存放数据和日志的目录</p>\r\n<pre><code><span class=\"hljs-comment\">#-----------myshardrs01 </span>\r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27318/<span class=\"hljs-keyword\">log</span> \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27318/data/db \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27418/<span class=\"hljs-keyword\">log</span> \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27418/data/db \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27518/<span class=\"hljs-keyword\">log</span> \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myshardrs01_27518/data/db\r\n</code></pre><p>2 新建或修改配置文件：<code>vim /mongodb/sharded_cluster/myshardrs01_27318/mongod.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27318/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27318/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27318/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27318 \r\nreplication: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">副本集的名称 </span>\r\n  replSetName: myshardrs01 \r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">分片角色 </span>\r\n  clusterRole: shardsvr\r\n</code></pre><p>3 新建或修改配置文件: <code>vim /mongodb/sharded_cluster/myshardrs01_27418/mongod.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27418/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27418/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27418/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27418 \r\nreplication: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">副本集的名称 </span>\r\n  replSetName: myshardrs01 \r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">分片角色 </span>\r\n  clusterRole: shardsvr\r\n</code></pre><p>4 新建或修改配置文件: <code>vim /mongodb/sharded_cluster/myshardrs01_27518/mongod.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27518/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27518/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27518/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27518 \r\nreplication: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">副本集的名称 </span>\r\n  replSetName: myshardrs01 \r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">分片角色 </span>\r\n  clusterRole: shardsvr\r\n</code></pre><p>5 启动第一套副本集：一主一副本一仲裁</p>\r\n<p>依次启动三个mongod服务:</p>\r\n<pre><code>/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/myshardrs01_27318/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/myshardrs01_27418/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/myshardrs01_27518/mongod.conf\r\n</code></pre><p>6 初始化副本集和创建主节点</p>\r\n<p>使用客户端命令连接任意一个节点，但这里尽量要连接主节点: <code>/usr/yltrcc/mongodb/bin/mongo --host 180.76.159.126 --port 27318</code></p>\r\n<p>执行命令：</p>\r\n<pre><code><span class=\"hljs-meta\">#</span><span class=\"bash\"> 初始化副本集</span>\r\n<span class=\"hljs-meta\">&gt;</span><span class=\"bash\"> rs.initiate()</span>\r\n<span class=\"hljs-meta\">\r\n#</span><span class=\"bash\"> 查看副本集情况</span>\r\nmyshardrs01:SECONDARY&gt; rs.status()\r\n<span class=\"hljs-meta\">\r\n#</span><span class=\"bash\"> 主节点配置查看</span>\r\nmyshardrs01:PRIMARY&gt; rs.conf()\r\n</code></pre><p>7 添加副本节点和仲裁节点</p>\r\n<pre><code># 添加从节点\r\n<span class=\"hljs-selector-tag\">myshardrs01</span><span class=\"hljs-selector-pseudo\">:PRIMARY</span>&gt; <span class=\"hljs-selector-tag\">rs</span><span class=\"hljs-selector-class\">.add</span>(\"180<span class=\"hljs-selector-class\">.76</span><span class=\"hljs-selector-class\">.159</span><span class=\"hljs-selector-class\">.126</span><span class=\"hljs-selector-pseudo\">:27418\")</span>\r\n\r\n# 添加仲裁节点\r\n<span class=\"hljs-selector-tag\">myshardrs01</span><span class=\"hljs-selector-pseudo\">:PRIMARY</span>&gt; <span class=\"hljs-selector-tag\">rs</span><span class=\"hljs-selector-class\">.addArb</span>(\"180<span class=\"hljs-selector-class\">.76</span><span class=\"hljs-selector-class\">.159</span><span class=\"hljs-selector-class\">.126</span><span class=\"hljs-selector-pseudo\">:27518\")</span>\r\n\r\n# 查看配置情况\r\n<span class=\"hljs-selector-tag\">myshardrs01</span><span class=\"hljs-selector-pseudo\">:PRIMARY</span>&gt; <span class=\"hljs-selector-tag\">rs</span><span class=\"hljs-selector-class\">.conf</span>()\r\n</code></pre><h2 id=\"-\">配置节点副本集创建</h2>\r\n<p>1 准备存放数据和日志的目录</p>\r\n<pre><code><span class=\"hljs-comment\">#-----------myshardrs01 </span>\r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myconfigrs_27019/<span class=\"hljs-keyword\">log</span> \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myconfigrs_27019/data/db \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myconfigrs_27119/<span class=\"hljs-keyword\">log</span> \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myconfigrs_27119/data/db \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myconfigrs_27219/<span class=\"hljs-keyword\">log</span> \\ &amp; \r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/myconfigrs_27219/data/db\r\n</code></pre><p>2 新建或修改配置文件：<code>vim /mongodb/sharded_cluster/myconfigrs_27019/mongod.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/myconfigrs_27019/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/myconfigrs_27019/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/myconfigrs_27019/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27019 \r\nreplication: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">副本集的名称 </span>\r\n  replSetName: myconfigrs\r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">分片角色 </span>\r\n  clusterRole: configsvr\r\n</code></pre><p>3 新建或修改配置文件: <code>vim /mongodb/sharded_cluster/myconfigrs_27119/mongod.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/myconfigrs_27119/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/myconfigrs_27119/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/myconfigrs_27119/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27119\r\nreplication: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">副本集的名称 </span>\r\n  replSetName: myconfigrs\r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">分片角色 </span>\r\n  clusterRole: configsvr\r\n</code></pre><p>4 新建或修改配置文件: <code>vim /mongodb/sharded_cluster/myconfigrs_27219/mongod.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/myconfigrs_27219/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/myconfigrs_27219/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/myconfigrs_27219/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27219 \r\nreplication: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">副本集的名称 </span>\r\n  replSetName: myconfigrs\r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">分片角色 </span>\r\n  clusterRole: configsvr\r\n</code></pre><p>5 启动第一套副本集：一主一副本一仲裁</p>\r\n<p>依次启动三个mongod服务:</p>\r\n<pre><code>/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/myconfigrs_27019/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/myconfigrs_27119/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/myconfigrs_27219/mongod.conf\r\n</code></pre><p>6 初始化副本集和创建主节点</p>\r\n<p>使用客户端命令连接任意一个节点，但这里尽量要连接主节点: <code>/usr/yltrcc/mongodb/bin/mongo --host 180.76.159.126 --port 27219</code></p>\r\n<p>执行命令：</p>\r\n<pre><code><span class=\"hljs-meta\">#</span><span class=\"bash\"> 初始化副本集</span>\r\n<span class=\"hljs-meta\">&gt;</span><span class=\"bash\"> rs.initiate()</span>\r\n<span class=\"hljs-meta\">\r\n#</span><span class=\"bash\"> 查看副本集情况</span>\r\nmyshardrs01:SECONDARY&gt; rs.status()\r\n<span class=\"hljs-meta\">\r\n#</span><span class=\"bash\"> 主节点配置查看</span>\r\nmyshardrs01:PRIMARY&gt; rs.conf()\r\n</code></pre><p>7 添加两个副本节点</p>\r\n<pre><code># 添加从节点\r\n<span class=\"hljs-selector-tag\">myshardrs01</span><span class=\"hljs-selector-pseudo\">:PRIMARY</span>&gt; <span class=\"hljs-selector-tag\">rs</span><span class=\"hljs-selector-class\">.add</span>(\"180<span class=\"hljs-selector-class\">.76</span><span class=\"hljs-selector-class\">.159</span><span class=\"hljs-selector-class\">.126</span><span class=\"hljs-selector-pseudo\">:27119\")</span>\r\n<span class=\"hljs-selector-tag\">myshardrs01</span><span class=\"hljs-selector-pseudo\">:PRIMARY</span>&gt; <span class=\"hljs-selector-tag\">rs</span><span class=\"hljs-selector-class\">.add</span>(\"180<span class=\"hljs-selector-class\">.76</span><span class=\"hljs-selector-class\">.159</span><span class=\"hljs-selector-class\">.126</span><span class=\"hljs-selector-pseudo\">:27219\")</span>\r\n\r\n# 查看配置情况\r\n<span class=\"hljs-selector-tag\">myshardrs01</span><span class=\"hljs-selector-pseudo\">:PRIMARY</span>&gt; <span class=\"hljs-selector-tag\">rs</span><span class=\"hljs-selector-class\">.conf</span>()\r\n</code></pre><h2 id=\"-\">路由节点的创建</h2>\r\n<h3 id=\"-\">第一个路由节点</h3>\r\n<p>1 准备存放数据和日志的目录</p>\r\n<pre><code><span class=\"hljs-comment\">#-----------mongos01</span>\r\n<span class=\"hljs-keyword\">mkdir</span> -p /mongodb/sharded_cluster/mymongos_27017/<span class=\"hljs-keyword\">log</span>\r\n</code></pre><p>2 新建或修改配置文件：<code>vi /mongodb/sharded_cluster/mymongos_27017/mongos.conf</code></p>\r\n<pre><code>systemLog: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">MongoDB发送所有日志输出的目标指定为文件 </span>\r\n  destination: file\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 </span>\r\n  path: \"/mongodb/sharded_cluster/mymongos_27017/log/mongod.log\" \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 </span>\r\n  logAppend: true \r\nstorage: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 </span>\r\n  dbPath: \"/mongodb/sharded_cluster/mymongos_27017/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">启用在后台运行mongos或mongod进程的守护进程模式。 </span>\r\n  fork: true \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID </span>\r\n  pidFilePath: \"/mongodb/sharded_cluster/mymongos_27017/log/mongod.pid\" \r\nnet:\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>IpAll: <span class=\"hljs-literal\">true</span> </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">服务实例绑定的IP </span>\r\n  bindIp: localhost,192.168.0.2 \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\"><span class=\"hljs-built_in\">bind</span>Ip </span>\r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">绑定的端口 </span>\r\n  port: 27017 \r\nsharding: \r\n<span class=\"hljs-meta\">  #</span><span class=\"bash\">指定配置节点副本集 </span>\r\n  configDB: myconfigrs/180.76.159.126:27019,180.76.159.126:27119,180.76.159.126:27219\r\n</code></pre><p>3 启动mongod服务:</p>\r\n<pre><code>/usr/yltrcc/mongodb/bin/mongod <span class=\"hljs-_\">-f</span> /mongodb/sharded_cluster/mymongos_27017/mongos.conf\r\n</code></pre><p>4 客户端登录mongos: <code>/usr/yltrcc/mongodb/bin/mongo --host 180.76.159.126 --port 27017</code></p>\r\n<p>通过路由节点操作，现在只是连接了配置节点，还没有连接分片数据节点，因此无法写入业务数据。</p>\r\n<p>5 在路由节点上进行分片配置操作</p>\r\n<p><strong>添加分片</strong>：<code>sh.addShard(&quot;IP:Port&quot;)</code> </p>\r\n<pre><code><span class=\"hljs-comment\"># 添加第一套副本集</span>\r\n<span class=\"hljs-attribute\">sh</span>.addShard(<span class=\"hljs-string\">\"myshardrs01/192.168.0.2:27018,180.76.159.126:27118,180.76.159.126:2 7218\"</span>)\r\n\r\n<span class=\"hljs-comment\"># 添加第二套副本集</span>\r\n<span class=\"hljs-attribute\">sh</span>.addShard(<span class=\"hljs-string\">\"myshardrs02/192.168.0.2:27318,180.76.159.126:27418,180.76.159.126:2 7518\"</span>)\r\n</code></pre><p>提示：如果添加分片失败，需要先手动移除分片，检查添加分片的信息的正确性后，再次添加分片。</p>\r\n<p>移除分片参考(了解)：</p>\r\n<pre><code><span class=\"hljs-selector-tag\">use</span> <span class=\"hljs-selector-tag\">admin</span> \r\n<span class=\"hljs-selector-tag\">db</span><span class=\"hljs-selector-class\">.runCommand</span>( { <span class=\"hljs-attribute\">removeShard</span>: <span class=\"hljs-string\">\"myshardrs02\"</span> } )\r\n</code></pre><p><strong>开启分片功能</strong>: <code>sh.enableSharding(&quot;库名&quot;)</code>、<code>sh.shardCollection(&quot;库名.集合名&quot;,{&quot;key&quot;:1})</code></p>\r\n<p>在mongos上的articledb数据库配置sharding</p>\r\n<pre><code><span class=\"hljs-attribute\">sh</span>.enableSharding(<span class=\"hljs-string\">\"articledb\"</span>)\r\n\r\n<span class=\"hljs-comment\"># 查看分片状态</span>\r\n <span class=\"hljs-attribute\">sh</span>.status()\r\n</code></pre><p><strong>集合分片</strong>： 对集合分片，你必须使用 <code>sh.shardCollection()</code> 方法指定集合和分片键。</p>\r\n<p>语法格式：<code>sh.shardCollection(namespace, key, unique)</code></p>\r\n<p>参数说明：</p>\r\n<table>\r\n<thead>\r\n<tr>\r\n<th></th>\r\n<th></th>\r\n<th></th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr>\r\n<td>Parameter</td>\r\n<td>Type</td>\r\n<td>Description</td>\r\n</tr>\r\n<tr>\r\n<td>namespace</td>\r\n<td>string</td>\r\n<td>要（分片）共享的目标集合的命名空间，格式： <database>.<collection></td>\r\n</tr>\r\n<tr>\r\n<td>key</td>\r\n<td>document</td>\r\n<td>用作分片键的索引规范文档。shard键决定MongoDB如何在shard之间分发文档。除非集合为空，否则索引必须在shard collection命令之前存在。如果集合为空，则MongoDB在对集合进行分片之前创建索引，前提是支持分片键的索引不存在。简单的说：由包含字段和该字段的索引遍历方向的文档组成。</td>\r\n</tr>\r\n<tr>\r\n<td>unique</td>\r\n<td>boolean</td>\r\n<td>当值为true情况下，片键字段上会限制为确保是唯一索引。哈希策略片键不支持唯一索引。默认是false。</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<p>6 分片后插入数据测试</p>\r\n<p>7 增加另一个路由节点</p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>电影散场，影院里的观众皆唏嘘而去。我和太太看到最后，直到音乐的休止落下、字幕拉到最底部。我似乎不能完整记住险象环生的情节，但那印度电影的唯美音乐，和虽然处于隐线却从来没有放弃追逐的爱情，让我喜欢和回味。</p>', '# 每日一句\r\nMedalist don\'t grow on trees， you have to nurture them with love, with hard work, with dedication. \r\n金牌选手不会从天而降，你必须用热爱、刻苦和投入来浇灌他们。\r\n\r\n# 概述\r\n\r\n分片（sharding）是一种垮多台机器分布数据的方法，MongoDB使用分片来支持具有非常大的数据集和高吞吐量操作的部署。\r\n\r\n分片(sharding)是指将数据拆分，将其分散存在不同的机器上的过程。有时也用分区(partitioning)来表示这个概念。将数据分散到不同的机器上，不需要功能强大的大型计算机就可以储存更多的数据，处理更多的负载。\r\n\r\n具有大型数据集或高吞吐量应用程序的数据库系统可以会挑战单个服务器的容量。例如，高查询率会耗尽服务器的CPU容量。工作集大小大于系统的RAM会强调磁盘驱动器的I / O容量。\r\n\r\n有两种解决系统增长的方法：垂直扩展和水平扩展。\r\n\r\n- 垂直扩展意味着增加单个服务器的容量，例如使用更强大的CPU，添加更多RAM或增加存储空间量。可用技术的局限性可能会限制单个机器对于给定工作负载而言足够强大。此外，基于云的提供商基于可用的硬件配置具有硬性上限。结果，垂直缩放有实际的最大值。\r\n- 水平扩展意味着划分系统数据集并加载多个服务器，添加其他服务器以根据需要增加容量。虽然单个机器的总体速度或容量可能不高，但每台机器处理整个工作负载的子集，可能提供比单个高速大容量服务器更高的效率。扩展部署容量只需要根据需要添加额外的服务器，这可能比单个机器的高端硬件的总体成本更低。MongoDB支持通过分片进行水平扩展。\r\n\r\n\r\n\r\n# 组件\r\n\r\nMongoDB分片群集包含以下组件：\r\n\r\n- 分片（存储）：每个分片包含分片数据的子集。每个分片都可以部署为副本集。\r\n- Mongos（路由）：mongos充当查询路由器，在客户端应用程序和分片集群之间提供接口。\r\n- config servers：配置服务器存储集群的元数据和配置设置。从MongoDB3.4开始，必须将配置服务器部署为副本集（CSRS）\r\n\r\n下图描述了分片集群中组件的交互：\r\n\r\n\r\nMongoDB在集合级别对数据进行分片，将集合数据分布在集群中的分片上。\r\n\r\n\r\n\r\n# 实例\r\n\r\n两个分片节点副本集（3+3）+一个配置节点副本集（3）+两个路由节点（2），共11个服务节点。\r\n\r\n\r\n\r\n## 分片节点副本集的创建\r\n\r\n所有的的配置文件都直接放到 sharded_cluster 的相应的子目录下面，默认配置文件名字：mongod.conf\r\n\r\n\r\n\r\n### 第一套副本集\r\n\r\n1 准备存放数据和日志的目录\r\n\r\n```\r\n#-----------myshardrs01 \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27018/log \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27018/data/db \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27118/log \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27118/data/db \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27218/log \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27218/data/db\r\n```\r\n\r\n2 新建或修改配置文件：`vim /mongodb/sharded_cluster/myshardrs01_27018/mongod.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27018/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27018/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27018/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27018 \r\nreplication: \r\n  #副本集的名称 \r\n  replSetName: myshardrs01 \r\nsharding: \r\n  #分片角色 \r\n  clusterRole: shardsvr\r\n```\r\n\r\nsharding.clusterRole：\r\n\r\n|||\r\n|-|-|\r\n|Value|Description|\r\n|configsvr|Start this instance as a [config server](https://docs.mongodb.com/manual/reference/glossary/#term-config-server). The instance starts on port 27019 by default.|\r\n|shardsvr|Start this instance as a [shard](https://docs.mongodb.com/manual/reference/glossary/#term-shard). The instance starts on port 27018 by default.|\r\n\r\n\r\n注意：\r\n\r\n设置sharding.clusterRole需要mongod实例运行复制。 要将实例部署为副本集成员，请使用\r\n\r\nreplSetName设置并指定副本集的名称。\r\n\r\n3 新建或修改配置文件: `vim /mongodb/sharded_cluster/myshardrs01_27118/mongod.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27118/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27118/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27118/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27118 \r\nreplication: \r\n  #副本集的名称 \r\n  replSetName: myshardrs01 \r\nsharding: \r\n  #分片角色 \r\n  clusterRole: shardsvr\r\n```\r\n\r\n4 新建或修改配置文件: `vim /mongodb/sharded_cluster/myshardrs01_27218/mongod.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27218/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27218/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27218/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27218 \r\nreplication: \r\n  #副本集的名称 \r\n  replSetName: myshardrs01 \r\nsharding: \r\n  #分片角色 \r\n  clusterRole: shardsvr\r\n```\r\n\r\n5 启动第一套副本集：一主一副本一仲裁\r\n\r\n依次启动三个mongod服务:\r\n\r\n```\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/myshardrs01_27018/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/myshardrs01_27118/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/myshardrs01_27218/mongod.conf\r\n\r\n```\r\n\r\n\r\n\r\n6 初始化副本集和创建主节点\r\n\r\n使用客户端命令连接任意一个节点，但这里尽量要连接主节点: `/usr/yltrcc/mongodb/bin/mongo --host 180.76.159.126 --port 27018`\r\n\r\n执行命令：\r\n\r\n```\r\n# 初始化副本集\r\n> rs.initiate()\r\n\r\n# 查看副本集情况\r\nmyshardrs01:SECONDARY> rs.status()\r\n\r\n# 主节点配置查看\r\nmyshardrs01:PRIMARY> rs.conf()\r\n\r\n```\r\n\r\n\r\n\r\n7 添加副本节点和仲裁节点\r\n\r\n```\r\n# 添加从节点\r\nmyshardrs01:PRIMARY> rs.add(\"180.76.159.126:27118\")\r\n\r\n# 添加仲裁节点\r\nmyshardrs01:PRIMARY> rs.addArb(\"180.76.159.126:27218\")\r\n\r\n# 查看配置情况\r\nmyshardrs01:PRIMARY> rs.conf()\r\n\r\n```\r\n\r\n\r\n\r\n### 第二套副本集\r\n\r\n1 准备存放数据和日志的目录\r\n\r\n```\r\n#-----------myshardrs01 \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27318/log \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27318/data/db \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27418/log \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27418/data/db \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27518/log \\ & \r\nmkdir -p /mongodb/sharded_cluster/myshardrs01_27518/data/db\r\n```\r\n\r\n2 新建或修改配置文件：`vim /mongodb/sharded_cluster/myshardrs01_27318/mongod.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27318/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27318/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27318/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27318 \r\nreplication: \r\n  #副本集的名称 \r\n  replSetName: myshardrs01 \r\nsharding: \r\n  #分片角色 \r\n  clusterRole: shardsvr\r\n```\r\n\r\n3 新建或修改配置文件: `vim /mongodb/sharded_cluster/myshardrs01_27418/mongod.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27418/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27418/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27418/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27418 \r\nreplication: \r\n  #副本集的名称 \r\n  replSetName: myshardrs01 \r\nsharding: \r\n  #分片角色 \r\n  clusterRole: shardsvr\r\n```\r\n\r\n4 新建或修改配置文件: `vim /mongodb/sharded_cluster/myshardrs01_27518/mongod.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/myshardrs01_27518/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/myshardrs01_27518/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/myshardrs01_27518/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27518 \r\nreplication: \r\n  #副本集的名称 \r\n  replSetName: myshardrs01 \r\nsharding: \r\n  #分片角色 \r\n  clusterRole: shardsvr\r\n```\r\n\r\n5 启动第一套副本集：一主一副本一仲裁\r\n\r\n依次启动三个mongod服务:\r\n\r\n```\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/myshardrs01_27318/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/myshardrs01_27418/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/myshardrs01_27518/mongod.conf\r\n\r\n```\r\n\r\n\r\n\r\n6 初始化副本集和创建主节点\r\n\r\n使用客户端命令连接任意一个节点，但这里尽量要连接主节点: `/usr/yltrcc/mongodb/bin/mongo --host 180.76.159.126 --port 27318`\r\n\r\n执行命令：\r\n\r\n```\r\n# 初始化副本集\r\n> rs.initiate()\r\n\r\n# 查看副本集情况\r\nmyshardrs01:SECONDARY> rs.status()\r\n\r\n# 主节点配置查看\r\nmyshardrs01:PRIMARY> rs.conf()\r\n\r\n```\r\n\r\n\r\n\r\n7 添加副本节点和仲裁节点\r\n\r\n```\r\n# 添加从节点\r\nmyshardrs01:PRIMARY> rs.add(\"180.76.159.126:27418\")\r\n\r\n# 添加仲裁节点\r\nmyshardrs01:PRIMARY> rs.addArb(\"180.76.159.126:27518\")\r\n\r\n# 查看配置情况\r\nmyshardrs01:PRIMARY> rs.conf()\r\n\r\n```\r\n\r\n\r\n\r\n## 配置节点副本集创建\r\n\r\n1 准备存放数据和日志的目录\r\n\r\n```\r\n#-----------myshardrs01 \r\nmkdir -p /mongodb/sharded_cluster/myconfigrs_27019/log \\ & \r\nmkdir -p /mongodb/sharded_cluster/myconfigrs_27019/data/db \\ & \r\nmkdir -p /mongodb/sharded_cluster/myconfigrs_27119/log \\ & \r\nmkdir -p /mongodb/sharded_cluster/myconfigrs_27119/data/db \\ & \r\nmkdir -p /mongodb/sharded_cluster/myconfigrs_27219/log \\ & \r\nmkdir -p /mongodb/sharded_cluster/myconfigrs_27219/data/db\r\n```\r\n\r\n2 新建或修改配置文件：`vim /mongodb/sharded_cluster/myconfigrs_27019/mongod.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/myconfigrs_27019/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/myconfigrs_27019/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/myconfigrs_27019/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27019 \r\nreplication: \r\n  #副本集的名称 \r\n  replSetName: myconfigrs\r\nsharding: \r\n  #分片角色 \r\n  clusterRole: configsvr\r\n```\r\n\r\n3 新建或修改配置文件: `vim /mongodb/sharded_cluster/myconfigrs_27119/mongod.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/myconfigrs_27119/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/myconfigrs_27119/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/myconfigrs_27119/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27119\r\nreplication: \r\n  #副本集的名称 \r\n  replSetName: myconfigrs\r\nsharding: \r\n  #分片角色 \r\n  clusterRole: configsvr\r\n```\r\n\r\n4 新建或修改配置文件: `vim /mongodb/sharded_cluster/myconfigrs_27219/mongod.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/myconfigrs_27219/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/myconfigrs_27219/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/myconfigrs_27219/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27219 \r\nreplication: \r\n  #副本集的名称 \r\n  replSetName: myconfigrs\r\nsharding: \r\n  #分片角色 \r\n  clusterRole: configsvr\r\n```\r\n\r\n5 启动第一套副本集：一主一副本一仲裁\r\n\r\n依次启动三个mongod服务:\r\n\r\n```\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/myconfigrs_27019/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/myconfigrs_27119/mongod.conf\r\n\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/myconfigrs_27219/mongod.conf\r\n\r\n```\r\n\r\n\r\n\r\n6 初始化副本集和创建主节点\r\n\r\n使用客户端命令连接任意一个节点，但这里尽量要连接主节点: `/usr/yltrcc/mongodb/bin/mongo --host 180.76.159.126 --port 27219`\r\n\r\n执行命令：\r\n\r\n```\r\n# 初始化副本集\r\n> rs.initiate()\r\n\r\n# 查看副本集情况\r\nmyshardrs01:SECONDARY> rs.status()\r\n\r\n# 主节点配置查看\r\nmyshardrs01:PRIMARY> rs.conf()\r\n\r\n```\r\n\r\n\r\n\r\n7 添加两个副本节点\r\n\r\n```\r\n# 添加从节点\r\nmyshardrs01:PRIMARY> rs.add(\"180.76.159.126:27119\")\r\nmyshardrs01:PRIMARY> rs.add(\"180.76.159.126:27219\")\r\n\r\n# 查看配置情况\r\nmyshardrs01:PRIMARY> rs.conf()\r\n\r\n```\r\n\r\n\r\n\r\n## 路由节点的创建\r\n\r\n### 第一个路由节点\r\n\r\n1 准备存放数据和日志的目录\r\n\r\n```\r\n#-----------mongos01\r\nmkdir -p /mongodb/sharded_cluster/mymongos_27017/log\r\n```\r\n\r\n2 新建或修改配置文件：`vi /mongodb/sharded_cluster/mymongos_27017/mongos.conf`\r\n\r\n```\r\nsystemLog: \r\n  #MongoDB发送所有日志输出的目标指定为文件 \r\n  destination: file\r\n  #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 \r\n  path: \"/mongodb/sharded_cluster/mymongos_27017/log/mongod.log\" \r\n  #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 \r\n  logAppend: true \r\nstorage: \r\n  #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 \r\n  dbPath: \"/mongodb/sharded_cluster/mymongos_27017/data/db\" \r\n  journal: \r\n    #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 \r\n    enabled: true \r\nprocessManagement: \r\n  #启用在后台运行mongos或mongod进程的守护进程模式。 \r\n  fork: true \r\n  #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID \r\n  pidFilePath: \"/mongodb/sharded_cluster/mymongos_27017/log/mongod.pid\" \r\nnet:\r\n  #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip \r\n  #bindIpAll: true \r\n  #服务实例绑定的IP \r\n  bindIp: localhost,192.168.0.2 \r\n  #bindIp \r\n  #绑定的端口 \r\n  port: 27017 \r\nsharding: \r\n  #指定配置节点副本集 \r\n  configDB: myconfigrs/180.76.159.126:27019,180.76.159.126:27119,180.76.159.126:27219\r\n```\r\n\r\n\r\n\r\n3 启动mongod服务:\r\n\r\n```\r\n/usr/yltrcc/mongodb/bin/mongod -f /mongodb/sharded_cluster/mymongos_27017/mongos.conf\r\n\r\n```\r\n\r\n\r\n\r\n4 客户端登录mongos: `/usr/yltrcc/mongodb/bin/mongo --host 180.76.159.126 --port 27017`\r\n\r\n通过路由节点操作，现在只是连接了配置节点，还没有连接分片数据节点，因此无法写入业务数据。\r\n\r\n\r\n\r\n5 在路由节点上进行分片配置操作\r\n\r\n**添加分片**：`sh.addShard(\"IP:Port\")` \r\n\r\n```\r\n# 添加第一套副本集\r\nsh.addShard(\"myshardrs01/192.168.0.2:27018,180.76.159.126:27118,180.76.159.126:2 7218\")\r\n\r\n# 添加第二套副本集\r\nsh.addShard(\"myshardrs02/192.168.0.2:27318,180.76.159.126:27418,180.76.159.126:2 7518\")\r\n\r\n```\r\n\r\n提示：如果添加分片失败，需要先手动移除分片，检查添加分片的信息的正确性后，再次添加分片。\r\n\r\n移除分片参考(了解)：\r\n\r\n```\r\nuse admin \r\ndb.runCommand( { removeShard: \"myshardrs02\" } )\r\n```\r\n\r\n**开启分片功能**: `sh.enableSharding(\"库名\")`、`sh.shardCollection(\"库名.集合名\",{\"key\":1})`\r\n\r\n在mongos上的articledb数据库配置sharding\r\n\r\n```\r\nsh.enableSharding(\"articledb\")\r\n\r\n# 查看分片状态\r\n sh.status()\r\n\r\n```\r\n\r\n**集合分片**： 对集合分片，你必须使用 `sh.shardCollection()` 方法指定集合和分片键。\r\n\r\n语法格式：`sh.shardCollection(namespace, key, unique)`\r\n\r\n参数说明：\r\n\r\n||||\r\n|-|-|-|\r\n|Parameter|Type|Description|\r\n|namespace|string|要（分片）共享的目标集合的命名空间，格式： <database>.<collection>|\r\n|key|document|用作分片键的索引规范文档。shard键决定MongoDB如何在shard之间分发文档。除非集合为空，否则索引必须在shard collection命令之前存在。如果集合为空，则MongoDB在对集合进行分片之前创建索引，前提是支持分片键的索引不存在。简单的说：由包含字段和该字段的索引遍历方向的文档组成。|\r\n|unique|boolean|当值为true情况下，片键字段上会限制为确保是唯一索引。哈希策略片键不支持唯一索引。默认是false。|\r\n\r\n\r\n\r\n\r\n6 分片后插入数据测试\r\n\r\n7 增加另一个路由节点\r\n\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n电影散场，影院里的观众皆唏嘘而去。我和太太看到最后，直到音乐的休止落下、字幕拉到最底部。我似乎不能完整记住险象环生的情节，但那印度电影的唯美音乐，和虽然处于隐线却从来没有放弃追逐的爱情，让我喜欢和回味。', '2022-01-18 21:40:54', 0, '每日一句Medalistdon&#39;tgrowontrees，youhavetonurturet', '/static/img/rand/1.jpg', 'MongoDB 分片集群', 0, 'post', 0, '2022-01-18 21:40:54', '1642563654', 10);
INSERT INTO `blog_article` VALUES (163, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>Ideal is the beacon. Without ideal, there is no secure direction; without direction, there is no life.<br>理想是指路明灯。没有理想，就没有坚定的方向;没有方向，就没有生活。</p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>对集合进行分片时,你需要选择一个 片键（Shard Key） , shard key 是每条记录都必须包含的,且建立了索引的单个字段或复合字段,MongoDB按照片键将数据划分到不同的 数据块 中,并将 数据块 均衡地分布到所有分片中.</p>\r\n<p>为了按照片键划分数据块,MongoDB使用如下方式分配：</p>\r\n<ul>\r\n<li>基于哈希的分片方式（随机平均分配）</li>\r\n<li>基于范围的分片方式（数值大小分配）</li>\r\n</ul>\r\n<p>用什么字段当片键都可以，如：nickname作为片键，但一定是必填字段。</p>\r\n<h1 id=\"-\">哈希策略</h1>\r\n<p>对于 基于哈希的分片 ,MongoDB计算一个字段的哈希值,并用这个哈希值来创建数据块.</p>\r\n<p>在使用基于哈希分片的系统中,拥有”相近”片键的文档 很可能不会 存储在同一个数据块中,因此数据的分离性更好一些.</p>\r\n<p>使用nickname作为片键，根据其值的哈希值进行数据分片</p>\r\n<pre><code><span class=\"hljs-attribute\">sh</span>.shardCollection(<span class=\"hljs-string\">\"articledb.comment\"</span>,{<span class=\"hljs-string\">\"nickname\"</span>:<span class=\"hljs-string\">\"hashed\"</span>})\r\n</code></pre><h1 id=\"-\">范围策略</h1>\r\n<p>对于 基于范围的分片 ,MongoDB按照片键的范围把数据分成不同部分.</p>\r\n<p>假设有一个数字的片键:想象一个从负无穷到正无穷的直线,每一个片键的值都在直线上画了一个点.MongoDB把这条直线划分为更短的不重叠的片段,并称之为 数据块 ,每个数据块包含了片键在一定范围内的数据.</p>\r\n<p>在使用片键做范围划分的系统中,拥有”相近”片键的文档很可能存储在同一个数据块中,因此也会存储在同一个分片中.</p>\r\n<p>如使用作者年龄字段作为片键，按照点赞数的值进行分片：</p>\r\n<pre><code><span class=\"hljs-attribute\">sh</span>.shardCollection(<span class=\"hljs-string\">\"articledb.author\"</span>,{<span class=\"hljs-string\">\"age\"</span>:1})\r\n</code></pre><p><strong>注意</strong></p>\r\n<p>1）一个集合只能指定一个片键，否则报错。</p>\r\n<p>2）一旦对一个集合分片，分片键和分片值就不可改变。 如：不能给集合选择不同的分片键、不能更新分片键的值。</p>\r\n<p>3）根据age索引进行分配数据。</p>\r\n<h1 id=\"-\">两种策略对比</h1>\r\n<p>基于范围的分片方式提供了更高效的范围查询,给定一个片键的范围,分发路由可以很简单地确定哪个数据块存储了请求需要的数据,并将请求转发到相应的分片中.不过,基于范围的分片会导致数据在不同分片上的不均衡,有时候,带来的消极作用会大于查询性能的积极作用.比如,如果片键所在的字段是线性增长的,一定时间内的所有请求都会落到某个固定的数据块中,最终导致分布在同一个分片中.在这种情况下,一小部分分片承载了集群大部分的数据,系统并不能很好地进行扩展.</p>\r\n<p>基于哈希的分片方式以范围查询性能的损失为代价,保证了集群中数据的均衡.哈希值的随机性，使数据随机分布在每个数据块中,因此也随机分布在不同分片中.但是也正由于随机性,一个范围查询很难确定应该请求哪些分片,通常为了返回需要的结果,需要请求所有分片.</p>\r\n<p>如无特殊情况，一般推荐使用 Hash Sharding。而使用 _id 作为片键是一个不错的选择，因为它是必有的，你可以使用数据文档 _id 的哈希作为片键。</p>\r\n<p>这个方案能够是的读和写都能够平均分布，并且它能够保证每个文档都有不同的片键所以数据块能够很精细。似乎还是不够完美，因为这样的话对多个文档的查询必将命中所有的分片。虽说如此，这也是一种比较好的方案了。</p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>一个人的自愈能力越强，才越有可能接近幸福。做一个寡言，却心有一片海的人，不伤人害己，于淡泊中，平和自在。</p>', '# 每日一句\r\nIdeal is the beacon. Without ideal, there is no secure direction; without direction, there is no life. \r\n理想是指路明灯。没有理想，就没有坚定的方向;没有方向，就没有生活。\r\n\r\n# 概述\r\n\r\n对集合进行分片时,你需要选择一个 片键（Shard Key） , shard key 是每条记录都必须包含的,且建立了索引的单个字段或复合字段,MongoDB按照片键将数据划分到不同的 数据块 中,并将 数据块 均衡地分布到所有分片中.\r\n\r\n为了按照片键划分数据块,MongoDB使用如下方式分配：\r\n\r\n-  基于哈希的分片方式（随机平均分配）\r\n- 基于范围的分片方式（数值大小分配）\r\n\r\n用什么字段当片键都可以，如：nickname作为片键，但一定是必填字段。\r\n\r\n\r\n\r\n# 哈希策略\r\n\r\n对于 基于哈希的分片 ,MongoDB计算一个字段的哈希值,并用这个哈希值来创建数据块.\r\n\r\n在使用基于哈希分片的系统中,拥有”相近”片键的文档 很可能不会 存储在同一个数据块中,因此数据的分离性更好一些.\r\n\r\n使用nickname作为片键，根据其值的哈希值进行数据分片\r\n\r\n\r\n\r\n```\r\nsh.shardCollection(\"articledb.comment\",{\"nickname\":\"hashed\"})\r\n```\r\n\r\n\r\n\r\n# 范围策略\r\n\r\n对于 基于范围的分片 ,MongoDB按照片键的范围把数据分成不同部分.\r\n\r\n假设有一个数字的片键:想象一个从负无穷到正无穷的直线,每一个片键的值都在直线上画了一个点.MongoDB把这条直线划分为更短的不重叠的片段,并称之为 数据块 ,每个数据块包含了片键在一定范围内的数据.\r\n\r\n在使用片键做范围划分的系统中,拥有”相近”片键的文档很可能存储在同一个数据块中,因此也会存储在同一个分片中.\r\n\r\n如使用作者年龄字段作为片键，按照点赞数的值进行分片：\r\n\r\n```\r\nsh.shardCollection(\"articledb.author\",{\"age\":1})\r\n```\r\n\r\n**注意**\r\n\r\n1）一个集合只能指定一个片键，否则报错。\r\n\r\n2）一旦对一个集合分片，分片键和分片值就不可改变。 如：不能给集合选择不同的分片键、不能更新分片键的值。\r\n\r\n3）根据age索引进行分配数据。\r\n\r\n\r\n\r\n# 两种策略对比\r\n\r\n基于范围的分片方式提供了更高效的范围查询,给定一个片键的范围,分发路由可以很简单地确定哪个数据块存储了请求需要的数据,并将请求转发到相应的分片中.不过,基于范围的分片会导致数据在不同分片上的不均衡,有时候,带来的消极作用会大于查询性能的积极作用.比如,如果片键所在的字段是线性增长的,一定时间内的所有请求都会落到某个固定的数据块中,最终导致分布在同一个分片中.在这种情况下,一小部分分片承载了集群大部分的数据,系统并不能很好地进行扩展.\r\n\r\n\r\n\r\n基于哈希的分片方式以范围查询性能的损失为代价,保证了集群中数据的均衡.哈希值的随机性，使数据随机分布在每个数据块中,因此也随机分布在不同分片中.但是也正由于随机性,一个范围查询很难确定应该请求哪些分片,通常为了返回需要的结果,需要请求所有分片.\r\n\r\n\r\n\r\n如无特殊情况，一般推荐使用 Hash Sharding。而使用 _id 作为片键是一个不错的选择，因为它是必有的，你可以使用数据文档 _id 的哈希作为片键。\r\n\r\n这个方案能够是的读和写都能够平均分布，并且它能够保证每个文档都有不同的片键所以数据块能够很精细。似乎还是不够完美，因为这样的话对多个文档的查询必将命中所有的分片。虽说如此，这也是一种比较好的方案了。\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n一个人的自愈能力越强，才越有可能接近幸福。做一个寡言，却心有一片海的人，不伤人害己，于淡泊中，平和自在。', '2022-01-19 21:12:45', 0, '每日一句Idealisthebeacon.Withoutideal,thereisnosecured', '/static/img/rand/8.jpg', 'MongoDB 分片规则', 0, 'post', 0, '2022-01-19 21:12:45', '1642648365', 10);
INSERT INTO `blog_article` VALUES (164, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>The secret of being miserable is to have leisure to bother about whether you are happy or not.<br>痛苦的秘密在于有闲工夫担心自己是否幸福。</p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>官网：<a href=\"https://www.rabbitmq.com/\">https://www.rabbitmq.com/</a></p>\r\n<p>RabbitMQ是实现了高级消息队列协议（Advanced Message Queueing Protocol , AMQP）的开源消息代理软件（亦称面向消息的中间件）。</p>\r\n<h4 id=\"-\">什么是消息中间件</h4>\r\n<p>定义：支持在分布式系统中发送和接受消息的硬件或软件基础设施</p>\r\n<h4 id=\"-\">消息中间件应用场景</h4>\r\n<p>消息中间件解决的就是分布式系统之间消息传递的问题。</p>\r\n<p>简单概括一下消息中间件的应用场景大致如下：</p>\r\n<ul>\r\n<li>业务解耦：交易系统不需要知道短信通知服务的存在，只需要发布消息</li>\r\n<li>削峰填谷：比如上游系统的吞吐能力高于下游系统，在流量洪峰时可能会冲垮下游系统，消息中间件可以在峰值时堆积消息，而在峰值过去后下游系统慢慢消费消息解决流量洪峰的问题</li>\r\n<li>事件驱动：系统与系统之间可以通过消息传递的形式驱动业务，以流式的模型处理</li>\r\n</ul>\r\n<h4 id=\"rabbitmq-\">rabbitMQ的起源</h4>\r\n<p>RabbitMQ 是采用 Erlang 语言实现 <strong>AMQP（Advanced Message Queuing Protocol）高级消息队列协议</strong> 的消息中间件，用于在 <strong>分布式系统中存储转发消息</strong>。</p>\r\n<p>RabbitMQ 正是由于它优越的表现被越来越多人认可。具体特点可以概括为以下几点：</p>\r\n<ul>\r\n<li>可靠性：持久化、<strong>传输确认</strong>、<strong>发布确认</strong>等。</li>\r\n<li>灵活的路由：在消息进入队列之前，通过 <strong>交换器</strong> 来 <strong>路由</strong> 消息</li>\r\n<li>扩展性：多个 RabbitMQ 节点可以组成一个集群，也可以动态扩展集群节点。</li>\r\n<li>高可用性：<strong>队列</strong> 可以在集群中的机器上设置 <strong>镜像</strong>，使得在部分节点出现问题的情况下，队列仍然可用</li>\r\n<li>多种协议：原生支持 AMQP 协议，还支持 STOMP、MQTT 等多种消息中间件协议</li>\r\n<li>多语言客户端：支持常用语言客户端。如：Java、Python、Ruby、PHP、<code>C#</code>、JavaScript</li>\r\n<li>管理界面：提供了一个易用的用户界面，使得用户可以 <strong>监控和管理消息、集群中的节点</strong> 等</li>\r\n<li>插件机制：提供了许多插件，以实现从多方面进行扩展，也可以自己编写插件。</li>\r\n</ul>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>在薄情的世界里，每个人都来去匆匆，没有谁会永远陪伴在你身边，没有人会时刻对你关怀备至，体贴入微，倒不如学会好好爱自己，不辜负余生。</p>', '# 每日一句\r\nThe secret of being miserable is to have leisure to bother about whether you are happy or not. \r\n痛苦的秘密在于有闲工夫担心自己是否幸福。\r\n\r\n# 概述\r\n\r\n官网：[https://www.rabbitmq.com/](https://www.rabbitmq.com/)\r\n\r\n\r\n\r\nRabbitMQ是实现了高级消息队列协议（Advanced Message Queueing Protocol , AMQP）的开源消息代理软件（亦称面向消息的中间件）。\r\n\r\n\r\n\r\n#### 什么是消息中间件\r\n\r\n定义：支持在分布式系统中发送和接受消息的硬件或软件基础设施\r\n\r\n#### 消息中间件应用场景\r\n\r\n消息中间件解决的就是分布式系统之间消息传递的问题。\r\n\r\n简单概括一下消息中间件的应用场景大致如下：\r\n\r\n- 业务解耦：交易系统不需要知道短信通知服务的存在，只需要发布消息\r\n- 削峰填谷：比如上游系统的吞吐能力高于下游系统，在流量洪峰时可能会冲垮下游系统，消息中间件可以在峰值时堆积消息，而在峰值过去后下游系统慢慢消费消息解决流量洪峰的问题\r\n- 事件驱动：系统与系统之间可以通过消息传递的形式驱动业务，以流式的模型处理\r\n\r\n#### rabbitMQ的起源\r\n\r\nRabbitMQ 是采用 Erlang 语言实现 **AMQP（Advanced Message Queuing Protocol）高级消息队列协议** 的消息中间件，用于在 **分布式系统中存储转发消息**。\r\n\r\nRabbitMQ 正是由于它优越的表现被越来越多人认可。具体特点可以概括为以下几点：\r\n\r\n- 可靠性：持久化、**传输确认**、**发布确认**等。\r\n- 灵活的路由：在消息进入队列之前，通过 **交换器** 来 **路由** 消息\r\n- 扩展性：多个 RabbitMQ 节点可以组成一个集群，也可以动态扩展集群节点。\r\n- 高可用性：**队列** 可以在集群中的机器上设置 **镜像**，使得在部分节点出现问题的情况下，队列仍然可用\r\n- 多种协议：原生支持 AMQP 协议，还支持 STOMP、MQTT 等多种消息中间件协议\r\n- 多语言客户端：支持常用语言客户端。如：Java、Python、Ruby、PHP、`C#`、JavaScript\r\n- 管理界面：提供了一个易用的用户界面，使得用户可以 **监控和管理消息、集群中的节点** 等\r\n- 插件机制：提供了许多插件，以实现从多方面进行扩展，也可以自己编写插件。\r\n\r\n\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n在薄情的世界里，每个人都来去匆匆，没有谁会永远陪伴在你身边，没有人会时刻对你关怀备至，体贴入微，倒不如学会好好爱自己，不辜负余生。', '2022-01-19 21:13:31', 0, '每日一句Thesecretofbeingmiserableistohaveleisuretoboth', '/static/img/rand/15.jpg', 'RabitMQ 简介', 0, 'post', 0, '2022-01-19 21:13:31', '1642648411', 10);
INSERT INTO `blog_article` VALUES (165, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>Wisdom is knowing what to do next, skill is knowing how to do it, and virtue is doing it.<br>智慧是知道下一步做什么，技能是知道如何做，而美德就是去做。</p>\r\n<h1 id=\"windows\">windows</h1>\r\n<p>1.下载并安装erlang,下载地址：<a href=\"https://www.erlang.org/downloads\">https://www.erlang.org/downloads</a></p>\r\n<p>2.配置erlang环境变量信息</p>\r\n<p>  新增环境变量ERLANG_HOME=erlang的安装地址</p>\r\n<p>  将%ERLANG_HOME%\\bin加入到path中</p>\r\n<p>3.下载并安装RabbitMQ，下载地址：<a href=\"http://www.rabbitmq.com/download.html\">http://www.rabbitmq.com/download.html</a></p>\r\n<p>注意: RabbitMQ 它依赖于Erlang,需要先安装Erlang。</p>\r\n<p>4。进入RabbitMQ安装目录下的sbin目录输入以下命令启动管理功能</p>\r\n<pre><code class=\"lang-Java\">rabbitmq-plugins <span class=\"hljs-built_in\">enable</span> rabbitmq_management\r\n</code></pre>\r\n<p><img src=\"https://www.ylcoder.top//upload/2022/1/image20220121074657352.png\" alt=\"\"></p>\r\n<p>然后双击运行 rabbitmq-server.bat</p>\r\n<p>5。 <a href=\"http://localhost:15672/\">http://localhost:15672/</a> 输入账号密码并登录：guest guest</p>\r\n<h1 id=\"linux\">linux</h1>\r\n<p><a href=\"https://blog.csdn.net/qq_26718271/article/details/76577356\">https://blog.csdn.net/qq_26718271/article/details/76577356</a></p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>时间从不会偏袒任何人，它给每个人的一天都是24小时。一样的时间，拉开人与人之间差距的，是对待时间的态度。</p>\r\n<p>你浪费时间，时间会忽略你；你重视时间，时间就会正视你。你跑到了许多人前面，成为了更好的自己，这就是时间给你最好的回馈。</p>\r\n<p>时间是公平的，当你消耗时间时，时间也正在默默抛弃你。你得过且过的每一步，浪费的每一分每一秒，都会让你走得越来越慢。</p>\r\n<p>山可移，海可填，日月既往不可复追。那些曾经攒在你手里的时间，那些本可以让你变得优秀的光阴，一旦浪费掉了，就再也没有了。</p>', '# 每日一句\r\nWisdom is knowing what to do next, skill is knowing how to do it, and virtue is doing it. \r\n智慧是知道下一步做什么，技能是知道如何做，而美德就是去做。\r\n\r\n# windows\r\n\r\n1.下载并安装erlang,下载地址：[https://www.erlang.org/downloads](https://www.erlang.org/downloads)\r\n\r\n2.配置erlang环境变量信息\r\n\r\n  新增环境变量ERLANG_HOME=erlang的安装地址\r\n\r\n  将%ERLANG_HOME%\\bin加入到path中\r\n\r\n3.下载并安装RabbitMQ，下载地址：[http://www.rabbitmq.com/download.html](http://www.rabbitmq.com/download.html)\r\n\r\n注意: RabbitMQ 它依赖于Erlang,需要先安装Erlang。\r\n\r\n4。进入RabbitMQ安装目录下的sbin目录输入以下命令启动管理功能\r\n\r\n```Java\r\nrabbitmq-plugins enable rabbitmq_management\r\n```\r\n\r\n![](https://www.ylcoder.top//upload/2022/1/image20220121074657352.png)\r\n\r\n然后双击运行 rabbitmq-server.bat\r\n\r\n5。 [http://localhost:15672/](http://localhost:15672/) 输入账号密码并登录：guest guest\r\n\r\n\r\n\r\n\r\n\r\n# linux\r\n\r\n[https://blog.csdn.net/qq_26718271/article/details/76577356](https://blog.csdn.net/qq_26718271/article/details/76577356)\r\n\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n时间从不会偏袒任何人，它给每个人的一天都是24小时。一样的时间，拉开人与人之间差距的，是对待时间的态度。\r\n\r\n你浪费时间，时间会忽略你；你重视时间，时间就会正视你。你跑到了许多人前面，成为了更好的自己，这就是时间给你最好的回馈。\r\n\r\n时间是公平的，当你消耗时间时，时间也正在默默抛弃你。你得过且过的每一步，浪费的每一分每一秒，都会让你走得越来越慢。\r\n\r\n山可移，海可填，日月既往不可复追。那些曾经攒在你手里的时间，那些本可以让你变得优秀的光阴，一旦浪费掉了，就再也没有了。', '2022-01-21 01:58:06', 0, '每日一句Wisdomisknowingwhattodonext,skillisknowinghowt', '/static/img/rand/2.jpg', 'RabbitMQ 环境安装', 0, 'post', 0, '2022-01-21 01:58:37', '1642751885', 10);
INSERT INTO `blog_article` VALUES (166, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>You must try things that may not work. And you must not let anyone define your limits because of where you come from. Your only limit is your soul.<br>千万不要怕失败，也不要因为出身低就让别人限制了你的发展，成败在于你自己。</p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。</p>\r\n<p>常见的消息中间件有：</p>\r\n<ol>\r\n<li>ActiveMQ</li>\r\n<li>RabbitMQ</li>\r\n<li>Kafka</li>\r\n<li>RocketMQ</li>\r\n</ol>\r\n<h1 id=\"-http-\">传统Http协议调用接口存在的缺陷</h1>\r\n<p>传统方式 采用同步的形式调用接口，如果调用的过程非常耗时间的话，客户需要等待非常久的时间才会响应；这样对客户端体验非常不好。</p>\r\n<p>比如用户注册 调用数据库新增插入会员信息需要3s、调用优惠券接口需要3s、调用第三方短信接口需要3s  一共需要9s的时间才会返回信息，这样用户的体验是非常不好；</p>\r\n<h1 id=\"mq-\">MQ 的作用</h1>\r\n<p>通常我们采用MQ来进行以下操作</p>\r\n<ul>\r\n<li>流量削峰</li>\r\n<li>应用解耦</li>\r\n<li>异步调用</li>\r\n</ul>\r\n<h2 id=\"-\">流量削峰</h2>\r\n<p>如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。</p>\r\n<p>但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。</p>\r\n<p>使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好</p>\r\n<h2 id=\"-\">应用解耦</h2>\r\n<p>以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。</p>\r\n<p>当转变成基于消息队列的方式后，系统间调用的问题会减少很多。</p>\r\n<ul>\r\n<li>物流系统因为发生故障，需要几分钟来修复。</li>\r\n<li>在这几分钟的时间里，物流系统要处理的内容被缓存在消息队列中，用户的下单操作可以正常完成。</li>\r\n<li>当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性</li>\r\n</ul>\r\n<h2 id=\"-\">异步处理</h2>\r\n<p>有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完。</p>\r\n<p>以前一般有两种方式：</p>\r\n<ul>\r\n<li>A 过一段时间去调用 B 的查询 api 查询。</li>\r\n<li>A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。</li>\r\n</ul>\r\n<p>这两种方式都不是很优雅，使用消息总线，可以很方便解决这个问题。</p>\r\n<ul>\r\n<li>A 调用 B 服务后，只需要监听 B 处理完成的消息</li>\r\n<li>当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此消息转发给 A 服务。</li>\r\n</ul>\r\n<p>这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样B 服务也不用做这些操作。A 服务还能及时的得到异步处理成功的消息。</p>\r\n<h1 id=\"-mq-\">常见的 MQ 对比分析</h1>\r\n<p>1.Kafka</p>\r\n<p>Kafka 主要特点是基于Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。</p>\r\n<p>大型公司建议可以选用，如果有日志采集功能，肯定是首选 kafka 了。</p>\r\n<p>2.RocketMQ</p>\r\n<p>天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。</p>\r\n<p>3.RabbitMQ</p>\r\n<p>结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。</p>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>苏轼曾经说过：“古之立大事者，不惟有超世之才，亦必有坚忍不拔之志。”我们或许无法有出类拔萃的才能，但我们都可以有坚韧不拔的意志。已经努力了一年，也许现在的你有些累了，但每个人的人生都需要砥砺前行，无论何时，都不要轻言放弃。请相信，你的坚持，不会被辜负。</p>\r\n<p>如果时光可以倒流，很多人想做的，只是过好当时的那一刻。</p>', '# 每日一句\r\nYou must try things that may not work. And you must not let anyone define your limits because of where you come from. Your only limit is your soul. \r\n千万不要怕失败，也不要因为出身低就让别人限制了你的发展，成败在于你自己。\r\n\r\n# 概述\r\n\r\n消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。\r\n\r\n常见的消息中间件有：\r\n\r\n1. ActiveMQ\r\n2. RabbitMQ\r\n3. Kafka\r\n4. RocketMQ\r\n\r\n# 传统Http协议调用接口存在的缺陷\r\n\r\n传统方式 采用同步的形式调用接口，如果调用的过程非常耗时间的话，客户需要等待非常久的时间才会响应；这样对客户端体验非常不好。\r\n\r\n比如用户注册 调用数据库新增插入会员信息需要3s、调用优惠券接口需要3s、调用第三方短信接口需要3s  一共需要9s的时间才会返回信息，这样用户的体验是非常不好；\r\n\r\n# MQ 的作用\r\n\r\n通常我们采用MQ来进行以下操作\r\n\r\n- 流量削峰\r\n- 应用解耦\r\n- 异步调用\r\n\r\n\r\n\r\n## 流量削峰\r\n\r\n如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。\r\n\r\n但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。\r\n\r\n使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好\r\n\r\n\r\n\r\n## 应用解耦\r\n\r\n以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。\r\n\r\n当转变成基于消息队列的方式后，系统间调用的问题会减少很多。\r\n\r\n- 物流系统因为发生故障，需要几分钟来修复。\r\n- 在这几分钟的时间里，物流系统要处理的内容被缓存在消息队列中，用户的下单操作可以正常完成。\r\n- 当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性\r\n\r\n\r\n\r\n## 异步处理\r\n\r\n有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完。\r\n\r\n以前一般有两种方式：\r\n\r\n- A 过一段时间去调用 B 的查询 api 查询。\r\n- A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。\r\n\r\n\r\n\r\n这两种方式都不是很优雅，使用消息总线，可以很方便解决这个问题。\r\n\r\n- A 调用 B 服务后，只需要监听 B 处理完成的消息\r\n- 当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此消息转发给 A 服务。\r\n\r\n\r\n\r\n这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样B 服务也不用做这些操作。A 服务还能及时的得到异步处理成功的消息。\r\n\r\n# 常见的 MQ 对比分析\r\n\r\n1.Kafka\r\n\r\nKafka 主要特点是基于Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。\r\n\r\n大型公司建议可以选用，如果有日志采集功能，肯定是首选 kafka 了。\r\n\r\n2.RocketMQ\r\n\r\n天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。\r\n\r\n3.RabbitMQ\r\n\r\n结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n苏轼曾经说过：“古之立大事者，不惟有超世之才，亦必有坚忍不拔之志。”我们或许无法有出类拔萃的才能，但我们都可以有坚韧不拔的意志。已经努力了一年，也许现在的你有些累了，但每个人的人生都需要砥砺前行，无论何时，都不要轻言放弃。请相信，你的坚持，不会被辜负。\r\n\r\n如果时光可以倒流，很多人想做的，只是过好当时的那一刻。', '2022-01-22 03:04:55', 0, '每日一句Youmusttrythingsthatmaynotwork.Andyoumustnotle', '/static/img/rand/13.jpg', 'MQ 简介', 0, 'post', 0, '2022-01-22 03:04:55', '1642842295', 10);
INSERT INTO `blog_article` VALUES (167, 9, '<h1 id=\"-\">每日一句</h1>\r\n<p>Human beings are designed for many things, but loneliness isn&#39;t one of them.<br>人类能应对许多问题，但孤独并不在其中。</p>\r\n<h1 id=\"-\">概述</h1>\r\n<p>RabbitMQ 是一个消息中间件：它接受并转发消息。类比于快递站点，当你要发送一个包裹时，你把你的包裹放到快递站，快递员最终会把你的快递送到收件人那里，按照这种逻辑 RabbitMQ 是一个快递站，一个快递员帮你传递快件。</p>\r\n<p>RabbitMQ 与快递站的主要区别在于，它不处理快件而是接收，存储和转发消息数据。</p>\r\n<h1 id=\"-\">几个核心概念</h1>\r\n<ul>\r\n<li>生产者与消费者</li>\r\n<li>交换机</li>\r\n<li>队列</li>\r\n</ul>\r\n<h2 id=\"-\">生产者与消费者</h2>\r\n<p>生产者：向队列发送消息的一方。发布消息的最终目的在于将消息内容传递给其他系统/模块，使对方按照约定处理该消息。</p>\r\n<p>消费者：消费者大多时候是一个等待接收消息的程序。很多时候生产者，消费者和消息中间件并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。接收消息的一方。当消费者消费一条消息时，只是消费消息的消息体。在消息路由的过程中，会丢弃标签，存入到队列中的只有消息体。</p>\r\n<h2 id=\"-\">交换机</h2>\r\n<p>交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。</p>\r\n<p>交换机必须确切知道如何处理它接收到的消息，由交换机类型决定是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃.</p>\r\n<h2 id=\"-\">队列</h2>\r\n<p>队列是用于存储消息的，生产者将消息送到队列，消费者从队列中获取和消费消息。多个消费者可以同时订阅同一个队列，队列里的消息分配给不同的消费者。</p>\r\n<p>队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。</p>\r\n<h1 id=\"-\">名词介绍</h1>\r\n<ul>\r\n<li><strong>Broker</strong>：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker</li>\r\n<li><strong>Virtual host</strong>：虚拟地址，用于进行逻辑隔离，是最上层的消息路由。一个 Virtual Host 里面可以有若干个 Exchange 和 Queue，同一个 Virtual Host 里面不能有相同名称的 Exchange 或 Queue</li>\r\n<li><strong>Connection</strong>：连接，应用程序与 Broker 的网络连接</li>\r\n<li><strong>Channel</strong>：网络信道，几乎所有的操作都在 Channel 中进行，Channel 是进行消息读写的通道。客户端可建立多个 Channel，每个Channel 代表一个会话任务；</li>\r\n<li><strong>Exchange</strong>：交换机，负责接收消息，根据路由键将消息转发到绑定的队列；</li>\r\n<li><strong>Queue</strong>：也称 Message Queue，消息队列，保存消息并将它们转发给消费者。</li>\r\n<li><strong>Binding</strong>：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据</li>\r\n</ul>\r\n<h1 id=\"-\">美文佳句</h1>\r\n<p>人们常说：“念念不忘，必有回响。”只要信念一直在，就总有被回应的一天。比别人多一点努力，你就会多一点成绩；比别人多一点执着，你就会多一点机会；比别人多一点坚持，你就会多一点收获。</p>', '# 每日一句\r\nHuman beings are designed for many things, but loneliness isn\'t one of them. \r\n人类能应对许多问题，但孤独并不在其中。\r\n\r\n# 概述\r\n\r\nRabbitMQ 是一个消息中间件：它接受并转发消息。类比于快递站点，当你要发送一个包裹时，你把你的包裹放到快递站，快递员最终会把你的快递送到收件人那里，按照这种逻辑 RabbitMQ 是一个快递站，一个快递员帮你传递快件。\r\n\r\nRabbitMQ 与快递站的主要区别在于，它不处理快件而是接收，存储和转发消息数据。\r\n\r\n\r\n\r\n# 几个核心概念\r\n\r\n- 生产者与消费者\r\n- 交换机\r\n- 队列\r\n\r\n\r\n\r\n## 生产者与消费者\r\n\r\n生产者：向队列发送消息的一方。发布消息的最终目的在于将消息内容传递给其他系统/模块，使对方按照约定处理该消息。\r\n\r\n消费者：消费者大多时候是一个等待接收消息的程序。很多时候生产者，消费者和消息中间件并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。接收消息的一方。当消费者消费一条消息时，只是消费消息的消息体。在消息路由的过程中，会丢弃标签，存入到队列中的只有消息体。\r\n\r\n\r\n\r\n## 交换机\r\n\r\n交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。\r\n\r\n交换机必须确切知道如何处理它接收到的消息，由交换机类型决定是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃.\r\n\r\n\r\n\r\n## 队列\r\n\r\n队列是用于存储消息的，生产者将消息送到队列，消费者从队列中获取和消费消息。多个消费者可以同时订阅同一个队列，队列里的消息分配给不同的消费者。\r\n\r\n队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。\r\n\r\n\r\n\r\n# 名词介绍\r\n\r\n- **Broker**：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker\r\n- **Virtual host**：虚拟地址，用于进行逻辑隔离，是最上层的消息路由。一个 Virtual Host 里面可以有若干个 Exchange 和 Queue，同一个 Virtual Host 里面不能有相同名称的 Exchange 或 Queue\r\n- **Connection**：连接，应用程序与 Broker 的网络连接\r\n- **Channel**：网络信道，几乎所有的操作都在 Channel 中进行，Channel 是进行消息读写的通道。客户端可建立多个 Channel，每个Channel 代表一个会话任务；\r\n- **Exchange**：交换机，负责接收消息，根据路由键将消息转发到绑定的队列；\r\n- **Queue**：也称 Message Queue，消息队列，保存消息并将它们转发给消费者。\r\n- **Binding**：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据\r\n\r\n\r\n\r\n\r\n# 美文佳句\r\n\r\n人们常说：“念念不忘，必有回响。”只要信念一直在，就总有被回应的一天。比别人多一点努力，你就会多一点成绩；比别人多一点执着，你就会多一点机会；比别人多一点坚持，你就会多一点收获。', '2022-01-22 03:05:16', 0, '每日一句Humanbeingsaredesignedformanythings,butlonelin', '/static/img/rand/9.jpg', 'RabbitMQ 相关概念', 0, 'post', 0, '2022-01-22 03:05:16', '1642842315', 10);

-- ----------------------------
-- Table structure for blog_article_category
-- ----------------------------
DROP TABLE IF EXISTS `blog_article_category`;
CREATE TABLE `blog_article_category`  (
  `article_id` int(20) NOT NULL,
  `category_id` bigint(20) NOT NULL,
  INDEX `blog_ARTILE_ID`(`article_id`) USING BTREE,
  INDEX `blog_ARTILE_CATEGORY_ID`(`category_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_article_category
-- ----------------------------
INSERT INTO `blog_article_category` VALUES (148, 20);
INSERT INTO `blog_article_category` VALUES (149, 20);
INSERT INTO `blog_article_category` VALUES (147, 21);
INSERT INTO `blog_article_category` VALUES (150, 20);
INSERT INTO `blog_article_category` VALUES (151, 20);
INSERT INTO `blog_article_category` VALUES (152, 20);
INSERT INTO `blog_article_category` VALUES (153, 20);
INSERT INTO `blog_article_category` VALUES (154, 20);
INSERT INTO `blog_article_category` VALUES (155, 20);
INSERT INTO `blog_article_category` VALUES (156, 22);
INSERT INTO `blog_article_category` VALUES (161, 23);
INSERT INTO `blog_article_category` VALUES (162, 23);
INSERT INTO `blog_article_category` VALUES (163, 23);
INSERT INTO `blog_article_category` VALUES (164, 24);
INSERT INTO `blog_article_category` VALUES (165, 24);
INSERT INTO `blog_article_category` VALUES (166, 24);
INSERT INTO `blog_article_category` VALUES (167, 24);

-- ----------------------------
-- Table structure for blog_article_tag
-- ----------------------------
DROP TABLE IF EXISTS `blog_article_tag`;
CREATE TABLE `blog_article_tag`  (
  `article_id` int(20) NOT NULL,
  `tag_id` bigint(20) NOT NULL,
  INDEX `blog_ARTILE_ID`(`article_id`) USING BTREE,
  INDEX `blog_ARTILE_TAG_ID`(`tag_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_article_tag
-- ----------------------------
INSERT INTO `blog_article_tag` VALUES (148, 20);
INSERT INTO `blog_article_tag` VALUES (149, 21);
INSERT INTO `blog_article_tag` VALUES (147, 22);

-- ----------------------------
-- Table structure for blog_attachment
-- ----------------------------
DROP TABLE IF EXISTS `blog_attachment`;
CREATE TABLE `blog_attachment`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `picture_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '图片名称',
  `picture_path` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '图片路径',
  `picture_small_path` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '略缩图',
  `picture_type` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '图片类型',
  `picture_create_date` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '上传时间',
  `picture_size` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '文件大小',
  `picture_suffix` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '后缀',
  `picture_wh` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '尺寸',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 257 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_attachment
-- ----------------------------
INSERT INTO `blog_attachment` VALUES (249, '27GinHHsJkpXpj8o1FJi262021121503494347.png', '/upload/2021/12/27GinHHsJkpXpj8o1FJi262021121503494347.png', '/upload/2021/12/27GinHHsJkpXpj8o1FJi262021121503494347_small.png', 'image/png', '2021-12-14 21:49:43.147', '69KB', '.png', '1520x856');
INSERT INTO `blog_attachment` VALUES (251, '2021122905555920211228215801223.png', '/upload/2021/12/2021122905555920211228215801223.png', '/upload/2021/12/2021122905555920211228215801223_small.png', 'image/png', '2021-12-28 15:58:01.167', '66KB', '.png', '1084x384');
INSERT INTO `blog_attachment` VALUES (252, 'portrait20220101194446747.jpg', '/upload/2022/1/portrait20220101194446747.jpg', '/upload/2022/1/portrait20220101194446747_small.jpg', 'image/jpeg', '2022-01-01 13:44:46.536', '28KB', '.jpg', '460x460');
INSERT INTO `blog_attachment` VALUES (253, 'image20220120111708135.png', '/upload/2022/1/image20220120111708135.png', '/upload/2022/1/image20220120111708135_small.png', 'image/png', '2022-01-20 05:17:08.236', '83KB', '.png', '857x269');
INSERT INTO `blog_attachment` VALUES (254, 'image20220121074657352.png', '/upload/2022/1/image20220121074657352.png', '/upload/2022/1/image20220121074657352_small.png', 'image/png', '2022-01-21 01:46:57.785', '52KB', '.png', '1009x459');
INSERT INTO `blog_attachment` VALUES (255, 'image20220122071346233.png', '/upload/2022/1/image20220122071346233.png', '/upload/2022/1/image20220122071346233_small.png', 'image/png', '2022-01-22 01:13:46.546', '37KB', '.png', '574x312');
INSERT INTO `blog_attachment` VALUES (256, 'image20220122071838859.png', '/upload/2022/1/image20220122071838859.png', '/upload/2022/1/image20220122071838859_small.png', 'image/png', '2022-01-22 01:18:38.307', '46KB', '.png', '1296x760');

-- ----------------------------
-- Table structure for blog_category
-- ----------------------------
DROP TABLE IF EXISTS `blog_category`;
CREATE TABLE `blog_category`  (
  `category_id` int(11) NOT NULL AUTO_INCREMENT,
  `category_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '分类名称',
  `category_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '分类路径',
  `category_describe` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '描述',
  PRIMARY KEY (`category_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 25 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_category
-- ----------------------------
INSERT INTO `blog_category` VALUES (20, '公众号', 'wechat', '公众号文章同步发表。');
INSERT INTO `blog_category` VALUES (21, '工具', 'tools', '各种工具 开发工具 性能压测工具等');
INSERT INTO `blog_category` VALUES (22, '年度总结', 'summary', '每年一篇总结。');
INSERT INTO `blog_category` VALUES (23, 'MongoDB', 'mongodb', 'MongoDB 相关文章');
INSERT INTO `blog_category` VALUES (24, 'RabbitMQ', 'RabbitMQ', '');

-- ----------------------------
-- Table structure for blog_link
-- ----------------------------
DROP TABLE IF EXISTS `blog_link`;
CREATE TABLE `blog_link`  (
  `link_id` int(11) NOT NULL AUTO_INCREMENT,
  `link_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '名称',
  `link_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '路径',
  `link_logo` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '链接logo',
  `link_describe` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '描述',
  PRIMARY KEY (`link_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 48 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for blog_logs
-- ----------------------------
DROP TABLE IF EXISTS `blog_logs`;
CREATE TABLE `blog_logs`  (
  `log_id` int(11) NOT NULL AUTO_INCREMENT,
  `log_title` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '标题',
  `log_content` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '内容',
  `log_ip` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT 'ip',
  `log_date` datetime(0) NULL DEFAULT NULL COMMENT '时间',
  PRIMARY KEY (`log_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1044 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_logs
-- ----------------------------
INSERT INTO `blog_logs` VALUES (892, '安装blog', '操作成功', '117.173.227.25', '2021-11-25 04:06:51');
INSERT INTO `blog_logs` VALUES (893, '登录后台', '登录失败', '117.172.223.239', '2021-12-13 09:24:08');
INSERT INTO `blog_logs` VALUES (894, '登录后台', '登录失败', '117.172.223.239', '2021-12-13 09:24:12');
INSERT INTO `blog_logs` VALUES (895, '登录后台', '登录失败', '117.172.223.239', '2021-12-13 09:24:23');
INSERT INTO `blog_logs` VALUES (896, '登录后台', '登录失败', '0:0:0:0:0:0:0:1', '2021-12-13 09:27:06');
INSERT INTO `blog_logs` VALUES (897, '登录后台', '登录成功', '0:0:0:0:0:0:0:1', '2021-12-13 09:37:00');
INSERT INTO `blog_logs` VALUES (898, '登录后台', '登录成功', '117.172.223.239', '2021-12-13 09:37:03');
INSERT INTO `blog_logs` VALUES (899, '登录后台', '登录成功', '117.172.223.239', '2021-12-13 17:00:13');
INSERT INTO `blog_logs` VALUES (900, '登录后台', '登录成功', '117.172.223.239', '2021-12-14 15:09:49');
INSERT INTO `blog_logs` VALUES (901, '上传附件', '上传成功', '117.172.223.239', '2021-12-14 15:15:26');
INSERT INTO `blog_logs` VALUES (902, '发表文章', '操作成功', '117.172.223.239', '2021-12-14 15:22:07');
INSERT INTO `blog_logs` VALUES (903, '登录后台', '登录成功', '117.172.223.239', '2021-12-14 20:24:56');
INSERT INTO `blog_logs` VALUES (904, '更新文章', '操作成功', '117.172.223.239', '2021-12-14 20:25:29');
INSERT INTO `blog_logs` VALUES (905, '更新文章', '操作成功', '117.172.223.239', '2021-12-14 20:26:33');
INSERT INTO `blog_logs` VALUES (906, '上传附件', '上传成功', '117.172.223.239', '2021-12-14 20:29:31');
INSERT INTO `blog_logs` VALUES (907, '登录后台', '登录成功', '117.172.223.239', '2021-12-14 21:04:37');
INSERT INTO `blog_logs` VALUES (908, '上传附件', '上传成功', '117.172.223.239', '2021-12-14 21:05:05');
INSERT INTO `blog_logs` VALUES (909, '登录后台', '登录成功', '117.172.223.239', '2021-12-14 21:27:04');
INSERT INTO `blog_logs` VALUES (910, '上传附件', '上传成功', '117.172.223.239', '2021-12-14 21:29:11');
INSERT INTO `blog_logs` VALUES (911, '登录后台', '登录成功', '117.172.223.239', '2021-12-14 21:39:21');
INSERT INTO `blog_logs` VALUES (912, '登录后台', '登录成功', '117.172.223.239', '2021-12-14 21:48:22');
INSERT INTO `blog_logs` VALUES (913, '登录后台', '登录成功', '117.172.223.239', '2021-12-14 21:49:12');
INSERT INTO `blog_logs` VALUES (914, '删除附件', '删除成功', '117.172.223.239', '2021-12-14 21:49:19');
INSERT INTO `blog_logs` VALUES (915, '删除附件', '删除成功', '117.172.223.239', '2021-12-14 21:49:24');
INSERT INTO `blog_logs` VALUES (916, '删除附件', '删除成功', '117.172.223.239', '2021-12-14 21:49:28');
INSERT INTO `blog_logs` VALUES (917, '删除附件', '删除成功', '117.172.223.239', '2021-12-14 21:49:32');
INSERT INTO `blog_logs` VALUES (918, '上传附件', '上传成功', '117.172.223.239', '2021-12-14 21:49:44');
INSERT INTO `blog_logs` VALUES (919, '更新文章', '操作成功', '117.172.223.239', '2021-12-14 21:50:30');
INSERT INTO `blog_logs` VALUES (920, '登录后台', '登录成功', '117.172.223.239', '2021-12-15 10:57:16');
INSERT INTO `blog_logs` VALUES (921, '登录后台', '登录成功', '117.172.223.239', '2021-12-15 11:40:25');
INSERT INTO `blog_logs` VALUES (922, '登录后台', '登录成功', '117.172.223.239', '2021-12-16 07:02:26');
INSERT INTO `blog_logs` VALUES (923, '发表文章', '操作成功', '117.172.223.239', '2021-12-16 07:03:44');
INSERT INTO `blog_logs` VALUES (924, '更新文章', '操作成功', '117.172.223.239', '2021-12-16 07:09:13');
INSERT INTO `blog_logs` VALUES (925, '更新文章', '操作成功', '117.172.223.239', '2021-12-16 07:12:03');
INSERT INTO `blog_logs` VALUES (926, '登录后台', '登录成功', '117.172.223.239', '2021-12-16 07:28:49');
INSERT INTO `blog_logs` VALUES (927, '发表文章', '操作成功', '117.172.223.239', '2021-12-16 07:36:41');
INSERT INTO `blog_logs` VALUES (928, '更新文章', '操作成功', '117.172.223.239', '2021-12-16 07:38:52');
INSERT INTO `blog_logs` VALUES (929, '发表文章', '操作成功', '117.172.223.239', '2021-12-16 07:41:46');
INSERT INTO `blog_logs` VALUES (930, '登录后台', '登录成功', '117.172.223.223', '2021-12-20 03:15:06');
INSERT INTO `blog_logs` VALUES (931, '登录后台', '登录成功', '117.172.223.209', '2021-12-21 01:44:21');
INSERT INTO `blog_logs` VALUES (932, '发表文章', '操作成功', '117.172.223.209', '2021-12-21 01:45:05');
INSERT INTO `blog_logs` VALUES (933, '发表文章', '操作成功', '117.172.223.209', '2021-12-21 01:53:53');
INSERT INTO `blog_logs` VALUES (934, '发表文章', '操作成功', '117.172.223.209', '2021-12-21 02:02:43');
INSERT INTO `blog_logs` VALUES (935, '发表文章', '操作成功', '117.172.223.209', '2021-12-21 02:23:10');
INSERT INTO `blog_logs` VALUES (936, '更新文章', '操作成功', '117.172.223.209', '2021-12-21 02:35:34');
INSERT INTO `blog_logs` VALUES (937, '发表文章', '操作成功', '117.172.223.209', '2021-12-21 02:41:14');
INSERT INTO `blog_logs` VALUES (938, '登录后台', '登录成功', '117.172.223.46', '2021-12-28 15:51:23');
INSERT INTO `blog_logs` VALUES (939, '上传附件', '上传成功', '117.172.223.46', '2021-12-28 15:56:17');
INSERT INTO `blog_logs` VALUES (940, '删除附件', '删除成功', '117.172.223.46', '2021-12-28 15:57:40');
INSERT INTO `blog_logs` VALUES (941, '上传附件', '上传成功', '117.172.223.46', '2021-12-28 15:58:01');
INSERT INTO `blog_logs` VALUES (942, '登录后台', '登录成功', '117.172.223.46', '2021-12-31 04:31:06');
INSERT INTO `blog_logs` VALUES (943, '发表文章', '操作成功', '117.172.223.46', '2021-12-31 04:48:49');
INSERT INTO `blog_logs` VALUES (944, '登录后台', '登录成功', '117.172.223.46', '2022-01-01 06:56:25');
INSERT INTO `blog_logs` VALUES (945, '登录后台', '登录成功', '117.172.223.46', '2022-01-01 13:31:59');
INSERT INTO `blog_logs` VALUES (946, '上传附件', '上传成功', '117.172.223.46', '2022-01-01 13:44:47');
INSERT INTO `blog_logs` VALUES (947, '安装blog', '操作成功', '117.172.223.46', '2022-01-02 08:19:51');
INSERT INTO `blog_logs` VALUES (948, '登录后台', '登录成功', '117.172.223.46', '2022-01-02 08:22:45');
INSERT INTO `blog_logs` VALUES (949, '登录后台', '登录成功', '117.172.223.46', '2022-01-02 09:09:58');
INSERT INTO `blog_logs` VALUES (950, '登录后台', '登录成功', '0:0:0:0:0:0:0:1', '2022-01-15 01:15:11');
INSERT INTO `blog_logs` VALUES (951, '登录后台', '登录成功', '0:0:0:0:0:0:0:1', '2022-01-15 01:21:01');
INSERT INTO `blog_logs` VALUES (952, '登录后台', '登录成功', '0:0:0:0:0:0:0:1', '2022-01-15 01:27:27');
INSERT INTO `blog_logs` VALUES (953, '登录后台', '登录成功', '0:0:0:0:0:0:0:1', '2022-01-15 01:49:21');
INSERT INTO `blog_logs` VALUES (954, '登录后台', '登录成功', '0:0:0:0:0:0:0:1', '2022-01-15 02:01:03');
INSERT INTO `blog_logs` VALUES (955, '登录后台', '登录成功', '117.172.223.196', '2022-01-17 03:43:32');
INSERT INTO `blog_logs` VALUES (956, '发表文章', '操作成功', '117.172.223.196', '2022-01-17 03:50:38');
INSERT INTO `blog_logs` VALUES (957, '发布页面', '操作成功', '117.172.223.196', '2022-01-17 03:59:37');
INSERT INTO `blog_logs` VALUES (958, '更新页面', '操作成功', '117.172.223.196', '2022-01-17 04:00:12');
INSERT INTO `blog_logs` VALUES (959, '更新页面', '操作成功', '117.172.223.196', '2022-01-17 04:01:03');
INSERT INTO `blog_logs` VALUES (960, '登录后台', '登录成功', '117.172.223.196', '2022-01-17 08:17:33');
INSERT INTO `blog_logs` VALUES (961, '登录后台', '登录成功', '117.172.223.225', '2022-01-18 21:38:51');
INSERT INTO `blog_logs` VALUES (962, '发表文章', '操作成功', '117.172.223.225', '2022-01-18 21:40:06');
INSERT INTO `blog_logs` VALUES (963, '发表文章', '操作成功', '117.172.223.225', '2022-01-18 21:40:54');
INSERT INTO `blog_logs` VALUES (964, '登录后台', '登录成功', '117.172.223.225', '2022-01-19 00:44:51');
INSERT INTO `blog_logs` VALUES (965, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 00:47:11');
INSERT INTO `blog_logs` VALUES (966, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 00:51:47');
INSERT INTO `blog_logs` VALUES (967, '更新文章', '操作成功', '117.172.223.225', '2022-01-19 00:57:39');
INSERT INTO `blog_logs` VALUES (968, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 00:59:43');
INSERT INTO `blog_logs` VALUES (969, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 00:59:57');
INSERT INTO `blog_logs` VALUES (970, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 01:00:12');
INSERT INTO `blog_logs` VALUES (971, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 01:00:31');
INSERT INTO `blog_logs` VALUES (972, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 01:01:17');
INSERT INTO `blog_logs` VALUES (973, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 01:04:15');
INSERT INTO `blog_logs` VALUES (974, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 01:11:03');
INSERT INTO `blog_logs` VALUES (975, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 01:12:38');
INSERT INTO `blog_logs` VALUES (976, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 01:14:02');
INSERT INTO `blog_logs` VALUES (977, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 01:20:43');
INSERT INTO `blog_logs` VALUES (978, '登录后台', '登录成功', '117.172.223.225', '2022-01-19 21:12:16');
INSERT INTO `blog_logs` VALUES (979, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 21:12:45');
INSERT INTO `blog_logs` VALUES (980, '发表文章', '操作成功', '117.172.223.225', '2022-01-19 21:13:31');
INSERT INTO `blog_logs` VALUES (981, '登录后台', '登录成功', '117.172.223.225', '2022-01-20 05:08:52');
INSERT INTO `blog_logs` VALUES (982, '发表文章', '操作成功', '117.172.223.225', '2022-01-20 05:09:13');
INSERT INTO `blog_logs` VALUES (983, '发表文章', '操作成功', '117.172.223.225', '2022-01-20 05:12:23');
INSERT INTO `blog_logs` VALUES (984, '发表文章', '操作成功', '117.172.223.225', '2022-01-20 05:15:29');
INSERT INTO `blog_logs` VALUES (985, '发表文章', '操作成功', '117.172.223.225', '2022-01-20 05:15:41');
INSERT INTO `blog_logs` VALUES (986, '发表文章', '操作成功', '117.172.223.225', '2022-01-20 05:15:51');
INSERT INTO `blog_logs` VALUES (987, '上传附件', '上传成功', '117.172.223.225', '2022-01-20 05:17:09');
INSERT INTO `blog_logs` VALUES (988, '发表文章', '操作成功', '117.172.223.225', '2022-01-20 05:17:52');
INSERT INTO `blog_logs` VALUES (989, '登录后台', '登录成功', '117.172.223.225', '2022-01-21 01:46:46');
INSERT INTO `blog_logs` VALUES (990, '上传附件', '上传成功', '117.172.223.225', '2022-01-21 01:46:58');
INSERT INTO `blog_logs` VALUES (991, '发表文章', '操作成功', '117.172.223.225', '2022-01-21 01:58:06');
INSERT INTO `blog_logs` VALUES (992, '更新文章', '操作成功', '117.172.223.225', '2022-01-21 01:58:37');
INSERT INTO `blog_logs` VALUES (993, '登录后台', '登录成功', '117.172.223.225', '2022-01-22 01:06:50');
INSERT INTO `blog_logs` VALUES (994, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:07:57');
INSERT INTO `blog_logs` VALUES (995, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:09:57');
INSERT INTO `blog_logs` VALUES (996, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:12:55');
INSERT INTO `blog_logs` VALUES (997, '上传附件', '上传成功', '117.172.223.225', '2022-01-22 01:13:47');
INSERT INTO `blog_logs` VALUES (998, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:14:22');
INSERT INTO `blog_logs` VALUES (999, '更新文章', '操作成功', '117.172.223.225', '2022-01-22 01:16:04');
INSERT INTO `blog_logs` VALUES (1000, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:16:52');
INSERT INTO `blog_logs` VALUES (1001, '上传附件', '上传成功', '117.172.223.225', '2022-01-22 01:18:39');
INSERT INTO `blog_logs` VALUES (1002, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:19:01');
INSERT INTO `blog_logs` VALUES (1003, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:19:49');
INSERT INTO `blog_logs` VALUES (1004, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:22:20');
INSERT INTO `blog_logs` VALUES (1005, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:28:44');
INSERT INTO `blog_logs` VALUES (1006, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:32:07');
INSERT INTO `blog_logs` VALUES (1007, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:49:01');
INSERT INTO `blog_logs` VALUES (1008, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 01:49:49');
INSERT INTO `blog_logs` VALUES (1009, '登录后台', '登录成功', '117.172.223.225', '2022-01-22 03:04:16');
INSERT INTO `blog_logs` VALUES (1010, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 03:04:55');
INSERT INTO `blog_logs` VALUES (1011, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 03:05:16');
INSERT INTO `blog_logs` VALUES (1012, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 03:29:17');
INSERT INTO `blog_logs` VALUES (1013, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 03:36:30');
INSERT INTO `blog_logs` VALUES (1014, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 03:38:00');
INSERT INTO `blog_logs` VALUES (1015, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 03:40:50');
INSERT INTO `blog_logs` VALUES (1016, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 03:41:20');
INSERT INTO `blog_logs` VALUES (1017, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 03:43:19');
INSERT INTO `blog_logs` VALUES (1018, '发表文章', '操作成功', '117.172.223.225', '2022-01-22 03:43:49');
INSERT INTO `blog_logs` VALUES (1019, '登录后台', '登录成功', '117.172.223.225', '2022-01-22 04:30:41');
INSERT INTO `blog_logs` VALUES (1020, '登录后台', '登录成功', '117.172.223.199', '2022-02-03 02:59:53');
INSERT INTO `blog_logs` VALUES (1021, '登录后台', '登录成功', '117.172.223.199', '2022-02-03 04:04:23');
INSERT INTO `blog_logs` VALUES (1022, '登录后台', '登录成功', '117.172.223.199', '2022-02-04 02:17:57');
INSERT INTO `blog_logs` VALUES (1023, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 02:29:29');
INSERT INTO `blog_logs` VALUES (1024, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 02:31:30');
INSERT INTO `blog_logs` VALUES (1025, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 02:32:50');
INSERT INTO `blog_logs` VALUES (1026, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 02:33:34');
INSERT INTO `blog_logs` VALUES (1027, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 02:38:26');
INSERT INTO `blog_logs` VALUES (1028, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 02:38:37');
INSERT INTO `blog_logs` VALUES (1029, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 02:53:31');
INSERT INTO `blog_logs` VALUES (1030, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 03:01:36');
INSERT INTO `blog_logs` VALUES (1031, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 03:11:04');
INSERT INTO `blog_logs` VALUES (1032, '登录后台', '登录成功', '117.172.223.199', '2022-02-04 03:48:23');
INSERT INTO `blog_logs` VALUES (1033, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 03:48:52');
INSERT INTO `blog_logs` VALUES (1034, '发表文章', '操作成功', '117.172.223.199', '2022-02-04 04:04:45');
INSERT INTO `blog_logs` VALUES (1035, '更新文章', '操作成功', '117.172.223.199', '2022-02-04 04:05:45');
INSERT INTO `blog_logs` VALUES (1036, '登录后台', '登录成功', '117.172.223.199', '2022-02-04 04:50:08');
INSERT INTO `blog_logs` VALUES (1037, '登录后台', '登录成功', '117.172.223.199', '2022-02-04 05:00:11');
INSERT INTO `blog_logs` VALUES (1038, '登录后台', '登录成功', '117.172.223.199', '2022-02-05 03:08:01');
INSERT INTO `blog_logs` VALUES (1039, '发表文章', '操作成功', '117.172.223.199', '2022-02-05 03:08:22');
INSERT INTO `blog_logs` VALUES (1040, '发表文章', '操作成功', '117.172.223.199', '2022-02-05 03:34:42');
INSERT INTO `blog_logs` VALUES (1041, '登录后台', '登录成功', '117.172.223.199', '2022-02-05 04:14:45');
INSERT INTO `blog_logs` VALUES (1042, '更新文章', '操作成功', '117.172.223.199', '2022-02-05 04:15:03');
INSERT INTO `blog_logs` VALUES (1043, '发表文章', '操作成功', '117.172.223.199', '2022-02-05 04:37:58');

-- ----------------------------
-- Table structure for blog_menu
-- ----------------------------
DROP TABLE IF EXISTS `blog_menu`;
CREATE TABLE `blog_menu`  (
  `menu_id` int(11) NOT NULL AUTO_INCREMENT,
  `menu_icon` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '菜单图标',
  `menu_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '菜单名称',
  `menu_sort` int(11) NULL DEFAULT NULL COMMENT '排序',
  `menu_target` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '打开方式',
  `menu_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '菜单路径',
  PRIMARY KEY (`menu_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 45 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_menu
-- ----------------------------
INSERT INTO `blog_menu` VALUES (34, 'app-menu__icon fa fa-book', '首页', 1, '_self', '/');
INSERT INTO `blog_menu` VALUES (35, NULL, '归档', 2, '_self', '/archives');
INSERT INTO `blog_menu` VALUES (37, '', '主页', 4, '_self', 'https://yltrcc.github.io/');
INSERT INTO `blog_menu` VALUES (38, '', '时光轴', 5, '_self', 'https://yltrcc.github.io/timeline/');
INSERT INTO `blog_menu` VALUES (39, '', 'github', 6, '_blank', 'https://github.com/yltrcc');
INSERT INTO `blog_menu` VALUES (40, '', '后台管理', 7, '_self', '/admin');
INSERT INTO `blog_menu` VALUES (41, 'app-menu__icon fa fa-book', '书籍', 8, '_blank', '/books');
INSERT INTO `blog_menu` VALUES (44, NULL, '友链', 3, '_self', '/links');

-- ----------------------------
-- Table structure for blog_options
-- ----------------------------
DROP TABLE IF EXISTS `blog_options`;
CREATE TABLE `blog_options`  (
  `option_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '设置名',
  `option_value` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL COMMENT '设置内容',
  PRIMARY KEY (`option_name`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_options
-- ----------------------------
INSERT INTO `blog_options` VALUES ('attachment_location', 'server');
INSERT INTO `blog_options` VALUES ('blog_footer', '');
INSERT INTO `blog_options` VALUES ('blog_logo', '');
INSERT INTO `blog_options` VALUES ('blog_name', '独行者的视界');
INSERT INTO `blog_options` VALUES ('blog_start', '2022-01-02');
INSERT INTO `blog_options` VALUES ('blog_url', '/');
INSERT INTO `blog_options` VALUES ('email_username', 'yltrcc');
INSERT INTO `blog_options` VALUES ('ico_logo', '');
INSERT INTO `blog_options` VALUES ('is_install', 'true');

-- ----------------------------
-- Table structure for blog_tag
-- ----------------------------
DROP TABLE IF EXISTS `blog_tag`;
CREATE TABLE `blog_tag`  (
  `tag_id` int(11) NOT NULL AUTO_INCREMENT,
  `tag_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '标签名称',
  `tag_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '标签路径',
  PRIMARY KEY (`tag_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 23 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_tag
-- ----------------------------
INSERT INTO `blog_tag` VALUES (20, '数据库', 'database');
INSERT INTO `blog_tag` VALUES (21, 'nacos', 'nacos');
INSERT INTO `blog_tag` VALUES (22, 'JMeter', 'JMeter');

-- ----------------------------
-- Table structure for blog_theme
-- ----------------------------
DROP TABLE IF EXISTS `blog_theme`;
CREATE TABLE `blog_theme`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `theme_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '主题名(url)',
  `theme_describe` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '主题描述',
  `theme_img` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '主题预览图',
  `theme_status` int(11) NULL DEFAULT 0 COMMENT '0未启用1已启用',
  `create_time` datetime(0) NULL DEFAULT NULL COMMENT '创建时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 28 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_theme
-- ----------------------------
INSERT INTO `blog_theme` VALUES (26, 'pinghsu', 'pinghsu', '/static/img/pinghsu.jpg', 1, '2021-11-25 04:06:51');
INSERT INTO `blog_theme` VALUES (27, 'pinghsu', 'pinghsu', '/static/img/pinghsu.jpg', 1, '2022-01-02 08:19:51');

-- ----------------------------
-- Table structure for blog_user
-- ----------------------------
DROP TABLE IF EXISTS `blog_user`;
CREATE TABLE `blog_user`  (
  `user_id` int(11) NOT NULL AUTO_INCREMENT,
  `login_enable` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '0' COMMENT '是否禁用登录',
  `login_error` int(11) NULL DEFAULT NULL COMMENT '登录失败次数',
  `login_last_time` datetime(0) NULL DEFAULT NULL COMMENT '最后登录时间',
  `user_portrait` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '头像',
  `user_explain` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '说明',
  `user_display_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '显示名称',
  `user_email` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '邮箱',
  `user_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '用户名',
  `user_pwd` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '密码',
  PRIMARY KEY (`user_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 12 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_user
-- ----------------------------
INSERT INTO `blog_user` VALUES (9, 'false', 0, '2022-02-05 04:14:45', NULL, NULL, 'yltrcc', '1952500855@qq.com', 'yltrcc', '202cb962ac59075b964b07152d234b70');

-- ----------------------------
-- Table structure for qb_details
-- ----------------------------
DROP TABLE IF EXISTS `qb_details`;
CREATE TABLE `qb_details`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NULL DEFAULT NULL COMMENT '发表用户',
  `article_content` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL COMMENT '文章内容html格式',
  `article_content_md` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL COMMENT '文章内容Markdown格式',
  `article_newstime` datetime(0) NULL DEFAULT NULL COMMENT '发布时间',
  `article_status` int(11) NULL DEFAULT NULL COMMENT '文章状态 0已发布1草稿2回收站',
  `article_summary` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '文章摘要',
  `article_thumbnail` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '略缩图',
  `article_title` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '文章标题',
  `article_type` int(255) NULL DEFAULT NULL COMMENT '文章类型0原创1转载',
  `article_post` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT 'post文章 page页面',
  `article_comment` int(11) NULL DEFAULT NULL COMMENT '是否开启评论 0开启1不开启',
  `article_updatetime` datetime(0) NULL DEFAULT NULL COMMENT '文章最后修改时间',
  `article_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '文章路径',
  `article_views` bigint(20) NULL DEFAULT 0 COMMENT '访问量统计',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `blog_ARTICLE_URL`(`article_url`) USING BTREE,
  INDEX `blog_ARTICLE_USERID`(`user_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 56 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of qb_details
-- ----------------------------
INSERT INTO `qb_details` VALUES (1, 9, '<h3 id=\"arraylist-linkedlist-vector-\">ArrayList 、LinkedList和Vector的区别？</h3>\r\n<pre><code class=\"lang-Java\">1. 是否保证线程安全：\r\n  <span class=\"hljs-selector-tag\">ArrayList</span>和<span class=\"hljs-selector-tag\">LinkedList</span>都不是线程安全的\r\n  <span class=\"hljs-selector-tag\">Vector</span>是线程安全的，但是底层大量使用了<span class=\"hljs-selector-tag\">synchronized</span>关键字，效率不是很高。\r\n2. 底层数据结构\r\n  <span class=\"hljs-selector-tag\">ArrayList</span> 和 <span class=\"hljs-selector-tag\">Vector</span> 底层是数组，查询效率高，多用于查询较多的场合；\r\n  <span class=\"hljs-selector-tag\">LinkedList</span> 底层是双向链表，插入和删除非常方便，适用于插入较多的场合\r\n3. 默认大小与扩容\r\n  <span class=\"hljs-selector-tag\">ArrayList</span> ：<span class=\"hljs-selector-tag\">JDK</span> 1<span class=\"hljs-selector-class\">.7</span> 之前默认大小是 10 <span class=\"hljs-selector-tag\">JDK</span> 1<span class=\"hljs-selector-class\">.7</span> 之后是0 每次按照1<span class=\"hljs-selector-class\">.5</span>倍扩容\r\n  <span class=\"hljs-selector-tag\">LinkedList</span>：底层是链表结构，是不连续的存储空间，没有默认大小的说法。\r\n  <span class=\"hljs-selector-tag\">Vector</span>扩容是2倍\r\n</code></pre>', '### ArrayList 、LinkedList和Vector的区别？\r\n\r\n```Java\r\n1. 是否保证线程安全：\r\n  ArrayList和LinkedList都不是线程安全的\r\n  Vector是线程安全的，但是底层大量使用了synchronized关键字，效率不是很高。\r\n2. 底层数据结构\r\n  ArrayList 和 Vector 底层是数组，查询效率高，多用于查询较多的场合；\r\n  LinkedList 底层是双向链表，插入和删除非常方便，适用于插入较多的场合\r\n3. 默认大小与扩容\r\n  ArrayList ：JDK 1.7 之前默认大小是 10 JDK 1.7 之后是0 每次按照1.5倍扩容\r\n  LinkedList：底层是链表结构，是不连续的存储空间，没有默认大小的说法。\r\n  Vector扩容是2倍\r\n```', '2022-01-15 09:52:28', 0, 'ArrayList、LinkedList和Vector的区别？1.是否保证线程安全：ArrayLis', '/static/img/rand/13.jpg', 'ArrayList 、LinkedList和Vector的区别？', 0, 'post', 0, '2022-01-15 09:52:28', '1642240347', NULL);
INSERT INTO `qb_details` VALUES (2, 9, '<h3 id=\"-map-\">你都知道哪些常用的Map集合?</h3>\r\n<p>HashMap、HashTable、TreeMap、LinkedHashMap、ConcurrentHashMap</p>', '### 你都知道哪些常用的Map集合?\r\n\r\nHashMap、HashTable、TreeMap、LinkedHashMap、ConcurrentHashMap', '2022-01-15 09:54:54', 0, '你都知道哪些常用的Map集合?HashMap、HashTable、TreeMap、LinkedHas', '/static/img/rand/6.jpg', '你都知道哪些常用的Map集合?', 0, 'post', 0, '2022-01-15 09:54:54', '1642240494', NULL);
INSERT INTO `qb_details` VALUES (3, 9, '<h3 id=\"hashmap-hashtable-\">HashMap和Hashtable有什么区别？</h3>\r\n<pre><code class=\"lang-Java\">线程安全问题：\r\n  Hashtable是线程安全的，HashMap不安全\r\n空值问题：\r\n  HashTable不允许<span class=\"hljs-literal\">null</span>值（key和<span class=\"hljs-keyword\">value</span>都不可以），\r\n  HashMap允许使用<span class=\"hljs-literal\">null</span>值（key和<span class=\"hljs-keyword\">value</span>）都可以。\r\n    但是这样的键只有一个，可以有一个或多个键所对应的值为<span class=\"hljs-literal\">null</span>。\r\n初始容量与扩容：\r\n  HashMap 默认初始大小 <span class=\"hljs-number\">16</span>，每次扩容 <span class=\"hljs-number\">2</span>n；\r\n  HashTable 默认初始大小为<span class=\"hljs-number\">11</span>，每次扩容 <span class=\"hljs-number\">2</span>n+<span class=\"hljs-number\">1</span>\r\n</code></pre>\r\n<h3 id=\"concurrenthashmap-hashtable-\">ConcurrentHashMap 和 Hashtable 的区别</h3>\r\n<pre><code class=\"lang-Java\">底层数据结构：\r\n  ConcurrentHashMap \r\n    JDK <span class=\"hljs-number\">1.7</span> 底层采用 分段的数组 + 链表实现。\r\n    JDK <span class=\"hljs-number\">1.8</span> 采用的是 数组 + 链表/红黑树\r\n  HashTable \r\n    底层采用的是 数组 + 链表\r\n实现线程安全的方式：\r\n  ConcurrentHashMap \r\n    JDK1.7底层采用分段锁，对整个桶数进行了分割分段（segment），\r\n      每一把锁只锁容器其中一部分数据，提高并发访问率。\r\n    JDK <span class=\"hljs-number\">1.8</span> 底层采用 Node数组 + 链表 + 红黑树的结构实现，\r\n      并发控制使用了 <span class=\"hljs-keyword\">synchronized</span> 和 CAS 操作。\r\n  HashTable 底层采用<span class=\"hljs-keyword\">synchronized</span> 来保证线程安全，\r\n    直接是方法级别的加锁， ConcurrentHashMap 虽然也是 <span class=\"hljs-keyword\">synchronized</span> \r\n    但它是对链表或者红黑树的头节点进行加锁，锁的粒度更小\r\n</code></pre>', '### HashMap和Hashtable有什么区别？\r\n\r\n```Java\r\n线程安全问题：\r\n  Hashtable是线程安全的，HashMap不安全\r\n空值问题：\r\n  HashTable不允许null值（key和value都不可以），\r\n  HashMap允许使用null值（key和value）都可以。\r\n    但是这样的键只有一个，可以有一个或多个键所对应的值为null。\r\n初始容量与扩容：\r\n  HashMap 默认初始大小 16，每次扩容 2n；\r\n  HashTable 默认初始大小为11，每次扩容 2n+1\r\n```\r\n\r\n### ConcurrentHashMap 和 Hashtable 的区别\r\n\r\n```Java\r\n底层数据结构：\r\n  ConcurrentHashMap \r\n    JDK 1.7 底层采用 分段的数组 + 链表实现。\r\n    JDK 1.8 采用的是 数组 + 链表/红黑树\r\n  HashTable \r\n    底层采用的是 数组 + 链表\r\n实现线程安全的方式：\r\n  ConcurrentHashMap \r\n    JDK1.7底层采用分段锁，对整个桶数进行了分割分段（segment），\r\n      每一把锁只锁容器其中一部分数据，提高并发访问率。\r\n    JDK 1.8 底层采用 Node数组 + 链表 + 红黑树的结构实现，\r\n      并发控制使用了 synchronized 和 CAS 操作。\r\n  HashTable 底层采用synchronized 来保证线程安全，\r\n    直接是方法级别的加锁， ConcurrentHashMap 虽然也是 synchronized \r\n    但它是对链表或者红黑树的头节点进行加锁，锁的粒度更小\r\n```', '2022-01-15 09:56:15', 0, 'HashMap和Hashtable有什么区别？线程安全问题：Hashtable是线程安全的，Hash', '/static/img/rand/16.jpg', 'HashMap和Hashtable有什么区别？', 0, 'post', 0, '2022-01-15 09:56:15', '1642240574', NULL);
INSERT INTO `qb_details` VALUES (4, 9, '<p>Spring Web MVC 框架提供”模型-视图-控制器”( Model-View-Controller )架构和随时可用的组件，用于开发灵活且松散耦合的 Web 应用程序。<br>MVC 模式有助于分离应用程序的不同方面，如输入逻辑，业务逻辑和 UI 逻辑，同时在所有这些元素之间提供松散耦合。</p>\r\n', 'Spring Web MVC 框架提供”模型-视图-控制器”( Model-View-Controller )架构和随时可用的组件，用于开发灵活且松散耦合的 Web 应用程序。\r\nMVC 模式有助于分离应用程序的不同方面，如输入逻辑，业务逻辑和 UI 逻辑，同时在所有这些元素之间提供松散耦合。', '2022-01-17 03:50:38', 0, 'SpringWebMVC框架提供”模型-视图-控制器”(Model-View-Controller)', '/static/img/rand/15.jpg', 'Spring MVC 框架有什么用？', 0, 'post', 0, '2022-01-17 03:50:38', '1642413038', NULL);
INSERT INTO `qb_details` VALUES (5, 9, '<h2 id=\"spring-mvc-\">Spring MVC 的主要组件？</h2>\r\n<ol>\r\n<li>前端控制器 DispatcherServlet<br> 作用：接收请求、响应结果，相当于转发器，有了 DispatcherServlet 就减少了其他组件之间的耦合度</li>\r\n<li>处理器映射器 HandlerMapping<br> 作用：根据请求的 url 来查找 handler</li>\r\n<li>处理器适配器 HandlerAdapter</li>\r\n<li>处理器 Handler</li>\r\n<li>视图解析器 ViewResolver<br> 作用：进行视图的解析，根据视图逻辑名解析成真正的视图（View）</li>\r\n<li>视图 View<br> View 是一个接口，它的实现类支持不同的视图类型（jsp、freemarker、pdf等）</li>\r\n</ol>', '## Spring MVC 的主要组件？\r\n\r\n1. 前端控制器 DispatcherServlet\r\n    作用：接收请求、响应结果，相当于转发器，有了 DispatcherServlet 就减少了其他组件之间的耦合度\r\n2. 处理器映射器 HandlerMapping\r\n    作用：根据请求的 url 来查找 handler\r\n3. 处理器适配器 HandlerAdapter\r\n4. 处理器 Handler\r\n5. 视图解析器 ViewResolver\r\n    作用：进行视图的解析，根据视图逻辑名解析成真正的视图（View）\r\n6. 视图 View\r\n    View 是一个接口，它的实现类支持不同的视图类型（jsp、freemarker、pdf等）', '2022-01-19 00:47:11', 0, '介绍下SpringMVC的核心组件？SpringMVC一共有九大核心组件，分别是：Multipart', '/static/img/rand/13.jpg', 'Spring MVC 的主要组件？', 0, 'post', 0, '2022-01-19 00:57:39', '1642574830', NULL);
INSERT INTO `qb_details` VALUES (6, 9, '<h2 id=\"springmvc-\">SpringMVC工作原理？</h2>\r\n<pre><code class=\"lang-text\">简版：\r\n1）客户端发送请求到DispatcherServlet\r\n2）DispatcherServlet查询handlerMapping找到处理请求的Controller\r\n3）Controller调用业务逻辑后，返回ModelAndView\r\n4）DispatcherServlet查询ModelAndView，找到指定视图\r\n5）视图将结果返回到客户端\r\n\r\n完整版：\r\n<span class=\"hljs-bullet\">1. </span>客户端发送请求到前端控制器 DispatcherServlet\r\n<span class=\"hljs-bullet\">2. </span>DispatcherServlet 收到请求后，调用 HandlerMapping 处理器映射器，请求获取 handler\r\n<span class=\"hljs-bullet\">3. </span>处理器映射器根据 url 找到具体的处理器，生成处理器对象以及处理器拦截器（如果有则生成）一并返回给 DispatcherServlet\r\n<span class=\"hljs-bullet\">4. </span>DispatcherServlet 调用 HandlerAdapter 处理器适配器\r\n<span class=\"hljs-bullet\">5. </span>HandlerAdapter 经过适配器调用 具体处理器（Handler，也叫后端控制器）\r\n<span class=\"hljs-bullet\">6. </span>Handler 执行完成返回 ModelAndView\r\n<span class=\"hljs-bullet\">7. </span>HandlerAdaper 将 Handler 执行结果 ModelAndView 返回给 DispatcherServlet\r\n<span class=\"hljs-bullet\">8. </span>DispatcherServlet 将 ModelAndView 传给 ViewResolver 视图解析器 进行解析\r\n<span class=\"hljs-bullet\">9. </span>ViewResolver 解析后返回具体 View\r\n<span class=\"hljs-bullet\">10. </span>DispatcherServlet 对 view 进行 渲染视图（即将模型数据填充至视图中）\r\n<span class=\"hljs-bullet\">11. </span>DispatcherServlet 响应用户\r\n</code></pre>\r\n<p><img src=\"https://secure2.wostatic.cn/static/xA85U7wg7sjhaVLtXHNsLZ/20200208211439106.png\" alt=\"\"></p>', '## SpringMVC工作原理？\r\n\r\n```text\r\n简版：\r\n1）客户端发送请求到DispatcherServlet\r\n2）DispatcherServlet查询handlerMapping找到处理请求的Controller\r\n3）Controller调用业务逻辑后，返回ModelAndView\r\n4）DispatcherServlet查询ModelAndView，找到指定视图\r\n5）视图将结果返回到客户端\r\n\r\n完整版：\r\n1. 客户端发送请求到前端控制器 DispatcherServlet\r\n2. DispatcherServlet 收到请求后，调用 HandlerMapping 处理器映射器，请求获取 handler\r\n3. 处理器映射器根据 url 找到具体的处理器，生成处理器对象以及处理器拦截器（如果有则生成）一并返回给 DispatcherServlet\r\n4. DispatcherServlet 调用 HandlerAdapter 处理器适配器\r\n5. HandlerAdapter 经过适配器调用 具体处理器（Handler，也叫后端控制器）\r\n6. Handler 执行完成返回 ModelAndView\r\n7. HandlerAdaper 将 Handler 执行结果 ModelAndView 返回给 DispatcherServlet\r\n8. DispatcherServlet 将 ModelAndView 传给 ViewResolver 视图解析器 进行解析\r\n9. ViewResolver 解析后返回具体 View\r\n10. DispatcherServlet 对 view 进行 渲染视图（即将模型数据填充至视图中）\r\n11. DispatcherServlet 响应用户\r\n```\r\n\r\n![](https://secure2.wostatic.cn/static/xA85U7wg7sjhaVLtXHNsLZ/20200208211439106.png)', '2022-01-19 00:51:47', 0, 'SpringMVC工作原理？简版：1）客户端发送请求到DispatcherServlet2）Disp', '/static/img/rand/18.jpg', 'SpringMVC工作原理？', 0, 'post', 0, '2022-01-19 00:51:47', '1642575107', NULL);
INSERT INTO `qb_details` VALUES (7, 9, '<h2 id=\"-controller-\">@Controller 注解有什么用？</h2>\r\n<p><code>@Controller</code> 注解，它将一个类标记为 Spring Web MVC <strong>控制器</strong> Controller 。</p>', '## @Controller 注解有什么用？\r\n\r\n`@Controller` 注解，它将一个类标记为 Spring Web MVC **控制器** Controller 。', '2022-01-19 00:59:43', 0, '@Controller注解有什么用？@Controller注解，它将一个类标记为SpringWebM', '/static/img/rand/17.jpg', '@Controller 注解有什么用？', 0, 'post', 0, '2022-01-19 00:59:43', '1642575582', NULL);
INSERT INTO `qb_details` VALUES (8, 9, '<h2 id=\"-restcontroller-controller-\">@RestController 和 @Controller 有什么区别？</h2>\r\n<p><code>@RestController</code> 注解，在 <code>@Controller</code> 基础上，增加了 <code>@ResponseBody</code> 注解，更加适合目前前后端分离的架构下，提供 Restful API ，返回例如 JSON 数据格式。当然，返回什么样的数据格式，根据客户端的 <code>&quot;ACCEPT&quot;</code> 请求头来决定。</p>', '## @RestController 和 @Controller 有什么区别？\r\n\r\n`@RestController` 注解，在 `@Controller` 基础上，增加了 `@ResponseBody` 注解，更加适合目前前后端分离的架构下，提供 Restful API ，返回例如 JSON 数据格式。当然，返回什么样的数据格式，根据客户端的 `\"ACCEPT\"` 请求头来决定。', '2022-01-19 00:59:57', 0, '@RestController和@Controller有什么区别？@RestController注解', '/static/img/rand/17.jpg', '@RestController 和 @Controller 有什么区别？', 0, 'post', 0, '2022-01-19 00:59:57', '1642575596', NULL);
INSERT INTO `qb_details` VALUES (9, 9, '<h2 id=\"-requestmapping-\">@RequestMapping 注解有什么用？</h2>\r\n<p><code>@RequestMapping</code> 注解，用于将特定 HTTP 请求方法映射到将处理相应请求的控制器中的特定类/方法。此注释可应用于两个级别：</p>\r\n<ul>\r\n<li>类级别：映射请求的 URL。</li>\r\n<li>方法级别：映射 URL 以及 HTTP 请求方法。</li>\r\n</ul>', '## @RequestMapping 注解有什么用？\r\n\r\n`@RequestMapping` 注解，用于将特定 HTTP 请求方法映射到将处理相应请求的控制器中的特定类/方法。此注释可应用于两个级别：\r\n\r\n- 类级别：映射请求的 URL。\r\n- 方法级别：映射 URL 以及 HTTP 请求方法。', '2022-01-19 01:00:12', 0, '@RequestMapping注解有什么用？@RequestMapping注解，用于将特定HTTP请', '/static/img/rand/17.jpg', '@RequestMapping 注解有什么用？', 0, 'post', 0, '2022-01-19 01:00:12', '1642575612', NULL);
INSERT INTO `qb_details` VALUES (10, 9, '<h2 id=\"-requestmapping-getmapping-\">@RequestMapping 和 @GetMapping 注解的不同之处在哪里？</h2>\r\n<ul>\r\n<li><code>@RequestMapping</code> 可注解在类和方法上；<code>@GetMapping</code> 仅可注册在方法上。</li>\r\n<li><code>@RequestMapping</code> 可进行 GET、POST、PUT、DELETE 等请求方法；<code>@GetMapping</code> 是 <code>@RequestMapping</code> 的 GET 请求方法的特例，目的是为了提高清晰度。</li>\r\n</ul>', '## @RequestMapping 和 @GetMapping 注解的不同之处在哪里？\r\n\r\n- `@RequestMapping` 可注解在类和方法上；`@GetMapping` 仅可注册在方法上。\r\n- `@RequestMapping` 可进行 GET、POST、PUT、DELETE 等请求方法；`@GetMapping` 是 `@RequestMapping` 的 GET 请求方法的特例，目的是为了提高清晰度。', '2022-01-19 01:00:31', 0, '@RequestMapping和@GetMapping注解的不同之处在哪里？@RequestMapp', '/static/img/rand/2.jpg', '@RequestMapping 和 @GetMapping 注解的不同之处在哪里？', 0, 'post', 0, '2022-01-19 01:00:31', '1642575630', NULL);
INSERT INTO `qb_details` VALUES (11, 9, '<h2 id=\"-json-\">返回 JSON 格式使用什么注解？</h2>\r\n<p>可以使用 <strong><code>@ResponseBody</code></strong> 注解，或者使用包含 <code>@ResponseBody</code> 注解的 <strong><code>@RestController</code></strong> 注解。</p>\r\n<p>当然，还是需要配合相应的支持 JSON 格式化的 HttpMessageConverter 实现类。例如，Spring MVC 默认使用 MappingJackson2HttpMessageConverter 。</p>', '## 返回 JSON 格式使用什么注解？\r\n\r\n可以使用 **`@ResponseBody`** 注解，或者使用包含 `@ResponseBody` 注解的 **`@RestController`** 注解。\r\n\r\n当然，还是需要配合相应的支持 JSON 格式化的 HttpMessageConverter 实现类。例如，Spring MVC 默认使用 MappingJackson2HttpMessageConverter 。', '2022-01-19 01:01:17', 0, '返回JSON格式使用什么注解？可以使用@ResponseBody注解，或者使用包含@Response', '/static/img/rand/13.jpg', '返回 JSON 格式使用什么注解？', 0, 'post', 0, '2022-01-19 01:01:17', '1642575677', NULL);
INSERT INTO `qb_details` VALUES (12, 9, '<h2 id=\"-webapplicationcontext-\">介绍一下 WebApplicationContext ？</h2>\r\n<p>WebApplicationContext 是实现ApplicationContext接口的子类，专门为 WEB 应用准备的。</p>\r\n<ul>\r\n<li>它允许从相对于 Web 根目录的路径中<strong>加载配置文件</strong>，<strong>完成初始化 Spring MVC 组件的工作</strong>。</li>\r\n<li>从 WebApplicationContext 中，可以获取 ServletContext 引用，整个 Web 应用上下文对象将作为属性放置在 ServletContext 中，以便 Web 应用环境可以访问 Spring 上下文。</li>\r\n</ul>\r\n<p>关于这一块，如果想要详细了解，可以看看如下两篇文章：</p>\r\n<ul>\r\n<li><a href=\"http://svip.iocoder.cn/Spring-MVC/context-init-Root-WebApplicationContext/\">《精尽 Spring MVC 源码分析 —— 容器的初始化（一）之 Root WebApplicationContext 容器》</a></li>\r\n<li><a href=\"http://svip.iocoder.cn/Spring-MVC/context-init-Servlet-WebApplicationContext/\">《精尽 Spring MVC 源码分析 —— 容器的初始化（二）之 Servlet WebApplicationContext 容器》</a></li>\r\n</ul>', '## 介绍一下 WebApplicationContext ？\r\n\r\nWebApplicationContext 是实现ApplicationContext接口的子类，专门为 WEB 应用准备的。\r\n\r\n- 它允许从相对于 Web 根目录的路径中**加载配置文件**，**完成初始化 Spring MVC 组件的工作**。\r\n- 从 WebApplicationContext 中，可以获取 ServletContext 引用，整个 Web 应用上下文对象将作为属性放置在 ServletContext 中，以便 Web 应用环境可以访问 Spring 上下文。\r\n\r\n关于这一块，如果想要详细了解，可以看看如下两篇文章：\r\n\r\n- [《精尽 Spring MVC 源码分析 —— 容器的初始化（一）之 Root WebApplicationContext 容器》](http://svip.iocoder.cn/Spring-MVC/context-init-Root-WebApplicationContext/)\r\n- [《精尽 Spring MVC 源码分析 —— 容器的初始化（二）之 Servlet WebApplicationContext 容器》](http://svip.iocoder.cn/Spring-MVC/context-init-Servlet-WebApplicationContext/)', '2022-01-19 01:04:15', 0, '介绍一下WebApplicationContext？WebApplicationContext是实现', '/static/img/rand/5.jpg', '介绍一下 WebApplicationContext ？', 0, 'post', 0, '2022-01-19 01:04:15', '1642575855', NULL);
INSERT INTO `qb_details` VALUES (13, 9, '<h2 id=\"spring-mvc-\">Spring MVC 的异常处理？</h2>\r\n<p>Spring MVC 提供了异常解析器 HandlerExceptionResolver 接口，将处理器( <code>handler</code> )执行时发生的异常，解析( 转换 )成对应的 ModelAndView 结果。代码如下：</p>\r\n<pre><code class=\"lang-Java\"><span class=\"hljs-comment\">// HandlerExceptionResolver.java  </span>\r\n\r\n<span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">interface</span> <span class=\"hljs-title\">HandlerExceptionResolver</span> {  \r\n\r\n  <span class=\"hljs-comment\">/**  \r\n    - 解析异常，转换成对应的 ModelAndView 结果  \r\n\r\n    */</span>  \r\n\r\n  @<span class=\"hljs-function\">Nullable  \r\n\r\n  ModelAndView <span class=\"hljs-title\">resolveException</span>(<span class=\"hljs-params\">  \r\n\r\n  HttpServletRequest request, HttpServletResponse response, @Nullable Object handler, Exception ex</span>)</span>;  \r\n\r\n}\r\n</code></pre>\r\n<ul>\r\n<li>也就是说，如果异常被解析成功，则会返回 ModelAndView 对象。</li>\r\n<li>详细的源码解析，见 <a href=\"http://svip.iocoder.cn/Spring-MVC/HandlerExceptionResolver/\">《精尽 Spring MVC 源码解析 —— HandlerExceptionResolver 组件》</a> 。</li>\r\n</ul>\r\n<p>一般情况下，我们使用 <code>@ExceptionHandler</code> 注解来实现过异常的处理，可以先看看 <a href=\"https://www.jianshu.com/p/12e1a752974d\">《Spring 异常处理 ExceptionHandler 的使用》</a> 。</p>\r\n<ul>\r\n<li>一般情况下，使用<strong>第三种</strong>：@ControllerAdvice注解-<strong>全局异常处理</strong>。</li>\r\n</ul>\r\n<pre><code class=\"lang-Java\"><span class=\"hljs-comment\">/**\r\n * Created by liuruijie on 2016/12/28.\r\n * 全局异常处理，捕获所有Controller中抛出的异常。\r\n */</span>\r\n<span class=\"hljs-meta\">@ControllerAdvice</span>\r\n<span class=\"hljs-keyword\">public</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">GlobalExceptionHandler</span> </span>{\r\n   <span class=\"hljs-comment\">//处理自定义的异常</span>\r\n   <span class=\"hljs-meta\">@ExceptionHandler</span>(SystemException.class) \r\n   <span class=\"hljs-meta\">@ResponseBody</span>\r\n   <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> Object <span class=\"hljs-title\">customHandler</span><span class=\"hljs-params\">(SystemException e)</span></span>{\r\n      e.printStackTrace();\r\n      <span class=\"hljs-keyword\">return</span> WebResult.buildResult().status(e.getCode()).msg(e.getMessage());\r\n   }\r\n   <span class=\"hljs-comment\">//其他未处理的异常</span>\r\n   <span class=\"hljs-meta\">@ExceptionHandler</span>(Exception.class)\r\n   <span class=\"hljs-meta\">@ResponseBody</span>\r\n   <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> Object <span class=\"hljs-title\">exceptionHandler</span><span class=\"hljs-params\">(Exception e)</span></span>{\r\n      e.printStackTrace();\r\n      <span class=\"hljs-keyword\">return</span> WebResult.buildResult().status(Config.FAIL).msg(<span class=\"hljs-string\">\"系统错误\"</span>);\r\n   }\r\n}\r\n</code></pre>', '## Spring MVC 的异常处理？\r\n\r\nSpring MVC 提供了异常解析器 HandlerExceptionResolver 接口，将处理器( `handler` )执行时发生的异常，解析( 转换 )成对应的 ModelAndView 结果。代码如下：\r\n\r\n```Java\r\n// HandlerExceptionResolver.java  \r\n\r\npublic interface HandlerExceptionResolver {  \r\n\r\n  /**  \r\n    - 解析异常，转换成对应的 ModelAndView 结果  \r\n\r\n    */  \r\n\r\n  @Nullable  \r\n\r\n  ModelAndView resolveException(  \r\n\r\n  HttpServletRequest request, HttpServletResponse response, @Nullable Object handler, Exception ex);  \r\n\r\n}  \r\n```\r\n\r\n- 也就是说，如果异常被解析成功，则会返回 ModelAndView 对象。\r\n- 详细的源码解析，见 [《精尽 Spring MVC 源码解析 —— HandlerExceptionResolver 组件》](http://svip.iocoder.cn/Spring-MVC/HandlerExceptionResolver/) 。\r\n\r\n一般情况下，我们使用 `@ExceptionHandler` 注解来实现过异常的处理，可以先看看 [《Spring 异常处理 ExceptionHandler 的使用》](https://www.jianshu.com/p/12e1a752974d) 。\r\n\r\n- 一般情况下，使用**第三种**：@ControllerAdvice注解-**全局异常处理**。\r\n\r\n```Java\r\n/**\r\n * Created by liuruijie on 2016/12/28.\r\n * 全局异常处理，捕获所有Controller中抛出的异常。\r\n */\r\n@ControllerAdvice\r\npublic class GlobalExceptionHandler {\r\n   //处理自定义的异常\r\n   @ExceptionHandler(SystemException.class) \r\n   @ResponseBody\r\n   public Object customHandler(SystemException e){\r\n      e.printStackTrace();\r\n      return WebResult.buildResult().status(e.getCode()).msg(e.getMessage());\r\n   }\r\n   //其他未处理的异常\r\n   @ExceptionHandler(Exception.class)\r\n   @ResponseBody\r\n   public Object exceptionHandler(Exception e){\r\n      e.printStackTrace();\r\n      return WebResult.buildResult().status(Config.FAIL).msg(\"系统错误\");\r\n   }\r\n}\r\n```', '2022-01-19 01:11:03', 0, 'SpringMVC的异常处理？SpringMVC提供了异常解析器HandlerExceptionRe', '/static/img/rand/2.jpg', 'Spring MVC 的异常处理？', 0, 'post', 0, '2022-01-19 01:11:03', '1642576263', NULL);
INSERT INTO `qb_details` VALUES (14, 9, '<h2 id=\"spring-mvc-\">Spring MVC 怎样设定重定向和转发 ？</h2>\r\n<ul>\r\n<li>结果转发：在返回值的前面加 <code>&quot;forward:/&quot;</code> 。</li>\r\n<li>重定向：在返回值的前面加上 <code>&quot;redirect:/&quot;</code> 。</li>\r\n</ul>\r\n<p>当然，目前前后端分离之后，我们作为后端开发，已经很少有机会用上这个功能了。</p>', '## Spring MVC 怎样设定重定向和转发 ？\r\n\r\n- 结果转发：在返回值的前面加 `\"forward:/\"` 。\r\n- 重定向：在返回值的前面加上 `\"redirect:/\"` 。\r\n\r\n当然，目前前后端分离之后，我们作为后端开发，已经很少有机会用上这个功能了。', '2022-01-19 01:12:38', 0, 'SpringMVC怎样设定重定向和转发？结果转发：在返回值的前面加&quot;forward:/&q', '/static/img/rand/11.jpg', 'Spring MVC 怎样设定重定向和转发 ？', 0, 'post', 0, '2022-01-19 01:12:38', '1642576358', NULL);
INSERT INTO `qb_details` VALUES (15, 9, '<h2 id=\"spring-mvc-controller-\">Spring MVC 的 Controller 是不是单例？</h2>\r\n<p>绝绝绝大多数情况下，Controller 是<strong>单例</strong>。</p>\r\n<p>那么，Controller 里一般不建议存在<strong>共享的变量</strong>。实际场景下，艿艿也没碰到需要使用共享变量的情况。</p>', '## Spring MVC 的 Controller 是不是单例？\r\n\r\n绝绝绝大多数情况下，Controller 是**单例**。\r\n\r\n那么，Controller 里一般不建议存在**共享的变量**。实际场景下，艿艿也没碰到需要使用共享变量的情况。', '2022-01-19 01:14:02', 0, 'SpringMVC的Controller是不是单例？绝绝绝大多数情况下，Controller是单例。', '/static/img/rand/4.jpg', 'Spring MVC 的 Controller 是不是单例？', 0, 'post', 0, '2022-01-19 01:14:02', '1642576442', NULL);
INSERT INTO `qb_details` VALUES (16, 9, '<h2 id=\"-request-session-\">怎么样在方法里面得到 Request,或者 Session？</h2>\r\n<p>答：直接在方法的形参中声明 request,SpringMvc 就自动把 request 对象传入</p>', '## 怎么样在方法里面得到 Request,或者 Session？\r\n\r\n答：直接在方法的形参中声明 request,SpringMvc 就自动把 request 对象传入', '2022-01-19 01:20:43', 0, '怎么样在方法里面得到Request,或者Session？答：直接在方法的形参中声明request,S', '/static/img/rand/3.jpg', '怎么样在方法里面得到 Request,或者 Session？', 0, 'post', 0, '2022-01-19 01:20:43', '1642576842', NULL);
INSERT INTO `qb_details` VALUES (17, 9, '<h2 id=\"ribbon-\">Ribbon 是干嘛的？</h2>\r\n<ul>\r\n<li>作用：主要提供客户侧的软件负载均衡算法。</li>\r\n<li>简介：Spring Cloud Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具，它基于 Netflix Ribbon 实现。通过 Spring Cloud 的封装，可以让我们轻松地将面向服务的 REST 模版请求自动转换成客户端负载均衡的服务调用。</li>\r\n<li>注意看上图，关键点就是将外界的 rest 调用，根据负载均衡策略转换为微服务调用。</li>\r\n</ul>', '## Ribbon 是干嘛的？\r\n\r\n- 作用：主要提供客户侧的软件负载均衡算法。\r\n- 简介：Spring Cloud Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具，它基于 Netflix Ribbon 实现。通过 Spring Cloud 的封装，可以让我们轻松地将面向服务的 REST 模版请求自动转换成客户端负载均衡的服务调用。\r\n- 注意看上图，关键点就是将外界的 rest 调用，根据负载均衡策略转换为微服务调用。', '2022-01-20 05:09:13', 0, 'Ribbon是干嘛的？作用：主要提供客户侧的软件负载均衡算法。简介：SpringCloudRibbo', '/static/img/rand/2.jpg', 'Ribbon 是干嘛的？', 0, 'post', 0, '2022-01-20 05:09:13', '1642676953', NULL);
INSERT INTO `qb_details` VALUES (18, 9, '<h2 id=\"-\">为什么要负载均衡？</h2>\r\n<p>简单来说，随着业务的发展，单台服务无法支撑访问的需要，于是搭建多个服务形成集群。那么随之要解决的是，每次请求，调用哪个服务，也就是需要进行负载均衡。</p>\r\n<p>目前负载均衡有两种模式：</p>\r\n<ol>\r\n<li>客户端模式</li>\r\n<li>服务端模式</li>\r\n</ol>\r\n<p>在 Spring Cloud 中，我们使用前者，即客户端模式。</p>\r\n<p>详细的内容，可以看看 <a href=\"https://blog.csdn.net/u014401141/article/details/78676296\">《客户端负载均衡与服务端负载均衡》</a> 。</p>\r\n<p><strong>负载平衡的意义什么？</strong></p>\r\n<p>在计算中，负载平衡可以改善跨计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器等多种计算资源的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一资源的过载。使用多个组件进行负载平衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。</p>', '## 为什么要负载均衡？\r\n\r\n简单来说，随着业务的发展，单台服务无法支撑访问的需要，于是搭建多个服务形成集群。那么随之要解决的是，每次请求，调用哪个服务，也就是需要进行负载均衡。\r\n\r\n目前负载均衡有两种模式：\r\n\r\n1. 客户端模式\r\n2. 服务端模式\r\n\r\n在 Spring Cloud 中，我们使用前者，即客户端模式。\r\n\r\n详细的内容，可以看看 [《客户端负载均衡与服务端负载均衡》](https://blog.csdn.net/u014401141/article/details/78676296) 。\r\n\r\n**负载平衡的意义什么？**\r\n\r\n在计算中，负载平衡可以改善跨计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器等多种计算资源的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一资源的过载。使用多个组件进行负载平衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。', '2022-01-20 05:12:23', 0, '为什么要负载均衡？简单来说，随着业务的发展，单台服务无法支撑访问的需要，于是搭建多个服务形成集群。那', '/static/img/rand/16.jpg', '为什么要负载均衡？', 0, 'post', 0, '2022-01-20 05:12:23', '1642677142', NULL);
INSERT INTO `qb_details` VALUES (19, 9, '<h3 id=\"ribbon-\">Ribbon 有哪些负载均衡算法？</h3>\r\n<p><a href=\"https://blog.csdn.net/rickiyeat/article/details/64918756\">《Ribbon 负载均衡策略配置》</a></p>\r\n<p>其中，默认的负载均衡算法是 Round Robin 算法，顺序向下轮询。</p>', '### Ribbon 有哪些负载均衡算法？\r\n\r\n[《Ribbon 负载均衡策略配置》](https://blog.csdn.net/rickiyeat/article/details/64918756)\r\n\r\n其中，默认的负载均衡算法是 Round Robin 算法，顺序向下轮询。', '2022-01-20 05:15:29', 0, 'Ribbon有哪些负载均衡算法？《Ribbon负载均衡策略配置》其中，默认的负载均衡算法是Round', '/static/img/rand/15.jpg', 'Ribbon 有哪些负载均衡算法？', 0, 'post', 0, '2022-01-20 05:15:29', '1642677328', NULL);
INSERT INTO `qb_details` VALUES (20, 9, '<h3 id=\"-ribbon-\">聊聊 Ribbon 缓存机制？</h3>\r\n<p>还是 <a href=\"http://bhsc881114.github.io/2018/04/01/eureka缓存细节以及生产环境的最佳配置/\">《Eureka 缓存细节以及生产环境的最佳配置》</a> 这篇文章，Ribbon 的缓存，可能也坑道蛮多人了。</p>', '### 聊聊 Ribbon 缓存机制？\r\n\r\n还是 [《Eureka 缓存细节以及生产环境的最佳配置》](http://bhsc881114.github.io/2018/04/01/eureka缓存细节以及生产环境的最佳配置/) 这篇文章，Ribbon 的缓存，可能也坑道蛮多人了。', '2022-01-20 05:15:41', 0, '聊聊Ribbon缓存机制？还是《Eureka缓存细节以及生产环境的最佳配置》这篇文章，Ribbon的', '/static/img/rand/14.jpg', '聊聊 Ribbon 缓存机制？', 0, 'post', 0, '2022-01-20 05:15:41', '1642677341', NULL);
INSERT INTO `qb_details` VALUES (21, 9, '<h3 id=\"-ribbon-\">聊聊 Ribbon 重试机制？</h3>\r\n<p><a href=\"https://www.jianshu.com/p/cdb6fedcab70\">《Spring Cloud Ribbon 重试机制》</a></p>\r\n<p>除了重试次数，还有请求的超时可以配置。</p>', '### 聊聊 Ribbon 重试机制？\r\n\r\n[《Spring Cloud Ribbon 重试机制》](https://www.jianshu.com/p/cdb6fedcab70)\r\n\r\n除了重试次数，还有请求的超时可以配置。', '2022-01-20 05:15:51', 0, '聊聊Ribbon重试机制？《SpringCloudRibbon重试机制》除了重试次数，还有请求的超时', '/static/img/rand/1.jpg', '聊聊 Ribbon 重试机制？', 0, 'post', 0, '2022-01-20 05:15:51', '1642677351', NULL);
INSERT INTO `qb_details` VALUES (22, 9, '<h3 id=\"feign-\">Feign 实现原理？</h3>\r\n<p><strong>Feign的一个关键机制就是使用了动态代理</strong>。咱们一起来看看下面的图，结合图来分析：</p>\r\n<ul>\r\n<li>首先，如果你对某个接口定义了 <code>@FeignClient</code> 注解，Feign 就会针对这个接口创建一个动态代理。</li>\r\n<li>接着你要是调用那个接口，本质就是会调用 Feign 创建的动态代理，这是核心中的核心。</li>\r\n<li>Feig n的动态代理会根据你在接口上的 <code>@RequestMapping</code> 等注解，来动态构造出你要请求的服务的地址。</li>\r\n<li>最后针对这个地址，发起请求、解析响应。</li>\r\n</ul>\r\n<p><img src=\"https://www.ylcoder.top/upload/2022/1/image20220120111708135.png\" alt=\"\"></p>', '### Feign 实现原理？\r\n\r\n**Feign的一个关键机制就是使用了动态代理**。咱们一起来看看下面的图，结合图来分析：\r\n\r\n- 首先，如果你对某个接口定义了 `@FeignClient` 注解，Feign 就会针对这个接口创建一个动态代理。\r\n- 接着你要是调用那个接口，本质就是会调用 Feign 创建的动态代理，这是核心中的核心。\r\n- Feig n的动态代理会根据你在接口上的 `@RequestMapping` 等注解，来动态构造出你要请求的服务的地址。\r\n- 最后针对这个地址，发起请求、解析响应。\r\n\r\n![](https://www.ylcoder.top/upload/2022/1/image20220120111708135.png)', '2022-01-20 05:17:52', 0, 'Feign实现原理？Feign的一个关键机制就是使用了动态代理。咱们一起来看看下面的图，结合图来分析', '/static/img/rand/16.jpg', 'Feign 实现原理？', 0, 'post', 0, '2022-01-20 05:17:52', '1642677471', NULL);
INSERT INTO `qb_details` VALUES (23, 9, '<h2 id=\"-feign-\">聊聊 Feign 重试机制？</h2>\r\n<p>可以看看 <a href=\"http://www.itmuch.com/spring-cloud-sum/spring-cloud-retry/\">《Spring Cloud 各组件重试总结》</a> 文章。因为 Ribbon 和 Feign 都有重试机制，在整合 Ribbon 的情况下，不使用 Feign 重试，而是使用 Ribbon 的重试。</p>', '## 聊聊 Feign 重试机制？\r\n\r\n可以看看 [《Spring Cloud 各组件重试总结》](http://www.itmuch.com/spring-cloud-sum/spring-cloud-retry/) 文章。因为 Ribbon 和 Feign 都有重试机制，在整合 Ribbon 的情况下，不使用 Feign 重试，而是使用 Ribbon 的重试。', '2022-01-22 01:07:57', 0, '聊聊Feign重试机制？可以看看《SpringCloud各组件重试总结》文章。因为Ribbon和Fe', '/static/img/rand/7.jpg', '聊聊 Feign 重试机制？', 0, 'post', 0, '2022-01-22 01:07:57', '1642835276', NULL);
INSERT INTO `qb_details` VALUES (24, 9, '<h2 id=\"-\">为什么要使用服务保障？</h2>\r\n<p>在微服务架构中，我们将业务拆分成一个个的服务，服务与服务之间可以相互调用（RPC）。为了保证其高可用，单个服务又必须集群部署。由于网络原因或者自身的原因，服务并不能保证服务的 100% 可用，如果单个服务出现问题，调用这个服务就会出现网络延迟，此时若有大量的网络涌入，会形成任务累积，导致服务瘫痪，甚至导致服务“雪崩”。为了解决这个问题，就出现断路器模型。</p>\r\n<p>详细的内容，可以看看 <a href=\"https://www.cnblogs.com/xyhero/p/53852cf0245c229fe3e22756a220508b.html\">《为什么要使用断路器 Hystrix？》</a> 。</p>', '## 为什么要使用服务保障？\r\n\r\n在微服务架构中，我们将业务拆分成一个个的服务，服务与服务之间可以相互调用（RPC）。为了保证其高可用，单个服务又必须集群部署。由于网络原因或者自身的原因，服务并不能保证服务的 100% 可用，如果单个服务出现问题，调用这个服务就会出现网络延迟，此时若有大量的网络涌入，会形成任务累积，导致服务瘫痪，甚至导致服务“雪崩”。为了解决这个问题，就出现断路器模型。\r\n\r\n详细的内容，可以看看 [《为什么要使用断路器 Hystrix？》](https://www.cnblogs.com/xyhero/p/53852cf0245c229fe3e22756a220508b.html) 。', '2022-01-22 01:09:57', 0, '为什么要使用服务保障？在微服务架构中，我们将业务拆分成一个个的服务，服务与服务之间可以相互调用（RP', '/static/img/rand/13.jpg', '为什么要使用服务保障？', 0, 'post', 0, '2022-01-22 01:09:57', '1642835397', NULL);
INSERT INTO `qb_details` VALUES (25, 9, '<h2 id=\"hystrix-\">hystrix是干嘛的？</h2>\r\n<p>Hystrix 是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。</p>\r\n<p>作用：断路器，保护系统，控制故障范围。</p>', '## hystrix是干嘛的？\r\n\r\nHystrix 是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。\r\n\r\n作用：断路器，保护系统，控制故障范围。', '2022-01-22 01:12:55', 0, 'hystrix是干嘛的？Hystrix是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，', '/static/img/rand/11.jpg', 'hystrix是干嘛的？', 0, 'post', 0, '2022-01-22 01:12:55', '1642835574', NULL);
INSERT INTO `qb_details` VALUES (26, 9, '<h2 id=\"hystrix-\">Hystrix的隔离模式</h2>\r\n<ol>\r\n<li>线程池隔离模式<br>使用一个线程池用来存储当前的请求，线程池对请求作处理，设置任务返回处理超时时间，堆积的请求堆积入线程池队列。<br>这种方式需要为每个依赖的服务申请线程池，有一定的资源消耗，好处是可以应对突发流量。</li>\r\n<li>信号量隔离模式<br>使用一个原子计数器（或信号量）来记录当前有多少个线程正在运行，请求来先判断计数器的数值。<br>若超过设置的最大线程个数则丢弃该类型的新请求，若不超过则执行计数操作请求，则计数器+1，请求返回计数器-1，无法处理突发流量。</li>\r\n</ol>\r\n<p><img src=\"https://www.ylcoder.top/upload/2022/1/image20220122071346233.png\" alt=\"\"><br>实际场景下，使用线程池隔离居多，因为支持超时功能。</p>\r\n<p>详细的，可以看看 <a href=\"https://blog.csdn.net/liuchuanhong1/article/details/73718794\">《Hystrix 的资源隔离策略》</a> 文章。</p>', '## Hystrix的隔离模式\r\n\r\n1. 线程池隔离模式\r\n  使用一个线程池用来存储当前的请求，线程池对请求作处理，设置任务返回处理超时时间，堆积的请求堆积入线程池队列。\r\n  这种方式需要为每个依赖的服务申请线程池，有一定的资源消耗，好处是可以应对突发流量。\r\n2. 信号量隔离模式\r\n  使用一个原子计数器（或信号量）来记录当前有多少个线程正在运行，请求来先判断计数器的数值。\r\n  若超过设置的最大线程个数则丢弃该类型的新请求，若不超过则执行计数操作请求，则计数器+1，请求返回计数器-1，无法处理突发流量。\r\n\r\n![](https://www.ylcoder.top/upload/2022/1/image20220122071346233.png) \r\n实际场景下，使用线程池隔离居多，因为支持超时功能。\r\n\r\n详细的，可以看看 [《Hystrix 的资源隔离策略》](https://blog.csdn.net/liuchuanhong1/article/details/73718794) 文章。', '2022-01-22 01:14:22', 0, 'Hystrix的隔离模式线程池隔离模式使用一个线程池用来存储当前的请求，线程池对请求作处理，设置任务', '/static/img/rand/8.jpg', 'Hystrix的隔离模式', 0, 'post', 0, '2022-01-22 01:16:04', '1642835662', NULL);
INSERT INTO `qb_details` VALUES (27, 9, '<h2 id=\"-hystrix-\">聊聊 Hystrix 缓存机制？</h2>\r\n<p>Hystrix 提供缓存功能，作用是：</p>\r\n<ul>\r\n<li>减少重复的请求数。</li>\r\n<li>在同一个用户请求的上下文中，相同依赖服务的返回数据始终保持一致。</li>\r\n</ul>\r\n<p>详细的，可以看看 <a href=\"https://blog.csdn.net/zhuchuangang/article/details/74566185\">《Hystrix 缓存功能的使用》</a> 文章。</p>', '## 聊聊 Hystrix 缓存机制？\r\n\r\nHystrix 提供缓存功能，作用是：\r\n\r\n- 减少重复的请求数。\r\n- 在同一个用户请求的上下文中，相同依赖服务的返回数据始终保持一致。\r\n\r\n详细的，可以看看 [《Hystrix 缓存功能的使用》](https://blog.csdn.net/zhuchuangang/article/details/74566185) 文章。', '2022-01-22 01:16:52', 0, '聊聊Hystrix缓存机制？Hystrix提供缓存功能，作用是：减少重复的请求数。在同一个用户请求的', '/static/img/rand/6.jpg', '聊聊 Hystrix 缓存机制？', 0, 'post', 0, '2022-01-22 01:16:52', '1642835811', NULL);
INSERT INTO `qb_details` VALUES (28, 9, '<h2 id=\"-hystrix-\">什么是 Hystrix 断路器？</h2>\r\n<p>Hystrix 断路器通过 HystrixCircuitBreaker 实现。</p>\r\n<p>HystrixCircuitBreaker 有三种状态 ：</p>\r\n<ul>\r\n<li><code>CLOSED</code> ：关闭</li>\r\n<li><code>OPEN</code> ：打开</li>\r\n<li><code>HALF_OPEN</code> ：半开</li>\r\n</ul>\r\n<p>其中，断路器处于 <code>OPEN</code> 状态时，链路处于<strong>非健康</strong>状态，命令执行时，直接调用<strong>回退</strong>逻辑，跳过<strong>正常</strong>逻辑。</p>\r\n<p>HystrixCircuitBreaker 状态变迁如下图 ：</p>\r\n<p><img src=\"https://www.ylcoder.top/upload/2022/1/image20220122071838859.png\" alt=\"\"></p>\r\n<p>HystrixCircuitBreaker 状态</p>\r\n<ul>\r\n<li><strong>红线</strong> ：初始时，断路器处于 <code>CLOSED</code> 状态，链路处于<strong>健康</strong>状态。当满足如下条件，断路器从 <code>CLOSED</code> 变成 <code>OPEN</code> 状态：<ul>\r\n<li><strong>周期</strong>( 可配，<code>HystrixCommandProperties.default_metricsRollingStatisticalWindow = 10000 ms</code> )内，总请求数超过一定<strong>量</strong>( 可配，<code>HystrixCommandProperties.circuitBreakerRequestVolumeThreshold = 20</code> ) 。</li>\r\n<li><strong>错误</strong>请求占总请求数超过一定<strong>比例</strong>( 可配，<code>HystrixCommandProperties.circuitBreakerErrorThresholdPercentage = 50%</code> ) 。</li>\r\n</ul>\r\n</li>\r\n<li><strong>绿线</strong> ：断路器处于 <code>OPEN</code> 状态，命令执行时，若当前时间超过断路器<strong>开启</strong>时间一定时间( <code>HystrixCommandProperties.circuitBreakerSleepWindowInMilliseconds = 5000 ms</code> )，断路器变成 <code>HALF_OPEN</code> 状态，<strong>尝试</strong>调用<strong>正常</strong>逻辑，根据执行是否成功，<strong>打开或关闭</strong>熔断器【<strong>蓝线</strong>】。</li>\r\n</ul>', '## 什么是 Hystrix 断路器？\r\n\r\nHystrix 断路器通过 HystrixCircuitBreaker 实现。\r\n\r\nHystrixCircuitBreaker 有三种状态 ：\r\n\r\n- `CLOSED` ：关闭\r\n- `OPEN` ：打开\r\n- `HALF_OPEN` ：半开\r\n\r\n其中，断路器处于 `OPEN` 状态时，链路处于**非健康**状态，命令执行时，直接调用**回退**逻辑，跳过**正常**逻辑。\r\n\r\nHystrixCircuitBreaker 状态变迁如下图 ：\r\n\r\n![](https://www.ylcoder.top/upload/2022/1/image20220122071838859.png)\r\n\r\nHystrixCircuitBreaker 状态\r\n\r\n- **红线** ：初始时，断路器处于 `CLOSED` 状态，链路处于**健康**状态。当满足如下条件，断路器从 `CLOSED` 变成 `OPEN` 状态：\r\n    - **周期**( 可配，`HystrixCommandProperties.default_metricsRollingStatisticalWindow = 10000 ms` )内，总请求数超过一定**量**( 可配，`HystrixCommandProperties.circuitBreakerRequestVolumeThreshold = 20` ) 。\r\n    - **错误**请求占总请求数超过一定**比例**( 可配，`HystrixCommandProperties.circuitBreakerErrorThresholdPercentage = 50%` ) 。\r\n- **绿线** ：断路器处于 `OPEN` 状态，命令执行时，若当前时间超过断路器**开启**时间一定时间( `HystrixCommandProperties.circuitBreakerSleepWindowInMilliseconds = 5000 ms` )，断路器变成 `HALF_OPEN` 状态，**尝试**调用**正常**逻辑，根据执行是否成功，**打开或关闭**熔断器【**蓝线**】。', '2022-01-22 01:19:01', 0, '什么是Hystrix断路器？Hystrix断路器通过HystrixCircuitBreaker实现。', '/static/img/rand/12.jpg', '什么是 Hystrix 断路器？', 0, 'post', 0, '2022-01-22 01:19:01', '1642835940', NULL);
INSERT INTO `qb_details` VALUES (29, 9, '<h2 id=\"-hystrix-\">什么是 Hystrix 服务降级？</h2>\r\n<p>在 Hystrix 断路器熔断时，可以调用一个降级方法，返回相应的结果。当然，降级方法需要配置和编码，如果胖友不需要，也可以不写，也就是不会有服务降级的功能。</p>\r\n<p>具体的使用方式，可以看看 <a href=\"https://blog.csdn.net/jiaobuchong/article/details/78232920\">《通过 Hystrix 理解熔断和降级》</a> 。</p>', '## 什么是 Hystrix 服务降级？\r\n\r\n在 Hystrix 断路器熔断时，可以调用一个降级方法，返回相应的结果。当然，降级方法需要配置和编码，如果胖友不需要，也可以不写，也就是不会有服务降级的功能。\r\n\r\n具体的使用方式，可以看看 [《通过 Hystrix 理解熔断和降级》](https://blog.csdn.net/jiaobuchong/article/details/78232920) 。', '2022-01-22 01:19:49', 0, '什么是Hystrix服务降级？在Hystrix断路器熔断时，可以调用一个降级方法，返回相应的结果。当', '/static/img/rand/12.jpg', '什么是 Hystrix 服务降级？', 0, 'post', 0, '2022-01-22 01:19:49', '1642835988', NULL);
INSERT INTO `qb_details` VALUES (30, 9, '<h2 id=\"-\">为什么要网关服务？</h2>\r\n<p>使用网关服务，我们实现统一的功能：</p>\r\n<ul>\r\n<li>动态路由</li>\r\n<li>灰度发布</li>\r\n<li>健康检查</li>\r\n<li>限流</li>\r\n<li>熔断</li>\r\n<li>认证: 如数支持 HMAC, JWT, Basic, OAuth 2.0 等常用协议</li>\r\n<li>鉴权: 权限控制，IP 黑白名单，同样是 OpenResty 的特性</li>\r\n<li>可用性</li>\r\n<li>高性能</li>\r\n</ul>\r\n<p>详细的，可以看看 <a href=\"http://dockone.io/article/2033\">《为什么微服务需要 API 网关？》</a> 。</p>', '## 为什么要网关服务？\r\n\r\n使用网关服务，我们实现统一的功能：\r\n\r\n- 动态路由\r\n- 灰度发布\r\n- 健康检查\r\n- 限流\r\n- 熔断\r\n- 认证: 如数支持 HMAC, JWT, Basic, OAuth 2.0 等常用协议\r\n- 鉴权: 权限控制，IP 黑白名单，同样是 OpenResty 的特性\r\n- 可用性\r\n- 高性能\r\n\r\n详细的，可以看看 [《为什么微服务需要 API 网关？》](http://dockone.io/article/2033) 。', '2022-01-22 01:22:20', 0, '为什么要网关服务？使用网关服务，我们实现统一的功能：动态路由灰度发布健康检查限流熔断认证:如数支持H', '/static/img/rand/17.jpg', '为什么要网关服务？', 0, 'post', 0, '2022-01-22 01:22:20', '1642836140', NULL);
INSERT INTO `qb_details` VALUES (31, 9, '<h2 id=\"-\">有哪些配置中心？</h2>\r\n<p>在 Spring Cloud 中，能够使用的配置中心，如下：</p>\r\n<ul>\r\n<li><a href=\"https://github.com/spring-cloud/spring-cloud-config\"><code>spring-cloud-config</code></a> ，基于 Git、SVN 作为存储。</li>\r\n<li><a href=\"https://github.com/spring-cloud-incubator/spring-cloud-alibaba/tree/master/spring-cloud-alibaba-nacos-config\"><code>spring-cloud-alibaba-nacos-config</code></a> ，基于 Nacos 实现。</li>\r\n<li><a href=\"https://github.com/ctripcorp/apollo\">Apollo</a> ，携程开源的配置中心。</li>\r\n</ul>', '## 有哪些配置中心？\r\n\r\n在 Spring Cloud 中，能够使用的配置中心，如下：\r\n\r\n- [`spring-cloud-config`](https://github.com/spring-cloud/spring-cloud-config) ，基于 Git、SVN 作为存储。\r\n- [`spring-cloud-alibaba-nacos-config`](https://github.com/spring-cloud-incubator/spring-cloud-alibaba/tree/master/spring-cloud-alibaba-nacos-config) ，基于 Nacos 实现。\r\n- [Apollo](https://github.com/ctripcorp/apollo) ，携程开源的配置中心。', '2022-01-22 01:28:44', 0, '有哪些配置中心？在SpringCloud中，能够使用的配置中心，如下：spring-cloud-co', '/static/img/rand/1.jpg', '有哪些配置中心？', 0, 'post', 0, '2022-01-22 01:28:44', '1642836523', NULL);
INSERT INTO `qb_details` VALUES (32, 9, '<h2 id=\"-springcloud-config-\">什么是 SpringCloud Config？</h2>\r\n<p>它的作用是配置管理。Spring Cloud Config 提供服务器端和客户端。服务器存储后端的默认实现使用 Git ，因此它轻松支持标签版本的配置环境，以及可以访问用于管理内容的各种工具。</p>\r\n<p>这个还是静态的，得配合 Spring Cloud Bus 实现动态的配置更新。</p>', '## 什么是 SpringCloud Config？\r\n\r\n它的作用是配置管理。Spring Cloud Config 提供服务器端和客户端。服务器存储后端的默认实现使用 Git ，因此它轻松支持标签版本的配置环境，以及可以访问用于管理内容的各种工具。\r\n\r\n这个还是静态的，得配合 Spring Cloud Bus 实现动态的配置更新。', '2022-01-22 01:32:07', 0, '什么是SpringCloudConfig？它的作用是配置管理。SpringCloudConfig提供', '/static/img/rand/11.jpg', '什么是 SpringCloud Config？', 0, 'post', 0, '2022-01-22 01:32:07', '1642836727', NULL);
INSERT INTO `qb_details` VALUES (33, 9, '<h2 id=\"mybatis-a-include-b-b-a-a-\">Mybatis 映射文件中，如果 A 标签通过 include 引用了B标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在A标签的前面？</h2>\r\n<p>虽然 Mybatis 解析 XML 映射文件是<strong>按照顺序</strong>解析的。但是，被引用的 B 标签依然可以定义在任何地方，Mybatis 都可以正确识别。<strong>也就是说，无需按照顺序，进行定义</strong>。</p>\r\n<p>原理是，Mybatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，Mybatis 会将 A 标签标记为<strong>未解析状态</strong>。然后，继续解析余下的标签，包含 B 标签，待所有标签解析完毕，Mybatis 会重新解析那些被标记为未解析的标签，此时再解析A标签时，B 标签已经存在，A 标签也就可以正常解析完成了。</p>\r\n<p>可能有一些绕，胖友可以看看 <a href=\"http://svip.iocoder.cn/MyBatis/builder-package-1\">《精尽 MyBatis 源码解析 —— MyBatis 初始化（一）之加载 mybatis-config》</a> 。</p>\r\n<p>此处，我们在引申一个问题，Spring IOC 中，存在互相依赖的 Bean 对象，该如何解决呢？答案见 <a href=\"http://svip.iocoder.cn/Spring/IoC-get-Bean-createBean-5/\">《【死磕 Spring】—— IoC 之加载 Bean：创建 Bean（五）之循环依赖处理》</a> 。</p>', '## Mybatis 映射文件中，如果 A 标签通过 include 引用了B标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在A标签的前面？\r\n\r\n虽然 Mybatis 解析 XML 映射文件是**按照顺序**解析的。但是，被引用的 B 标签依然可以定义在任何地方，Mybatis 都可以正确识别。**也就是说，无需按照顺序，进行定义**。\r\n\r\n原理是，Mybatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，Mybatis 会将 A 标签标记为**未解析状态**。然后，继续解析余下的标签，包含 B 标签，待所有标签解析完毕，Mybatis 会重新解析那些被标记为未解析的标签，此时再解析A标签时，B 标签已经存在，A 标签也就可以正常解析完成了。\r\n\r\n可能有一些绕，胖友可以看看 [《精尽 MyBatis 源码解析 —— MyBatis 初始化（一）之加载 mybatis-config》](http://svip.iocoder.cn/MyBatis/builder-package-1) 。\r\n\r\n此处，我们在引申一个问题，Spring IOC 中，存在互相依赖的 Bean 对象，该如何解决呢？答案见 [《【死磕 Spring】—— IoC 之加载 Bean：创建 Bean（五）之循环依赖处理》](http://svip.iocoder.cn/Spring/IoC-get-Bean-createBean-5/) 。', '2022-01-22 01:49:01', 0, 'Mybatis映射文件中，如果A标签通过include引用了B标签的内容，请问，B标签能否定义在A标', '/static/img/rand/9.jpg', 'Mybatis 映射文件中，如果 A 标签通过 include 引用了B标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在A标签的前面？', 0, 'post', 0, '2022-01-22 01:49:01', '1642837740', NULL);
INSERT INTO `qb_details` VALUES (34, 9, '<h2 id=\"-mybatis-xml-mybatis-\">简述 Mybatis 的 XML 映射文件和 Mybatis 内部数据结构之间的映射关系？</h2>\r\n<p>Mybatis 将所有 XML 配置信息都封装到 All-In-One 重量级对象Configuration内部。</p>\r\n<p>在 XML Mapper 文件中：</p>\r\n<ul>\r\n<li><code>&lt;parameterMap&gt;</code> 标签，会被解析为 ParameterMap 对象，其每个子元素会被解析为 ParameterMapping 对象。</li>\r\n<li><code>&lt;resultMap&gt;</code> 标签，会被解析为 ResultMap 对象，其每个子元素会被解析为 ResultMapping 对象。</li>\r\n<li>每一个 <code>&lt;select&gt;</code>、<code>&lt;insert&gt;</code>、<code>&lt;update&gt;</code>、<code>&lt;delete&gt;</code> 标签，均会被解析为一个 MappedStatement 对象，标签内的 SQL 会被解析为一个 BoundSql 对象。</li>\r\n</ul>', '## 简述 Mybatis 的 XML 映射文件和 Mybatis 内部数据结构之间的映射关系？\r\n\r\nMybatis 将所有 XML 配置信息都封装到 All-In-One 重量级对象Configuration内部。\r\n\r\n在 XML Mapper 文件中：\r\n\r\n- `<parameterMap>` 标签，会被解析为 ParameterMap 对象，其每个子元素会被解析为 ParameterMapping 对象。\r\n- `<resultMap>` 标签，会被解析为 ResultMap 对象，其每个子元素会被解析为 ResultMapping 对象。\r\n- 每一个 `<select>`、`<insert>`、`<update>`、`<delete>` 标签，均会被解析为一个 MappedStatement 对象，标签内的 SQL 会被解析为一个 BoundSql 对象。', '2022-01-22 01:49:49', 0, '简述Mybatis的XML映射文件和Mybatis内部数据结构之间的映射关系？Mybatis将所有X', '/static/img/rand/3.jpg', '简述 Mybatis 的 XML 映射文件和 Mybatis 内部数据结构之间的映射关系？', 0, 'post', 0, '2022-01-22 01:49:49', '1642837789', NULL);
INSERT INTO `qb_details` VALUES (35, 9, '<h2 id=\"-\">什么是消息队列？</h2>\r\n<p>消息队列，是分布式系统中重要的组件。</p>\r\n<ul>\r\n<li>主要解决应用耦合，异步消息，流量削锋等问题。</li>\r\n<li>可实现高性能，高可用，可伸缩和最终一致性架构，是大型分布式系统不可缺少的中间件。</li>\r\n</ul>\r\n<p>目前主流的消息队列有</p>\r\n<ul>\r\n<li>Kafka</li>\r\n<li>RabbitMQ</li>\r\n<li>RocketMQ ，老版本是 MetaQ 。</li>\r\n<li>ActiveMQ ，目前用的人越来越少了。</li>\r\n</ul>\r\n<p>另外，消息队列容易和 Java 中的本地 MessageQueue 搞混，所以消息队列更多被称为消息中间件、分布式消息队列等等。</p>', '## 什么是消息队列？\r\n\r\n消息队列，是分布式系统中重要的组件。\r\n\r\n- 主要解决应用耦合，异步消息，流量削锋等问题。\r\n- 可实现高性能，高可用，可伸缩和最终一致性架构，是大型分布式系统不可缺少的中间件。\r\n\r\n目前主流的消息队列有\r\n\r\n- Kafka\r\n- RabbitMQ\r\n- RocketMQ ，老版本是 MetaQ 。\r\n- ActiveMQ ，目前用的人越来越少了。\r\n\r\n另外，消息队列容易和 Java 中的本地 MessageQueue 搞混，所以消息队列更多被称为消息中间件、分布式消息队列等等。', '2022-01-22 03:29:17', 0, '什么是消息队列？消息队列，是分布式系统中重要的组件。主要解决应用耦合，异步消息，流量削锋等问题。可实', '/static/img/rand/11.jpg', '什么是消息队列？', 0, 'post', 0, '2022-01-22 03:29:17', '1642843756', NULL);
INSERT INTO `qb_details` VALUES (36, 9, '<h2 id=\"-\">消息队列有几种消费语义？</h2>\r\n<p>一共有 3 种，分别如下：</p>\r\n<ol>\r\n<li>消息至多被消费一次（At most once）：消息可能会丢失，但绝不重传。</li>\r\n<li>消息至少被消费一次（At least once）：消息可以重传，但绝不丢失。</li>\r\n<li>消息仅被消费一次（Exactly once）：每一条消息只被传递一次。</li>\r\n</ol>\r\n<p>为了支持上面 3 种消费语义，可以分 3 个阶段，考虑消息队列系统中Producer、Message Broker、Consumer 需要满足的条件。</p>\r\n<blockquote>\r\n<p>下面的内容，可能比较绕，胖友耐心理解。</p>\r\n</blockquote>\r\n<p>该语义是最容易满足的，特点是整个消息队列吞吐量大，实现简单。适合能容忍丢消息，消息重复消费的任务（和厮大沟通了下，这句话应该是错的，所以去掉）。</p>\r\n<blockquote>\r\n<p>和晓峰又讨论了下，“消息重复消费的任务”的意思是，因为不会重复投递，所以间接解决了消息重复消费的问题。</p>\r\n</blockquote>\r\n<ul>\r\n<li>Producer 发送消息到 Message Broker 阶段<ul>\r\n<li>Producer 发消息给Message Broker 时，不要求 Message Broker 对接收到的消息响应确认，Producer 也不用关心 Message Broker 是否收到消息了。</li>\r\n</ul>\r\n</li>\r\n<li>Message Broker 存储/转发阶段<ul>\r\n<li>对 Message Broker 的存储不要求持久性。</li>\r\n<li>转发消息时，也不用关心 Consumer 是否真的收到了。</li>\r\n</ul>\r\n</li>\r\n<li><p>Consumer 消费阶段</p>\r\n<ul>\r\n<li>Consumer 从 Message Broker 中获取到消息后，可以从 Message Broker 删除消息。</li>\r\n<li><p>或 Message Broker 在消息被 Consumer 拿去消费时删除消息，不用关心 Consumer 最后对消息的消费情况如何。</p>\r\n<p><strong>2. 消息至少被消费一次</strong></p>\r\n</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p>适合不能容忍丢消息，允许重复消费的任务。</p>\r\n<ul>\r\n<li>Producer 发送消息到 Message Broker 阶段<ul>\r\n<li>Producer 发消息给 Message Broker ，Message Broker 必须响应对消息的确认。</li>\r\n</ul>\r\n</li>\r\n<li>Message Broker 存储/转发阶段<ul>\r\n<li>Message Broker 必须提供持久性保障。</li>\r\n<li>转发消息时，Message Broker 需要 Consumer 通知删除消息，才能将消息删除。</li>\r\n</ul>\r\n</li>\r\n<li><p>Consumer消费阶段</p>\r\n<ul>\r\n<li><p>Consumer 从 Message Broker 中获取到消息，必须在消费完成后，Message Broker上的消息才能被删除。</p>\r\n<p><strong>3. 消息仅被消费一次</strong></p>\r\n</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p>适合对消息消费情况要求非常高的任务，实现较为复杂。</p>\r\n<p>在这里需要考虑一个问题，就是这里的“仅被消费一次”指的是如下哪种场景：</p>\r\n<ul>\r\n<li>Message Broker 上存储的消息被 Consumer 仅消费一次。</li>\r\n<li>Producer 上产生的消息被 Consumer 仅消费一次。</li>\r\n</ul>\r\n<p>① Message Broker 上存储的消息被 Consumer 仅消费一次</p>\r\n<ul>\r\n<li>Producer 发送消息到 Message Broker 阶段<ul>\r\n<li>Producer 发消息给 Message Broker 时，不要求 Message Broker 对接收到的消息响应确认，Producer 也不用关心Message Broker 是否收到消息了。</li>\r\n</ul>\r\n</li>\r\n<li>Message Broker 存储/转发阶段<ul>\r\n<li>Message Broker 必须提供持久性保障</li>\r\n<li>并且，每条消息在其消费队列里有唯一标识（这个唯一标识可以由 Producer 产生，也可以由 Message Broker 产生）。</li>\r\n</ul>\r\n</li>\r\n<li>Consumer 消费阶段<ul>\r\n<li>Consumer 从 Message Broker中获取到消息后，需要记录下消费的消息标识，以便在后续消费中防止对某个消息重复消费（比如 Consumer 获取到消息，消费完后，还没来得及从 Message Broker 删除消息，就挂了，这样 Message Broker 如果把消息重新加入待消费队列的话，那么这条消息就会被重复消费了）。</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p>② Producer 上产生的消息被 Consumer 仅消费一次</p>\r\n<ul>\r\n<li>Producer 发送消息到 Message Broker 阶段<ul>\r\n<li>Producer 发消息给 Message Broker 时，Message Broker 必须响应对消息的确认，并且 Producer 负责为该消息产生唯一标识，以防止 Consumer 重复消费（因为 Producer 发消息给Message Broker 后，由于网络问题没收到 Message Broker 的响应，可能会重发消息给到 Message Broker ）。</li>\r\n</ul>\r\n</li>\r\n<li>Message Broker 存储/转发阶段<ul>\r\n<li>Message Broker 必须提供持久性保障</li>\r\n<li>并且，每条消息在其消费队列里有唯一标识（这个唯一标识需要由Producer产生）。</li>\r\n</ul>\r\n</li>\r\n<li>Consumer 消费阶段<ul>\r\n<li>和【① Message Broker 上存储的消息被 Consumer 仅消费一次】相同。</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<hr>\r\n<p>虽然 3 种方式看起来比较复杂，但是我们会发现，是层层递进，越来越可靠。</p>\r\n<p>实际生产场景下，我们是倾向第 3 种的 ② 的情况，每条消息从 Producer 保证被送达，并且被 Consumer 仅消费一次。当然，重心还是如何保证 <strong>Consumer 仅消费一次</strong>，虽然说，消息产生的唯一标志可以在框架层级去做排重，但是最稳妥的，还是业务层也保证消费的幂等性。</p>', '## 消息队列有几种消费语义？\r\n\r\n一共有 3 种，分别如下：\r\n\r\n1. 消息至多被消费一次（At most once）：消息可能会丢失，但绝不重传。\r\n2. 消息至少被消费一次（At least once）：消息可以重传，但绝不丢失。\r\n3. 消息仅被消费一次（Exactly once）：每一条消息只被传递一次。\r\n\r\n为了支持上面 3 种消费语义，可以分 3 个阶段，考虑消息队列系统中Producer、Message Broker、Consumer 需要满足的条件。\r\n\r\n> 下面的内容，可能比较绕，胖友耐心理解。\r\n\r\n该语义是最容易满足的，特点是整个消息队列吞吐量大，实现简单。适合能容忍丢消息，消息重复消费的任务（和厮大沟通了下，这句话应该是错的，所以去掉）。\r\n\r\n> 和晓峰又讨论了下，“消息重复消费的任务”的意思是，因为不会重复投递，所以间接解决了消息重复消费的问题。\r\n\r\n- Producer 发送消息到 Message Broker 阶段\r\n    - Producer 发消息给Message Broker 时，不要求 Message Broker 对接收到的消息响应确认，Producer 也不用关心 Message Broker 是否收到消息了。\r\n- Message Broker 存储/转发阶段\r\n    - 对 Message Broker 的存储不要求持久性。\r\n    - 转发消息时，也不用关心 Consumer 是否真的收到了。\r\n- Consumer 消费阶段\r\n    - Consumer 从 Message Broker 中获取到消息后，可以从 Message Broker 删除消息。\r\n    - 或 Message Broker 在消息被 Consumer 拿去消费时删除消息，不用关心 Consumer 最后对消息的消费情况如何。\r\n\r\n    **2. 消息至少被消费一次**\r\n\r\n适合不能容忍丢消息，允许重复消费的任务。\r\n\r\n- Producer 发送消息到 Message Broker 阶段\r\n    - Producer 发消息给 Message Broker ，Message Broker 必须响应对消息的确认。\r\n- Message Broker 存储/转发阶段\r\n    - Message Broker 必须提供持久性保障。\r\n    - 转发消息时，Message Broker 需要 Consumer 通知删除消息，才能将消息删除。\r\n- Consumer消费阶段\r\n    - Consumer 从 Message Broker 中获取到消息，必须在消费完成后，Message Broker上的消息才能被删除。\r\n\r\n    **3. 消息仅被消费一次**\r\n\r\n适合对消息消费情况要求非常高的任务，实现较为复杂。\r\n\r\n在这里需要考虑一个问题，就是这里的“仅被消费一次”指的是如下哪种场景：\r\n\r\n- Message Broker 上存储的消息被 Consumer 仅消费一次。\r\n- Producer 上产生的消息被 Consumer 仅消费一次。\r\n\r\n① Message Broker 上存储的消息被 Consumer 仅消费一次\r\n\r\n- Producer 发送消息到 Message Broker 阶段\r\n    - Producer 发消息给 Message Broker 时，不要求 Message Broker 对接收到的消息响应确认，Producer 也不用关心Message Broker 是否收到消息了。\r\n- Message Broker 存储/转发阶段\r\n    - Message Broker 必须提供持久性保障\r\n    - 并且，每条消息在其消费队列里有唯一标识（这个唯一标识可以由 Producer 产生，也可以由 Message Broker 产生）。\r\n- Consumer 消费阶段\r\n    - Consumer 从 Message Broker中获取到消息后，需要记录下消费的消息标识，以便在后续消费中防止对某个消息重复消费（比如 Consumer 获取到消息，消费完后，还没来得及从 Message Broker 删除消息，就挂了，这样 Message Broker 如果把消息重新加入待消费队列的话，那么这条消息就会被重复消费了）。\r\n\r\n② Producer 上产生的消息被 Consumer 仅消费一次\r\n\r\n- Producer 发送消息到 Message Broker 阶段\r\n    - Producer 发消息给 Message Broker 时，Message Broker 必须响应对消息的确认，并且 Producer 负责为该消息产生唯一标识，以防止 Consumer 重复消费（因为 Producer 发消息给Message Broker 后，由于网络问题没收到 Message Broker 的响应，可能会重发消息给到 Message Broker ）。\r\n- Message Broker 存储/转发阶段\r\n    - Message Broker 必须提供持久性保障\r\n    - 并且，每条消息在其消费队列里有唯一标识（这个唯一标识需要由Producer产生）。\r\n- Consumer 消费阶段\r\n    - 和【① Message Broker 上存储的消息被 Consumer 仅消费一次】相同。\r\n\r\n---\r\n\r\n虽然 3 种方式看起来比较复杂，但是我们会发现，是层层递进，越来越可靠。\r\n\r\n实际生产场景下，我们是倾向第 3 种的 ② 的情况，每条消息从 Producer 保证被送达，并且被 Consumer 仅消费一次。当然，重心还是如何保证 **Consumer 仅消费一次**，虽然说，消息产生的唯一标志可以在框架层级去做排重，但是最稳妥的，还是业务层也保证消费的幂等性。', '2022-01-22 03:36:30', 0, '消息队列有几种消费语义？一共有3种，分别如下：消息至多被消费一次（Atmostonce）：消息可能会', '/static/img/rand/18.jpg', '消息队列有几种消费语义？', 0, 'post', 0, '2022-01-22 03:36:30', '1642844189', NULL);
INSERT INTO `qb_details` VALUES (37, 9, '<h2 id=\"-\">消息队列有几种投递方式？分别有什么优缺点</h2>\r\n<p>在 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「消息队列由哪些角色组成？」</a> 中，我们已经提到消息队列有 <strong>push 推送</strong>和 <strong>pull 拉取</strong>两种投递方式。</p>\r\n<p>一种模型的某些场景下的优点，在另一些场景就可能是缺点。无论是 push 还是 pull ，都存在各种的利弊。</p>\r\n<ul>\r\n<li>push<ul>\r\n<li>优点，就是及时性。</li>\r\n<li>缺点，就是受限于消费者的消费能力，可能造成消息的堆积，Broker 会不断给消费者发送不能处理的消息。</li>\r\n</ul>\r\n</li>\r\n<li>pull<ul>\r\n<li>优点，就是主动权掌握在消费方，可以根据自己的消息速度进行消息拉取。</li>\r\n<li>缺点，就是消费方不知道什么时候可以获取的最新的消息，会有消息延迟和忙等。</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p>目前的消息队列，基于 push + pull 模式结合的方式，Broker 仅仅告诉 Consumer 有新的消息，具体的消息拉取，还是 Consumer 自己主动拉取。</p>', '## 消息队列有几种投递方式？分别有什么优缺点\r\n\r\n在 [「消息队列由哪些角色组成？」](http://svip.iocoder.cn/MQ/Interview/#) 中，我们已经提到消息队列有 **push 推送**和 **pull 拉取**两种投递方式。\r\n\r\n一种模型的某些场景下的优点，在另一些场景就可能是缺点。无论是 push 还是 pull ，都存在各种的利弊。\r\n\r\n- push\r\n    - 优点，就是及时性。\r\n    - 缺点，就是受限于消费者的消费能力，可能造成消息的堆积，Broker 会不断给消费者发送不能处理的消息。\r\n- pull\r\n    - 优点，就是主动权掌握在消费方，可以根据自己的消息速度进行消息拉取。\r\n    - 缺点，就是消费方不知道什么时候可以获取的最新的消息，会有消息延迟和忙等。\r\n\r\n目前的消息队列，基于 push + pull 模式结合的方式，Broker 仅仅告诉 Consumer 有新的消息，具体的消息拉取，还是 Consumer 自己主动拉取。', '2022-01-22 03:38:00', 0, '消息队列有几种投递方式？分别有什么优缺点在「消息队列由哪些角色组成？」中，我们已经提到消息队列有pu', '/static/img/rand/14.jpg', '消息队列有几种投递方式？分别有什么优缺点', 0, 'post', 0, '2022-01-22 03:38:00', '1642844280', NULL);
INSERT INTO `qb_details` VALUES (38, 9, '<h2 id=\"-\">如何保证消费者的消费消息的幂等性？</h2>\r\n<p><strong>分析原因</strong></p>\r\n<p>在 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「消息队列有几种消费语义？」</a> 中，我们已经看了三种消费语义。如果要达到消费者的消费消息的幂等性，就需要<strong>消息仅被消费一次</strong>，且<strong>每条消息从 Producer 保证被送达，并且被 Consumer 仅消费一次</strong>。</p>\r\n<p>那么，我们就基于这个场景，来思考下，为什么会出现消息重复的问题？</p>\r\n<ul>\r\n<li>对于 Producer 来说<ul>\r\n<li>可能因为网络问题，Producer 重试多次发送消息，实际第一次就发送成功，那么就会产生多条相同的消息。</li>\r\n<li>….</li>\r\n</ul>\r\n</li>\r\n<li><p>对于 Consumer 来说</p>\r\n<ul>\r\n<li>可能因为 Broker 的消息进度丢失，导致消息重复投递给 Consumer 。</li>\r\n<li><p>Consumer 消费成功，但是因为 JVM 异常崩溃，导致消息的消费进度未及时同步给 Consumer 。</p>\r\n<blockquote>\r\n<p>对于大多数消息队列，考虑到性能，消费进度是异步定时同步给 Broker 。</p>\r\n</blockquote>\r\n</li>\r\n<li>…</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p><strong>如何解决</strong></p>\r\n<p>所以，上述的种种情况，都可能导致消费者会获取到重复的消息，那么我们的思考就无法是解决不发送、投递重复的消息，而是消费者在消费时，如何保证幂等性。</p>\r\n<p>消费者实现幂等性，有两种方式：</p>\r\n<ol>\r\n<li>框架层统一封装。</li>\r\n<li>业务层自己实现。</li>\r\n</ol>\r\n<p>① <strong>框架层统一封装</strong></p>\r\n<p>首先，需要有一个消息排重的唯一标识，该编号只能由 Producer 生成，例如说使用 uuid、或者其它唯一编号的算法 。</p>\r\n<p>然后，就需要有一个排重的存储器，例如说：</p>\r\n<ul>\r\n<li>使用关系数据库，增加一个排重表，使用消息编号作为唯一主键。</li>\r\n<li>使用 KV 数据库，KEY 存储消息编号，VALUE 任一。<em>此处，暂时不考虑 KV 数据库持久化的问题</em></li>\r\n</ul>\r\n<p>那么，我们要什么时候插入这条排重记录呢？</p>\r\n<ul>\r\n<li>在消息消费执行业务逻辑<strong>之前</strong>，插入这条排重记录。但是，此时会有可能 JVM 异常崩溃。那么 JVM 重启后，这条消息就无法被消费了。因为，已经存在这条排重记录。</li>\r\n<li>在消息消费执行业务逻辑<strong>之后</strong>，插入这条排重记录。<ul>\r\n<li>如果业务逻辑执行失败，显然，我们不能插入这条排重记录，因为我们后续要消费重试。</li>\r\n<li>如果业务逻辑执行成功，此时，我们可以插入这条排重记录。但是，万一插入这条排重记录失败呢？<strong>那么，需要让插入记录和业务逻辑在同一个事务当中，此时，我们只能使用数据库</strong>。</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p>② <strong>业务层自己实现</strong></p>\r\n<p>方式很多，这个和 HTTP 请求实现幂等是一样的逻辑：</p>\r\n<ul>\r\n<li>先查询数据库，判断数据是否已经被更新过。如果是，则直接返回消费完成，否则执行消费。</li>\r\n<li>更新数据库时，带上数据的状态。如果更新失败，则直接返回消费完成，否则执行消费。</li>\r\n<li>…</li>\r\n</ul>\r\n<p>如果胖友的系统的并发量非常大，可以使用 Zookeeper 或者 Redis 实现分布式锁，避免并发带来的问题。当然，引入一个组件，也会带来另外的复杂性：</p>\r\n<ol>\r\n<li>系统的并发能力下降。</li>\r\n<li>Zookeeper 和 Redis 在获取分布式锁时，发现它们已经挂掉，此时到底要不要继续执行下去呢？嘿嘿。</li>\r\n</ol>\r\n<p><strong>选择</strong></p>\r\n<p>正常情况下，出现重复消息的概率其实很小，如果由框架层统一封装来实现的话，肯定会对消息系统的吞吐量和高可用有影响，所以最好还是由业务层自己实现处理消息重复的问题。</p>\r\n<p>当然，这两种方式不是冲突的。可以提供不同类型的消息，根据配置，使用哪种方式。例如说：</p>\r\n<ul>\r\n<li>默认情况下，开启【框架层统一封装】的功能。</li>\r\n<li>可以通过配置，关闭【框架层统一封装】的功能。</li>\r\n</ul>\r\n<p>当然，如果可能的话，尽可能业务层自己实现。/(ㄒoㄒ)/~~但是，实际上，很多时候，开发者不太会注意，哈哈哈哈。</p>', '## 如何保证消费者的消费消息的幂等性？\r\n\r\n**分析原因**\r\n\r\n在 [「消息队列有几种消费语义？」](http://svip.iocoder.cn/MQ/Interview/#) 中，我们已经看了三种消费语义。如果要达到消费者的消费消息的幂等性，就需要**消息仅被消费一次**，且**每条消息从 Producer 保证被送达，并且被 Consumer 仅消费一次**。\r\n\r\n那么，我们就基于这个场景，来思考下，为什么会出现消息重复的问题？\r\n\r\n- 对于 Producer 来说\r\n    - 可能因为网络问题，Producer 重试多次发送消息，实际第一次就发送成功，那么就会产生多条相同的消息。\r\n    - ….\r\n- 对于 Consumer 来说\r\n    - 可能因为 Broker 的消息进度丢失，导致消息重复投递给 Consumer 。\r\n    - Consumer 消费成功，但是因为 JVM 异常崩溃，导致消息的消费进度未及时同步给 Consumer 。\r\n\r\n        > 对于大多数消息队列，考虑到性能，消费进度是异步定时同步给 Broker 。\r\n    - …\r\n\r\n**如何解决**\r\n\r\n所以，上述的种种情况，都可能导致消费者会获取到重复的消息，那么我们的思考就无法是解决不发送、投递重复的消息，而是消费者在消费时，如何保证幂等性。\r\n\r\n消费者实现幂等性，有两种方式：\r\n\r\n1. 框架层统一封装。\r\n2. 业务层自己实现。\r\n\r\n① **框架层统一封装**\r\n\r\n首先，需要有一个消息排重的唯一标识，该编号只能由 Producer 生成，例如说使用 uuid、或者其它唯一编号的算法 。\r\n\r\n然后，就需要有一个排重的存储器，例如说：\r\n\r\n- 使用关系数据库，增加一个排重表，使用消息编号作为唯一主键。\r\n- 使用 KV 数据库，KEY 存储消息编号，VALUE 任一。*此处，暂时不考虑 KV 数据库持久化的问题*\r\n\r\n那么，我们要什么时候插入这条排重记录呢？\r\n\r\n- 在消息消费执行业务逻辑**之前**，插入这条排重记录。但是，此时会有可能 JVM 异常崩溃。那么 JVM 重启后，这条消息就无法被消费了。因为，已经存在这条排重记录。\r\n- 在消息消费执行业务逻辑**之后**，插入这条排重记录。\r\n    - 如果业务逻辑执行失败，显然，我们不能插入这条排重记录，因为我们后续要消费重试。\r\n    - 如果业务逻辑执行成功，此时，我们可以插入这条排重记录。但是，万一插入这条排重记录失败呢？**那么，需要让插入记录和业务逻辑在同一个事务当中，此时，我们只能使用数据库**。\r\n\r\n② **业务层自己实现**\r\n\r\n方式很多，这个和 HTTP 请求实现幂等是一样的逻辑：\r\n\r\n- 先查询数据库，判断数据是否已经被更新过。如果是，则直接返回消费完成，否则执行消费。\r\n- 更新数据库时，带上数据的状态。如果更新失败，则直接返回消费完成，否则执行消费。\r\n- …\r\n\r\n如果胖友的系统的并发量非常大，可以使用 Zookeeper 或者 Redis 实现分布式锁，避免并发带来的问题。当然，引入一个组件，也会带来另外的复杂性：\r\n\r\n1. 系统的并发能力下降。\r\n2. Zookeeper 和 Redis 在获取分布式锁时，发现它们已经挂掉，此时到底要不要继续执行下去呢？嘿嘿。\r\n\r\n**选择**\r\n\r\n正常情况下，出现重复消息的概率其实很小，如果由框架层统一封装来实现的话，肯定会对消息系统的吞吐量和高可用有影响，所以最好还是由业务层自己实现处理消息重复的问题。\r\n\r\n当然，这两种方式不是冲突的。可以提供不同类型的消息，根据配置，使用哪种方式。例如说：\r\n\r\n- 默认情况下，开启【框架层统一封装】的功能。\r\n- 可以通过配置，关闭【框架层统一封装】的功能。\r\n\r\n当然，如果可能的话，尽可能业务层自己实现。/(ㄒoㄒ)/~~但是，实际上，很多时候，开发者不太会注意，哈哈哈哈。', '2022-01-22 03:40:49', 0, '如何保证消费者的消费消息的幂等性？分析原因在「消息队列有几种消费语义？」中，我们已经看了三种消费语义', '/static/img/rand/17.jpg', '如何保证消费者的消费消息的幂等性？', 0, 'post', 0, '2022-01-22 03:40:49', '1642844449', NULL);
INSERT INTO `qb_details` VALUES (39, 9, '<h2 id=\"-\">如何保证生产者的发送消息的可靠性？</h2>\r\n<p>不同的消息队列，其架构不同，所以实现发送消息的可靠性的方案不同。所以参见如下文章：</p>\r\n<ul>\r\n<li>RocketMQ <a href=\"http://svip.iocoder.cn/RocketMQ/Interview/\">《精尽 RocketMQ 面试题》</a> 的 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「RocketMQ 是否会弄丢数据？」</a> 的面试题。</li>\r\n<li>RabbitMQ <a href=\"http://svip.iocoder.cn/RabbitMQ/Interview/\">《精尽 RabbitMQ 面试题》</a> 的 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「RabbitMQ 是否会弄丢数据？」</a> 的面试题。</li>\r\n<li>Kafka <a href=\"http://svip.iocoder.cn/Kafka/Interview/\">《精尽 Kafka 面试题》</a> 的 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「Kafka 是否会弄丢数据？」</a> 的面试题。</li>\r\n</ul>', '## 如何保证生产者的发送消息的可靠性？\r\n\r\n不同的消息队列，其架构不同，所以实现发送消息的可靠性的方案不同。所以参见如下文章：\r\n\r\n- RocketMQ [《精尽 RocketMQ 面试题》](http://svip.iocoder.cn/RocketMQ/Interview/) 的 [「RocketMQ 是否会弄丢数据？」](http://svip.iocoder.cn/MQ/Interview/#) 的面试题。\r\n- RabbitMQ [《精尽 RabbitMQ 面试题》](http://svip.iocoder.cn/RabbitMQ/Interview/) 的 [「RabbitMQ 是否会弄丢数据？」](http://svip.iocoder.cn/MQ/Interview/#) 的面试题。\r\n- Kafka [《精尽 Kafka 面试题》](http://svip.iocoder.cn/Kafka/Interview/) 的 [「Kafka 是否会弄丢数据？」](http://svip.iocoder.cn/MQ/Interview/#) 的面试题。', '2022-01-22 03:41:20', 0, '如何保证生产者的发送消息的可靠性？不同的消息队列，其架构不同，所以实现发送消息的可靠性的方案不同。所', '/static/img/rand/12.jpg', '如何保证生产者的发送消息的可靠性？', 0, 'post', 0, '2022-01-22 03:41:20', '1642844479', NULL);
INSERT INTO `qb_details` VALUES (40, 9, '<h2 id=\"-\">如何保证消息的顺序性？</h2>\r\n<p>不同的消息队列，其架构不同，所以实现消息的顺序性的方案不同。所以参见如下文章：</p>\r\n<ul>\r\n<li>RocketMQ <a href=\"http://svip.iocoder.cn/RocketMQ/Interview/\">《精尽 RocketMQ 面试题》</a> 的 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「什么是顺序消息？如何实现？」</a> 的面试题。</li>\r\n<li>RabbitMQ <a href=\"http://svip.iocoder.cn/RabbitMQ/Interview/\">《精尽 RabbitMQ 面试题》</a> 的 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「RabbitMQ 如何保证消息的顺序性？」</a> 面试题。</li>\r\n<li>Kafka <a href=\"http://svip.iocoder.cn/Kafka/Interview/\">《精尽 Kafka 面试题》</a> 的 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「Kafka 如何保证消息的顺序性？」</a> 的面试题。</li>\r\n</ul>', '## 如何保证消息的顺序性？\r\n\r\n不同的消息队列，其架构不同，所以实现消息的顺序性的方案不同。所以参见如下文章：\r\n\r\n- RocketMQ [《精尽 RocketMQ 面试题》](http://svip.iocoder.cn/RocketMQ/Interview/) 的 [「什么是顺序消息？如何实现？」](http://svip.iocoder.cn/MQ/Interview/#) 的面试题。\r\n- RabbitMQ [《精尽 RabbitMQ 面试题》](http://svip.iocoder.cn/RabbitMQ/Interview/) 的 [「RabbitMQ 如何保证消息的顺序性？」](http://svip.iocoder.cn/MQ/Interview/#) 面试题。\r\n- Kafka [《精尽 Kafka 面试题》](http://svip.iocoder.cn/Kafka/Interview/) 的 [「Kafka 如何保证消息的顺序性？」](http://svip.iocoder.cn/MQ/Interview/#) 的面试题。', '2022-01-22 03:43:19', 0, '如何保证消息的顺序性？不同的消息队列，其架构不同，所以实现消息的顺序性的方案不同。所以参见如下文章：', '/static/img/rand/6.jpg', '如何保证消息的顺序性？', 0, 'post', 0, '2022-01-22 03:43:19', '1642844599', NULL);
INSERT INTO `qb_details` VALUES (41, 9, '<h2 id=\"-\">消息队列如何实现高可用？</h2>\r\n<p>不同的消息队列，其架构不同，所以实现高可用的方案不同。所以参见如下文章：</p>\r\n<ul>\r\n<li>RocketMQ <a href=\"http://svip.iocoder.cn/RocketMQ/Interview/\">《精尽 RocketMQ 面试题》</a> 的 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「如何实现 RocketMQ 高可用？」</a> 的面试题。</li>\r\n<li>RabbitMQ <a href=\"http://svip.iocoder.cn/RabbitMQ/Interview/\">《精尽 RabbitMQ 面试题》</a> 的 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「RabbitMQ 如何实现高可用？」</a> 的面试题。</li>\r\n<li>Kafka <a href=\"http://svip.iocoder.cn/Kafka/Interview/\">《精尽 Kafka 面试题》</a> 的 <a href=\"http://svip.iocoder.cn/MQ/Interview/#\">「Kafka 如何实现高可用？」</a> 的面试题。</li>\r\n</ul>', '## 消息队列如何实现高可用？\r\n\r\n不同的消息队列，其架构不同，所以实现高可用的方案不同。所以参见如下文章：\r\n\r\n- RocketMQ [《精尽 RocketMQ 面试题》](http://svip.iocoder.cn/RocketMQ/Interview/) 的 [「如何实现 RocketMQ 高可用？」](http://svip.iocoder.cn/MQ/Interview/#) 的面试题。\r\n- RabbitMQ [《精尽 RabbitMQ 面试题》](http://svip.iocoder.cn/RabbitMQ/Interview/) 的 [「RabbitMQ 如何实现高可用？」](http://svip.iocoder.cn/MQ/Interview/#) 的面试题。\r\n- Kafka [《精尽 Kafka 面试题》](http://svip.iocoder.cn/Kafka/Interview/) 的 [「Kafka 如何实现高可用？」](http://svip.iocoder.cn/MQ/Interview/#) 的面试题。', '2022-01-22 03:43:49', 0, '消息队列如何实现高可用？不同的消息队列，其架构不同，所以实现高可用的方案不同。所以参见如下文章：Ro', '/static/img/rand/3.jpg', '消息队列如何实现高可用？', 0, 'post', 0, '2022-01-22 03:43:49', '1642844629', NULL);
INSERT INTO `qb_details` VALUES (42, 9, '<h2 id=\"-\">面向对象的特征有哪些？</h2>\r\n<ol>\r\n<li>抽象：将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象</li>\r\n<li>继承：继承是从已有类得到继承信息创建新类的过程。提供继承信息的类被称为父类（超类、基类）；得到继承信息的类被称为子类（派生类）。</li>\r\n<li>封装：通常认为封装是把数据和操作数据的方法绑定起来，对数据的访问只能通过已定义的接口。</li>\r\n<li>多态：多态性是指允许不同子类型的对象对同一消息作出不同的响应。简单的说就是用同样的对象引用调用同样的方法但是做了不同的事情。</li>\r\n</ol>', '## 面向对象的特征有哪些？\r\n\r\n1. 抽象：将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象\r\n2. 继承：继承是从已有类得到继承信息创建新类的过程。提供继承信息的类被称为父类（超类、基类）；得到继承信息的类被称为子类（派生类）。\r\n3. 封装：通常认为封装是把数据和操作数据的方法绑定起来，对数据的访问只能通过已定义的接口。\r\n4. 多态：多态性是指允许不同子类型的对象对同一消息作出不同的响应。简单的说就是用同样的对象引用调用同样的方法但是做了不同的事情。', '2022-02-04 02:29:29', 0, '面向对象的特征有哪些？抽象：将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象继承：继', '/static/img/rand/2.jpg', '面向对象的特征有哪些？', 0, 'post', 0, '2022-02-04 02:29:29', '1643963369', NULL);
INSERT INTO `qb_details` VALUES (43, 9, '<h2 id=\"-overload-override-\">重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？</h2>\r\n<p>方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。</p>\r\n<p>重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载；重载对返回类型没有特殊的要求。<br>重写发生在子父类之间，重写要求有相同的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。</p>', '## 重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？\r\n\r\n方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。\r\n\r\n重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载；重载对返回类型没有特殊的要求。\r\n重写发生在子父类之间，重写要求有相同的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。', '2022-02-04 02:31:30', 0, '重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？方法的', '/static/img/rand/7.jpg', '重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？', 0, 'post', 0, '2022-02-04 02:31:30', '1643963489', NULL);
INSERT INTO `qb_details` VALUES (44, 9, '<h2 id=\"-\">说说面向对象的”六原则一法则？</h2>\r\n<p>单一职责原则<br>　　一个类只做它该做的事情。<br>开闭原则<br>　　一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。<br>依赖倒转原则<br>　　程序要依赖于抽象接口，不依赖于具体实现。<br>里氏替换原则<br>　　任何时候都可以用子类型替换掉父类型。<br>接口隔原则<br>　　接口要小而专，绝不能大而全。<br>合成聚合复用原则<br>　　优先使用聚合或合成关系复用代码。<br>迪米特法则<br> 　　一个对象应该对其他的对象有尽可能少的了解，又叫最少知识原则。</p>', '## 说说面向对象的”六原则一法则？\r\n\r\n单一职责原则\r\n　　一个类只做它该做的事情。\r\n开闭原则\r\n　　一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。\r\n依赖倒转原则\r\n　　程序要依赖于抽象接口，不依赖于具体实现。\r\n里氏替换原则\r\n　　任何时候都可以用子类型替换掉父类型。\r\n接口隔原则\r\n　　接口要小而专，绝不能大而全。\r\n合成聚合复用原则\r\n　　优先使用聚合或合成关系复用代码。\r\n迪米特法则\r\n 　　一个对象应该对其他的对象有尽可能少的了解，又叫最少知识原则。', '2022-02-04 02:32:50', 0, '说说面向对象的”六原则一法则？单一职责原则一个类只做它该做的事情。开闭原则一个软件实体应当对扩展开放', '/static/img/rand/11.jpg', '说说面向对象的”六原则一法则？', 0, 'post', 0, '2022-02-04 02:32:50', '1643963569', NULL);
INSERT INTO `qb_details` VALUES (45, 9, '<h2 id=\"-\">如何实现对象克隆？</h2>\r\n<p>1). 实现Cloneable接口并重写Object类中的clone()方法；<br>2). 实现Serializable接口，通过对象的序列化和反序列化实现克隆，可以实现真正的深度克隆</p>', '## 如何实现对象克隆？\r\n\r\n1). 实现Cloneable接口并重写Object类中的clone()方法；\r\n2). 实现Serializable接口，通过对象的序列化和反序列化实现克隆，可以实现真正的深度克隆', '2022-02-04 02:33:34', 0, '如何实现对象克隆？1).实现Cloneable接口并重写Object类中的clone()方法；2).', '/static/img/rand/8.jpg', '如何实现对象克隆？', 0, 'post', 0, '2022-02-04 02:33:34', '1643963614', NULL);
INSERT INTO `qb_details` VALUES (46, 9, '<h2 id=\"-\">说说面向对象类的几种关系</h2>\r\n<ul>\r\n<li>继承</li>\r\n<li>实现</li>\r\n<li>依赖</li>\r\n<li>关联</li>\r\n<li>聚合</li>\r\n<li>组合</li>\r\n</ul>', '## 说说面向对象类的几种关系\r\n\r\n- 继承\r\n- 实现\r\n- 依赖\r\n- 关联\r\n- 聚合\r\n- 组合', '2022-02-04 02:38:26', 0, '说说面向对象类的几种关系继承实现依赖关联聚合组合', '/static/img/rand/7.jpg', '说说面向对象类的几种关系', 0, 'post', 0, '2022-02-04 02:38:26', '1643963906', NULL);
INSERT INTO `qb_details` VALUES (47, 9, '<h2 id=\"-\">面向对象中的组合和聚合区别</h2>\r\n<p>聚合关系是关联关系的一种，耦合度强于关联，他们的代码表现是相同的，仅仅是在语义上有所区别：关联关系的对象间是相互独立的，而聚合关系的对象之间存在着包容关系，他们之间是“整体-个体”的相互关系。</p>\r\n<p><img src=\"https://secure2.wostatic.cn/static/j8o5TrRYHaF5MZGhcVwa4x/image.png\" alt=\"\"></p>\r\n<p>组合是一种耦合度更强的关联关系。存在组合关系的类表示“整体-部分”的关联关系，“整体”负责“部分”的生命周期，他们之间是共生共死的；并且“部分”单独存在时没有任何意义。</p>\r\n<p><img src=\"https://secure2.wostatic.cn/static/s9pJDRFRgKhKk9TsjjSQSY/image.png\" alt=\"\"></p>', '## 面向对象中的组合和聚合区别\r\n\r\n聚合关系是关联关系的一种，耦合度强于关联，他们的代码表现是相同的，仅仅是在语义上有所区别：关联关系的对象间是相互独立的，而聚合关系的对象之间存在着包容关系，他们之间是“整体-个体”的相互关系。\r\n\r\n![](https://secure2.wostatic.cn/static/j8o5TrRYHaF5MZGhcVwa4x/image.png)\r\n\r\n组合是一种耦合度更强的关联关系。存在组合关系的类表示“整体-部分”的关联关系，“整体”负责“部分”的生命周期，他们之间是共生共死的；并且“部分”单独存在时没有任何意义。\r\n\r\n![](https://secure2.wostatic.cn/static/s9pJDRFRgKhKk9TsjjSQSY/image.png)', '2022-02-04 02:38:37', 0, '面向对象中的组合和聚合区别聚合关系是关联关系的一种，耦合度强于关联，他们的代码表现是相同的，仅仅是在', '/static/img/rand/5.jpg', '面向对象中的组合和聚合区别', 0, 'post', 0, '2022-02-04 02:38:37', '1643963916', NULL);
INSERT INTO `qb_details` VALUES (48, 9, '<h2 id=\"-\">说说数据库的三大范式，为什么要有三大范式？</h2>\r\n<p>第一范式：数据库中所有的属性字段都是不可分解的，即我们创建的属性在此字段中一定是你设计表的最小的字段值，遵循数据的原子性</p>\r\n<p>第二范式：表中的属性字段必须依赖于表的主键</p>\r\n<p>第三范式：不能出现传递依赖</p>\r\n<p>范式即是对数据库表设计的约束，约束越多，表设计就越复杂，而规范化目的是使结构更合理，消除存储异常，使数据冗余尽量小。便于插入、删除和更新。</p>', '## 说说数据库的三大范式，为什么要有三大范式？\r\n\r\n第一范式：数据库中所有的属性字段都是不可分解的，即我们创建的属性在此字段中一定是你设计表的最小的字段值，遵循数据的原子性\r\n\r\n第二范式：表中的属性字段必须依赖于表的主键\r\n\r\n第三范式：不能出现传递依赖\r\n\r\n范式即是对数据库表设计的约束，约束越多，表设计就越复杂，而规范化目的是使结构更合理，消除存储异常，使数据冗余尽量小。便于插入、删除和更新。', '2022-02-04 02:53:31', 0, '说说数据库的三大范式，为什么要有三大范式？第一范式：数据库中所有的属性字段都是不可分解的，即我们创建', '/static/img/rand/11.jpg', '说说数据库的三大范式，为什么要有三大范式？', 0, 'post', 0, '2022-02-04 02:53:31', '1643964811', NULL);
INSERT INTO `qb_details` VALUES (49, 9, '<h2 id=\"mysql-rc-\">MySQL事务隔离级别？以及默认是哪个?考虑用RC吗</h2>\r\n<p>MySQL的隔离级别的作用就是让事务之间互相隔离，互不影响，这样可以保证事务的一致性。</p>\r\n<p>按照隔离级别从低到高有以下几个级别：</p>\r\n<p>1。读未提交（Read Uncommited）</p>\r\n<p>2。读已提交（Read Committed (RC)）</p>\r\n<p>3。可重复读（Repeatable Read (RR)）</p>\r\n<p>4。可串行化（Serializable）</p>\r\n<p>隔离级别越高，所消耗的MySQL性能越大（如事务并发严重性），为了平衡二者，<strong>一般建议设置的隔离级别为可重复读，MySQL默认的隔离级别也是可重复读。</strong></p>\r\n<p>相较于RR，RC有两点优势</p>\r\n<p>1。提高并发。RC 在加锁的过程中，是不需要添加Gap Lock和 Next-Key Lock 的，只对要修改的记录添加行级锁就行了。并且RC 还支持&quot;半一致读&quot;，可以大大的减少了更新语句时行锁的冲突；对于不满足更新条件的记录，可以提前释放锁，提升并发度。</p>\r\n<p>2。减少死锁。因为RR这种事务隔离级别会增加Gap Lock和 Next-Key Lock，这就使得锁的粒度变大，那么就会使得死锁的概率增大。</p>\r\n<p><strong>拓展</strong>：</p>\r\n<p>死锁：一个事务锁住了表A，然后又访问表B；另一个事务锁住了表B，然后企图访问表A；这时就会互相等待对方释放锁，就导致了死锁。</p>\r\n<p>锁的三种类型：数据库的锁，在不同的事务隔离级别下，是采用了不同的机制的</p>\r\n<p>在 MySQL 中，有三种类型的锁，分别是Record Lock、Gap Lock和 Next-Key Lock。</p>\r\n<ul>\r\n<li>Record Lock表示记录锁，锁的是索引记录。</li>\r\n<li>Gap Lock是间隙锁，锁的是索引记录之间的间隙。</li>\r\n<li>Next-Key Lock是Record Lock和Gap Lock的组合，同时锁索引记录和间隙。他的范围是左开右闭的。</li>\r\n</ul>', '## MySQL事务隔离级别？以及默认是哪个?考虑用RC吗\r\n\r\nMySQL的隔离级别的作用就是让事务之间互相隔离，互不影响，这样可以保证事务的一致性。\r\n\r\n按照隔离级别从低到高有以下几个级别：\r\n\r\n1。读未提交（Read Uncommited）\r\n\r\n2。读已提交（Read Committed (RC)）\r\n\r\n3。可重复读（Repeatable Read (RR)）\r\n\r\n4。可串行化（Serializable）\r\n\r\n隔离级别越高，所消耗的MySQL性能越大（如事务并发严重性），为了平衡二者，**一般建议设置的隔离级别为可重复读，MySQL默认的隔离级别也是可重复读。**\r\n\r\n相较于RR，RC有两点优势\r\n\r\n1。提高并发。RC 在加锁的过程中，是不需要添加Gap Lock和 Next-Key Lock 的，只对要修改的记录添加行级锁就行了。并且RC 还支持\"半一致读\"，可以大大的减少了更新语句时行锁的冲突；对于不满足更新条件的记录，可以提前释放锁，提升并发度。\r\n\r\n2。减少死锁。因为RR这种事务隔离级别会增加Gap Lock和 Next-Key Lock，这就使得锁的粒度变大，那么就会使得死锁的概率增大。\r\n\r\n**拓展**：\r\n\r\n死锁：一个事务锁住了表A，然后又访问表B；另一个事务锁住了表B，然后企图访问表A；这时就会互相等待对方释放锁，就导致了死锁。\r\n\r\n锁的三种类型：数据库的锁，在不同的事务隔离级别下，是采用了不同的机制的\r\n\r\n在 MySQL 中，有三种类型的锁，分别是Record Lock、Gap Lock和 Next-Key Lock。\r\n\r\n- Record Lock表示记录锁，锁的是索引记录。\r\n- Gap Lock是间隙锁，锁的是索引记录之间的间隙。\r\n- Next-Key Lock是Record Lock和Gap Lock的组合，同时锁索引记录和间隙。他的范围是左开右闭的。', '2022-02-04 03:01:36', 0, 'MySQL事务隔离级别？以及默认是哪个？MySQL的隔离级别的作用就是让事务之间互相隔离，互不影响，', '/static/img/rand/13.jpg', 'MySQL事务隔离级别？以及默认是哪个?考虑用RC吗', 0, 'post', 0, '2022-02-05 04:15:03', '1643965295', NULL);
INSERT INTO `qb_details` VALUES (50, 9, '<h2 id=\"spring-aop-\">Spring AOP使用了什么设计模式？</h2>\r\n<p>Spring AOP 的实现采用了代理设计模式。</p>\r\n<p>如果要代理的对象，实现了某个接口，那么Spring AOP会使用<strong>JDK Proxy</strong>，去创建代理对象。</p>\r\n<p>对于没有实现接口的对象，Spring AOP会使用<strong>Cglib</strong> ，这时候Spring AOP会使用 <strong>Cglib</strong> 生成一个被代理对象的子类来作为代理</p>', '## Spring AOP使用了什么设计模式？\r\n\r\nSpring AOP 的实现采用了代理设计模式。\r\n\r\n如果要代理的对象，实现了某个接口，那么Spring AOP会使用**JDK Proxy**，去创建代理对象。\r\n\r\n对于没有实现接口的对象，Spring AOP会使用**Cglib** ，这时候Spring AOP会使用 **Cglib** 生成一个被代理对象的子类来作为代理', '2022-02-04 03:11:04', 0, 'SpringAOP使用了什么设计模式？SpringAOP的实现采用了代理设计模式。如果要代理的对象，', '/static/img/rand/15.jpg', 'Spring AOP使用了什么设计模式？', 0, 'post', 0, '2022-02-04 03:11:04', '1643965863', NULL);
INSERT INTO `qb_details` VALUES (51, 9, '<h2 id=\"-\">怎么创建一个线程池？有哪几种创建方式？传入的参数分别什么含义？</h2>\r\n<p>四种创建方式：</p>\r\n<p>1。newCachedThreadPool 创建一个可缓存线程池<br>2。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数。</p>\r\n<p>3。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。<br>4。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务。</p>\r\n<p>七个核心参数</p>\r\n<p>1。核心线程数（corePoolSize）：线程池中活跃的线程数，即使它们是空闲的。（allowCoreThreadTimeOut的值是控制核心线程数是否在没有任务时是否停止活跃的线程，当它的值为true时，在线程池没有任务时，所有的工作线程都会停止。）</p>\r\n<p>2。最大线程数（maximumPoolSize）：线程池所允许存在的最大线程数。</p>\r\n<p>3。多余线程存活时长（keepAliveTime）：线程池中除核心线程数之外的线程（多余线程）的最大存活时间，如果在这个时间范围内，多余线程没有任务需要执行，则多余线程就会停止。(注意：多余线程数 = 最大线程数 - 核心线程数)</p>\r\n<p>4。时间单位（unit）：多余线程存活时间的单位，可以是分钟、秒、毫秒等。</p>\r\n<p>5。任务队列（workQueue）：线程池的任务队列，使用线程池执行任务时，任务会先提交到这个队列中，然后工作线程取出任务进行执行，当这个队列满了，线程池就会执行拒绝策略。</p>\r\n<p>6。线程工厂（threadFactory）：创建线程池的工厂，线程池将使用这个工厂来创建线程池，自定义线程工厂需要实现ThreadFactory接口。</p>\r\n<p>7。拒绝执行处理器（也称拒绝策略）（handler）：当线程池无空闲线程，并且任务队列已满，此时将线程池将使用这个处理器来处理新提交的任务。</p>', '## 怎么创建一个线程池？有哪几种创建方式？传入的参数分别什么含义？\r\n\r\n四种创建方式：\r\n\r\n1。newCachedThreadPool 创建一个可缓存线程池\r\n2。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数。\r\n\r\n3。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。\r\n4。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务。\r\n\r\n七个核心参数\r\n\r\n1。核心线程数（corePoolSize）：线程池中活跃的线程数，即使它们是空闲的。（allowCoreThreadTimeOut的值是控制核心线程数是否在没有任务时是否停止活跃的线程，当它的值为true时，在线程池没有任务时，所有的工作线程都会停止。）\r\n\r\n2。最大线程数（maximumPoolSize）：线程池所允许存在的最大线程数。\r\n\r\n3。多余线程存活时长（keepAliveTime）：线程池中除核心线程数之外的线程（多余线程）的最大存活时间，如果在这个时间范围内，多余线程没有任务需要执行，则多余线程就会停止。(注意：多余线程数 = 最大线程数 - 核心线程数)\r\n\r\n4。时间单位（unit）：多余线程存活时间的单位，可以是分钟、秒、毫秒等。\r\n\r\n5。任务队列（workQueue）：线程池的任务队列，使用线程池执行任务时，任务会先提交到这个队列中，然后工作线程取出任务进行执行，当这个队列满了，线程池就会执行拒绝策略。\r\n\r\n6。线程工厂（threadFactory）：创建线程池的工厂，线程池将使用这个工厂来创建线程池，自定义线程工厂需要实现ThreadFactory接口。\r\n\r\n7。拒绝执行处理器（也称拒绝策略）（handler）：当线程池无空闲线程，并且任务队列已满，此时将线程池将使用这个处理器来处理新提交的任务。', '2022-02-04 03:48:52', 0, '怎么创建一个线程池？有哪几种创建方式？传入的参数分别什么含义？四种创建方式：1。newCachedT', '/static/img/rand/3.jpg', '怎么创建一个线程池？有哪几种创建方式？传入的参数分别什么含义？', 0, 'post', 0, '2022-02-04 03:48:52', '1643968131', NULL);
INSERT INTO `qb_details` VALUES (52, 9, '<h2 id=\"-wait-sleep-sleep-\">讲讲wait和sleep的区别？如果sleep还未到时间我要唤醒如何做?</h2>\r\n<p>1。区别：</p>\r\n<p>1)  原理不同。</p>\r\n<p>sleep()方法是Thread类的静态方法，是线程用来控制自身流程的，他会使此线程暂停执行一段时间，而把执行机会让给其他线程，等到计时时间一到，此线程会自动苏醒。例如，当线程执行报时功能时，每一秒钟打印出一个时间，那么此时就需要在打印方法前面加一个sleep()方法，以便让自己每隔一秒执行一次，该过程如同闹钟一样。而wait()方法是object类的方法，用于线程间通信，这个方法会使当前拥有该对象锁的进程等待，直到其他线程调用notify（）方法或者notifyAll（）时才醒来，不过开发人员也可以给他指定一个时间，自动醒来。</p>\r\n<p>2)  对锁的处理机制不同。</p>\r\n<p>由于sleep()方法的主要作用是让线程暂停执行一段时间，时间一到则自动恢复，不涉及线程间的通信，因此，调用sleep()方法并不会释放锁。而wait()方法则不同，当调用wait()方法后，线程会释放掉他所占用的锁，从而使线程所在对象中的其他synchronized数据可以被其他线程使用。</p>\r\n<p>3)  使用区域不同。</p>\r\n<p>wait()方法必须放在同步控制方法和同步代码块中使用，sleep()方法则可以放在任何地方使用。sleep()方法必须捕获异常，而wait()、notify（）、notifyAll（）不需要捕获异常。在sleep的过程中，有可能被其他对象调用他的interrupt（），产生InterruptedException。由于sleep不会释放锁标志，容易导致死锁问题的发生，因此一般情况下，推荐使用wait（）方法。</p>\r\n<p>2。使用thread.interrupt();可以改变中断状态，给受阻塞的线程发出一个中断信号，这样受阻线程就得以退出阻塞的状态。</p>\r\n<pre><code class=\"lang-Java\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(String[] args)</span> </span>{\r\n  <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">0</span>;i&lt;<span class=\"hljs-number\">5</span>;i++){\r\n    Thread thread=<span class=\"hljs-keyword\">new</span> Thread( <span class=\"hljs-keyword\">new</span> InterruptThread());\r\n    thread.start();\r\n    thread.interrupt();\r\n  }\r\n}\r\n\r\n<span class=\"hljs-keyword\">static</span>  <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span>   <span class=\"hljs-title\">InterruptThread</span> <span class=\"hljs-keyword\">implements</span>  <span class=\"hljs-title\">Runnable</span>  </span>{\r\n <span class=\"hljs-meta\">@Override</span>\r\n <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">run</span><span class=\"hljs-params\">()</span> </span>{\r\n   <span class=\"hljs-keyword\">try</span> {\r\n       Thread.sleep(<span class=\"hljs-number\">2000</span>);\r\n   } <span class=\"hljs-keyword\">catch</span> (InterruptedException e) {\r\n       System.out.println(<span class=\"hljs-string\">\"线程处于阻塞状态时，中断线程，就会抛出异常。\"</span>);\r\n       e.printStackTrace();\r\n   }\r\n }\r\n}\r\n</code></pre>', '## 讲讲wait和sleep的区别？如果sleep还未到时间我要唤醒如何做?\r\n\r\n1。区别：\r\n\r\n1)  原理不同。\r\n\r\nsleep()方法是Thread类的静态方法，是线程用来控制自身流程的，他会使此线程暂停执行一段时间，而把执行机会让给其他线程，等到计时时间一到，此线程会自动苏醒。例如，当线程执行报时功能时，每一秒钟打印出一个时间，那么此时就需要在打印方法前面加一个sleep()方法，以便让自己每隔一秒执行一次，该过程如同闹钟一样。而wait()方法是object类的方法，用于线程间通信，这个方法会使当前拥有该对象锁的进程等待，直到其他线程调用notify（）方法或者notifyAll（）时才醒来，不过开发人员也可以给他指定一个时间，自动醒来。\r\n\r\n2)  对锁的处理机制不同。\r\n\r\n由于sleep()方法的主要作用是让线程暂停执行一段时间，时间一到则自动恢复，不涉及线程间的通信，因此，调用sleep()方法并不会释放锁。而wait()方法则不同，当调用wait()方法后，线程会释放掉他所占用的锁，从而使线程所在对象中的其他synchronized数据可以被其他线程使用。\r\n\r\n3)  使用区域不同。\r\n\r\nwait()方法必须放在同步控制方法和同步代码块中使用，sleep()方法则可以放在任何地方使用。sleep()方法必须捕获异常，而wait()、notify（）、notifyAll（）不需要捕获异常。在sleep的过程中，有可能被其他对象调用他的interrupt（），产生InterruptedException。由于sleep不会释放锁标志，容易导致死锁问题的发生，因此一般情况下，推荐使用wait（）方法。\r\n\r\n2。使用thread.interrupt();可以改变中断状态，给受阻塞的线程发出一个中断信号，这样受阻线程就得以退出阻塞的状态。\r\n\r\n```Java\r\npublic static void main(String[] args) {\r\n  for(int i=0;i<5;i++){\r\n    Thread thread=new Thread( new InterruptThread());\r\n    thread.start();\r\n    thread.interrupt();\r\n  }\r\n}\r\n\r\nstatic  class   InterruptThread implements  Runnable  {\r\n @Override\r\n public void run() {\r\n   try {\r\n       Thread.sleep(2000);\r\n   } catch (InterruptedException e) {\r\n       System.out.println(\"线程处于阻塞状态时，中断线程，就会抛出异常。\");\r\n       e.printStackTrace();\r\n   }\r\n }\r\n}\r\n```', '2022-02-04 04:04:45', 0, '讲讲wait和sleep的区别？如果sleep还未到时间我要唤醒如何做?1。区别：1)原理不同。sl', '/static/img/rand/5.jpg', '讲讲wait和sleep的区别？如果sleep还未到时间我要唤醒如何做?', 0, 'post', 0, '2022-02-04 04:05:45', '1643969084', NULL);
INSERT INTO `qb_details` VALUES (53, 9, '<h2 id=\"-es-solr-\">为什么用es，与solr对比？</h2>\r\n<p>1。检索速度：对已有数据进行搜索时，Solr 更快。实时搜索ES更具有优势</p>\r\n<p>2。扩容（分布式）与缩容：ES 默认是集群化的（即时是在单台服务器上运行，也称之为集群），并且总是可以添加更多的服务器用于增加容量或者容错性。类似的，如果负载较低的时候，可以很容易地从集群中移除服务器，降低成本。而SolrCloud 是基于 Solr 和 Zookeeper 的分布式搜索方案。它的主要思想是使用 Zookeeper 作为 SolrCloud 集群的配置信息中心，统一管理 solrcloud 的配置，比如 solrconfig.xml 和 schema.xml。横向拓展需要修改程序。</p>\r\n<p>3。数据聚合功能（aggregation）：过滤与分组，支持复杂的搜索时间聚合</p>\r\n<p>4。Elasticsearch在开源日志管理占主导地位，Solr更加面向文本搜索</p>\r\n<p>5。使用起来ES更加简单一点</p>', '## 为什么用es，与solr对比？\r\n\r\n1。检索速度：对已有数据进行搜索时，Solr 更快。实时搜索ES更具有优势\r\n\r\n2。扩容（分布式）与缩容：ES 默认是集群化的（即时是在单台服务器上运行，也称之为集群），并且总是可以添加更多的服务器用于增加容量或者容错性。类似的，如果负载较低的时候，可以很容易地从集群中移除服务器，降低成本。而SolrCloud 是基于 Solr 和 Zookeeper 的分布式搜索方案。它的主要思想是使用 Zookeeper 作为 SolrCloud 集群的配置信息中心，统一管理 solrcloud 的配置，比如 solrconfig.xml 和 schema.xml。横向拓展需要修改程序。\r\n\r\n3。数据聚合功能（aggregation）：过滤与分组，支持复杂的搜索时间聚合\r\n\r\n4。Elasticsearch在开源日志管理占主导地位，Solr更加面向文本搜索\r\n\r\n5。使用起来ES更加简单一点', '2022-02-05 03:08:22', 0, '为什么用es，与solr对比？1。检索速度：对已有数据进行搜索时，Solr更快。实时搜索ES更具有优', '/static/img/rand/2.jpg', '为什么用es，与solr对比？', 0, 'post', 0, '2022-02-05 03:08:22', '1644052102', NULL);
INSERT INTO `qb_details` VALUES (54, 9, '<h2 id=\"-elasticsearch-\">在并发情况下，ElasticSearch 如果保证读写一致？</h2>\r\n<ol>\r\n<li>可以通过版本号使用乐观锁并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突。</li>\r\n<li>另外对于写操作，一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将<br>会在一个不同的节点上重建</li>\r\n<li>对于读操作，可以设置 replication 为 sync（默认），这使得操作在主分片和副本分片都完成后才会返回如果设置 replication 为sync 时，也可以通过设置搜索请求参数 _preference 为 primary来查询主分片确保文档是最新版本</li>\r\n</ol>', '## 在并发情况下，ElasticSearch 如果保证读写一致？\r\n\r\n1. 可以通过版本号使用乐观锁并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突。\r\n2. 另外对于写操作，一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将\r\n  会在一个不同的节点上重建\r\n3. 对于读操作，可以设置 replication 为 sync（默认），这使得操作在主分片和副本分片都完成后才会返回如果设置 replication 为sync 时，也可以通过设置搜索请求参数 _preference 为 primary来查询主分片确保文档是最新版本', '2022-02-05 03:34:42', 0, '在并发情况下，ElasticSearch如果保证读写一致？可以通过版本号使用乐观锁并发控制，以确保新', '/static/img/rand/9.jpg', '在并发情况下，ElasticSearch 如果保证读写一致？', 0, 'post', 0, '2022-02-05 03:34:42', '1644053682', NULL);
INSERT INTO `qb_details` VALUES (55, 9, '<h2 id=\"-redis-\">使用过 Redis 分布式锁么，它是什么回事？</h2>\r\n<p>先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。</p>\r\n<p>注：这里是两个操作，不具有原子性。</p>\r\n<p>情况一：<br>  如果在 setnx 之后执行 expire之前进程意外 crash 或者要重启维护了，会出现锁无法释放的情况。<br>  解决方案：<br>    为了保证 这两个操作的原子性，可以使用 set 指令将这两条指令合称为一条指令来用。</p>\r\n<p>情况二：<br>  过期时间已经到了，但是服务1还没有释放锁，那么就有可能会出现多个服务操作一个对象的场景？<br>  解决方案：<br>    思路一：任务执行的时候，开辟一个守护线程，在守护线程中每隔一段时间重新设置过期时间。<br>    思路二：通过Redisson中的看门狗来实现。</p>\r\n<p>情况三：<br>如果你对某个redis master实例，写入了myLock这种锁key的value，此时会异步复制给对应的master slave实例。<br>但是这个过程中一旦发生redis master宕机，主备切换，redis slave变为了redis master。<br>接着就会导致，客户端2来尝试加锁的时候，在新的redis master上完成了加锁，而客户端1也以为自己成功加了锁。此时就会导致多个客户端对一个分布式锁完成了加锁。</p>\r\n<p>简单来说就是：在redis master实例宕机的时候，可能导致多个客户端同时完成加锁。</p>\r\n<pre><code>解决方案：\r\n  Redisson 的 RedLock 算法\r\n    遍历所有的Redis客户端，然后依次加锁，最后统计成功的次数来判断是否加锁成功。不能只在一个redis实例上创建锁，应该是在多个redis实例上创建锁，n / 2 + 1，\r\n    必须在大多数redis节点上都成功创建锁，才能算这个整体的RedLock加锁成功\r\n</code></pre>', '## 使用过 Redis 分布式锁么，它是什么回事？\r\n\r\n先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。\r\n\r\n注：这里是两个操作，不具有原子性。\r\n\r\n情况一：\r\n  如果在 setnx 之后执行 expire之前进程意外 crash 或者要重启维护了，会出现锁无法释放的情况。\r\n  解决方案：\r\n    为了保证 这两个操作的原子性，可以使用 set 指令将这两条指令合称为一条指令来用。\r\n\r\n情况二：\r\n  过期时间已经到了，但是服务1还没有释放锁，那么就有可能会出现多个服务操作一个对象的场景？\r\n  解决方案：\r\n    思路一：任务执行的时候，开辟一个守护线程，在守护线程中每隔一段时间重新设置过期时间。\r\n    思路二：通过Redisson中的看门狗来实现。\r\n\r\n情况三：\r\n如果你对某个redis master实例，写入了myLock这种锁key的value，此时会异步复制给对应的master slave实例。\r\n但是这个过程中一旦发生redis master宕机，主备切换，redis slave变为了redis master。\r\n接着就会导致，客户端2来尝试加锁的时候，在新的redis master上完成了加锁，而客户端1也以为自己成功加了锁。此时就会导致多个客户端对一个分布式锁完成了加锁。\r\n\r\n简单来说就是：在redis master实例宕机的时候，可能导致多个客户端同时完成加锁。\r\n\r\n    解决方案：\r\n      Redisson 的 RedLock 算法\r\n        遍历所有的Redis客户端，然后依次加锁，最后统计成功的次数来判断是否加锁成功。不能只在一个redis实例上创建锁，应该是在多个redis实例上创建锁，n / 2 + 1，\r\n        必须在大多数redis节点上都成功创建锁，才能算这个整体的RedLock加锁成功', '2022-02-05 04:37:58', 0, '使用过Redis分布式锁么，它是什么回事？先拿setnx来争抢锁，抢到之后，再用expire给锁加一', '/static/img/rand/9.jpg', '使用过 Redis 分布式锁么，它是什么回事？', 0, 'post', 0, '2022-02-05 04:37:58', '1644057477', NULL);

SET FOREIGN_KEY_CHECKS = 1;
